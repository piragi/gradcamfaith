For a personal project, I try to measure the impact of SAE features that we gathered from the residual stream and want to see how much impact it has on the final classification. Also, we want to measure if the patches where the features turn up have high gradients in the attention maps. The goal is to then later identify features that have high impact on the final classification but are not really flagged by the attention mechanism. With the identified features, I then boost the token positions at the specific layer when doing attribution generation with Chefer's method.
My first hypothesis is, that we should be able to identify features that have spatial properties and directly relate to the classification of a specific class, which we can the subsequently use to boost attribution maps and result with more faithful representations. Maybe, there is a similar effect as in the steering paper, that using a specific subset of features could improve the attribution map. In the steering paper, they found that a specific subset (approximately 10%) are highly steerable.
In current findings from my project, I have found a positive correlation between a subset of features and their attribution strength. Meaning, I was able to identify a subset of features that have a high correlation with patches that are highlighted by the attribution method. This would strengthen my assumption, that some features have spatial properties, which could be exploited for boosting purposes. The idea is simple. Build a dictionary that maps the features and how they correlate with attribution strength inside your training data. Use this dictionary to identify features that light up during your validation run and reinforce signals that had a high correlation (when predicting the same class as in the training set).
