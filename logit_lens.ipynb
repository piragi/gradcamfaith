{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55cc60d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 1050 X-ray images\n",
      "Preprocessing complete. 1050 images saved to results/test/preprocessed\n",
      "Found 1050 original images for processing.\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "ViT model loaded, hooks registered, and set to eval mode.\n",
      "Running Classify & Explain for original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying & Explaining (suffix: ''): 100%|██████████| 1050/1050 [00:00<00:00, 38709.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test/classification_results_originals_explained.csv\n",
      "Evaluate Faithfulness Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings - n_trials: 3, nr_runs: 100, subset_size: 224\n",
      "Running estimator: FaithfulnessEstimate\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': True, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'features_in_step': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piragi/projects/gradcamfaithtest/gradcamfaith/.venv/lib/python3.10/site-packages/quantus/helpers/warn.py:257: UserWarning: The settings for perturbing input e.g., 'perturb_func' didn't cause change in input. Reconsider the parameter settings.\n",
      "  warnings.warn(\n",
      "1050it [19:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': True, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'features_in_step': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1050it [19:03,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': True, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'features_in_step': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1050it [19:02,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running estimator: FaithfulnessCorrelation\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n",
      "\n",
      "FaithfulnessEstimate faithfulness statistics (across 3 trials):\n",
      "  Mean: 0.3493\n",
      "  Median: 0.3758\n",
      "  Count: 1050\n",
      "  Avg trial std: 0.0000 (lower is more stable)\n",
      "\n",
      "FaithfulnessEstimate per-class faithfulness statistics:\n",
      "  Class 2:\n",
      "    Mean: 0.3118\n",
      "    Median: 0.3258\n",
      "    Count: 327\n",
      "    Avg trial std: 0.0000\n",
      "  Class 1:\n",
      "    Mean: 0.3356\n",
      "    Median: 0.3613\n",
      "    Count: 375\n",
      "    Avg trial std: 0.0000\n",
      "  Class 0:\n",
      "    Mean: 0.3993\n",
      "    Median: 0.4545\n",
      "    Count: 348\n",
      "    Avg trial std: 0.0000\n",
      "\n",
      "FaithfulnessCorrelation faithfulness statistics (across 3 trials):\n",
      "  Mean: 0.1658\n",
      "  Median: 0.1680\n",
      "  Count: 1050\n",
      "  Avg trial std: 0.0706 (lower is more stable)\n",
      "\n",
      "FaithfulnessCorrelation per-class faithfulness statistics:\n",
      "  Class 2:\n",
      "    Mean: 0.2390\n",
      "    Median: 0.2376\n",
      "    Count: 327\n",
      "    Avg trial std: 0.0710\n",
      "  Class 1:\n",
      "    Mean: 0.1882\n",
      "    Median: 0.1911\n",
      "    Count: 375\n",
      "    Avg trial std: 0.0683\n",
      "  Class 0:\n",
      "    Mean: 0.0727\n",
      "    Median: 0.0711\n",
      "    Count: 348\n",
      "    Avg trial std: 0.0727\n",
      "Raw scores for FaithfulnessEstimate saved to results/test/faithfulness_scores_FaithfulnessEstimate.npy.npz\n",
      "Raw scores for FaithfulnessCorrelation saved to results/test/faithfulness_scores_FaithfulnessCorrelation.npy.npz\n",
      "Faithfulness statistics saved to results/test/faithfulness_stats.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing dataset: 100%|██████████| 1050/1050 [00:03<00:00, 286.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 205800 perturbed image records.\n",
      "Running Classify ONLY for perturbed images (suffix: '_perturbed')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying dataset (suffix: '_perturbed'): 100%|██████████| 205800/205800 [00:03<00:00, 52190.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test/classification_results_perturbed_classified_only_perturbed.csv\n",
      "Full pipeline finished.\n",
      "compare attributions\n",
      "Building analysis context...\n",
      "Generating perturbation comparison DataFrame for SaCo...\n",
      "Generating perturbation comparison data for SaCo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Perturbations: 100%|██████████| 205800/205800 [00:09<00:00, 22532.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base comparison DataFrame for SaCo saved to results/test/perturbation_comparison_for_saco_perturbed.csv\n",
      "Running core SaCo calculations...\n",
      "Average SaCo score for method 'mean': 0.3866 (over 1050 images)\n",
      "SaCo patch analysis saved to results/test/saco_patch_analysis_mean_perturbed.csv\n",
      "Analyzing key attribution patterns...\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "\n",
      "============================================================\n",
      "OVERALL CORRELATIONS WITH SACO SCORE:\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: Normal\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for Normal:\n",
      "  Total samples: 305\n",
      "  Mean SaCo score: 0.504\n",
      "  Median SaCo score: 0.531\n",
      "  Std SaCo score: 0.167\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: COVID-19\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for COVID-19:\n",
      "  Total samples: 335\n",
      "  Mean SaCo score: 0.302\n",
      "  Median SaCo score: 0.321\n",
      "  Std SaCo score: 0.166\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: Non-COVID\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for Non-COVID:\n",
      "  Total samples: 331\n",
      "  Mean SaCo score: 0.371\n",
      "  Median SaCo score: 0.382\n",
      "  Std SaCo score: 0.189\n",
      "Saving analysis results...\n",
      "Saved perturbation_comparison to results/test/analysis_perturbation_comparison_perturbed.csv\n",
      "Saved saco_scores to results/test/analysis_saco_scores_perturbed.csv\n",
      "Saved patch_metrics to results/test/analysis_patch_metrics_perturbed.csv\n",
      "Saved faithfulness_correctness to results/test/analysis_faithfulness_correctness_perturbed.csv\n",
      "Saved attribution_patterns to results/test/analysis_attribution_patterns_perturbed.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import analysis\n",
    "import config\n",
    "import pipeline as pipe\n",
    "import vit.model as model\n",
    "from head_analysis import run_head_analysis\n",
    "from main import run_saco_from_pipeline_outputs\n",
    "\n",
    "pipeline_config = config.PipelineConfig()\n",
    "pipeline_config.file.use_cached_original = True\n",
    "pipeline_config.file.current_mode = \"test\"\n",
    "pipeline_config.file.weighted = False\n",
    "pipeline_config.classify.analysis = True\n",
    "\n",
    "pipeline_config.classify.data_collection = False\n",
    "\n",
    "original_classification, (\n",
    "    perturbed_image_records, perturbed_classification) = pipe.run_pipeline(\n",
    "        pipeline_config,\n",
    "        source_dir_for_preprocessing=Path(\n",
    "            f\"./COVID-QU-Ex/{pipeline_config.file.current_mode}\"))\n",
    "\n",
    "print(\"compare attributions\")\n",
    "run_saco_from_pipeline_outputs(pipeline_config, original_classification,\n",
    "                                perturbed_image_records,\n",
    "                                perturbed_classification)\n",
    "\n",
    "# vit = model.load_vit_model()\n",
    "# direction_similarities, head_importance, token_patterns = run_head_analysis(\n",
    "#     original_classification,\n",
    "#     vit,\n",
    "#     pipeline_config,\n",
    "#     num_layers_to_analyze=5,\n",
    "#     importance_threshold=0.2,\n",
    "#     cls_token_only=False,  # Set to False to analyze all tokens\n",
    "#     analyze_token_patterns=True,\n",
    "#     pca_components=10,\n",
    "#     n_clusters=5\n",
    "# )\n",
    "\n",
    "# # If you want to examine the results later\n",
    "# if token_patterns:\n",
    "#     for cls_idx, patterns in token_patterns.items():\n",
    "#         print(f\"Class {cls_idx} has {len(patterns['clusters'])} pattern clusters\")\n",
    "        \n",
    "#         # Print the largest cluster's top token activations\n",
    "#         largest_cluster = max(patterns['clusters'], key=lambda x: x['size'])\n",
    "#         print(f\"Largest cluster ({largest_cluster['size']} images):\")\n",
    "#         for l, h, t, v in sorted(largest_cluster['top_activations'], key=lambda x: x[3], reverse=True)[:5]:\n",
    "#             layer_offset = 12 - 5  # Adjust if analyzing different number of layers\n",
    "#             print(f\"  Layer {l+layer_offset}, Head {h}, Token {t}: {v:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691da854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piragi/projects/gradcamfaithtest/gradcamfaith/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 1050 X-ray images\n",
      "Preprocessing complete. 1050 images saved to results/test/preprocessed\n",
      "Found 1050 original images for processing.\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "ViT model loaded, hooks registered, and set to eval mode.\n",
      "Running Classify & Explain for original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying & Explaining (suffix: ''): 100%|██████████| 1050/1050 [01:56<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test/classification_results_originals_explained.csv\n",
      "Evaluate Faithfulness Pipeline\n",
      "Settings - n_trials: 3, nr_runs: 100, subset_size: 224\n",
      "Running estimator: FaithfulnessEstimate\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': True, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'features_in_step': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [01:09,  1.08s/it]                 /home/piragi/projects/gradcamfaithtest/gradcamfaith/.venv/lib/python3.10/site-packages/quantus/helpers/warn.py:257: UserWarning: The settings for perturbing input e.g., 'perturb_func' didn't cause change in input. Reconsider the parameter settings.\n",
      "  warnings.warn(\n",
      "1050it [19:02,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': True, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'features_in_step': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1050it [19:01,  1.09s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': True, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'features_in_step': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1050it [19:01,  1.09s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running estimator: FaithfulnessCorrelation\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x75c8b82c7b70>, 'normalise_func': <function normalise_by_max at 0x75c818a51e10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x75c8145413f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x75c818a52560>, perturb_baseline='black')}\n",
      "\n",
      "FaithfulnessEstimate faithfulness statistics (across 3 trials):\n",
      "  Mean: 0.3493\n",
      "  Median: 0.3758\n",
      "  Count: 1050\n",
      "  Avg trial std: 0.0000 (lower is more stable)\n",
      "\n",
      "FaithfulnessEstimate per-class faithfulness statistics:\n",
      "  Class 2:\n",
      "    Mean: 0.3118\n",
      "    Median: 0.3258\n",
      "    Count: 327\n",
      "    Avg trial std: 0.0000\n",
      "  Class 1:\n",
      "    Mean: 0.3356\n",
      "    Median: 0.3613\n",
      "    Count: 375\n",
      "    Avg trial std: 0.0000\n",
      "  Class 0:\n",
      "    Mean: 0.3993\n",
      "    Median: 0.4545\n",
      "    Count: 348\n",
      "    Avg trial std: 0.0000\n",
      "\n",
      "FaithfulnessCorrelation faithfulness statistics (across 3 trials):\n",
      "  Mean: 0.1658\n",
      "  Median: 0.1680\n",
      "  Count: 1050\n",
      "  Avg trial std: 0.0706 (lower is more stable)\n",
      "\n",
      "FaithfulnessCorrelation per-class faithfulness statistics:\n",
      "  Class 2:\n",
      "    Mean: 0.2390\n",
      "    Median: 0.2376\n",
      "    Count: 327\n",
      "    Avg trial std: 0.0710\n",
      "  Class 1:\n",
      "    Mean: 0.1882\n",
      "    Median: 0.1911\n",
      "    Count: 375\n",
      "    Avg trial std: 0.0683\n",
      "  Class 0:\n",
      "    Mean: 0.0727\n",
      "    Median: 0.0711\n",
      "    Count: 348\n",
      "    Avg trial std: 0.0727\n",
      "Raw scores for FaithfulnessEstimate saved to results/test/faithfulness_scores_FaithfulnessEstimate.npy.npz\n",
      "Raw scores for FaithfulnessCorrelation saved to results/test/faithfulness_scores_FaithfulnessCorrelation.npy.npz\n",
      "Faithfulness statistics saved to results/test/faithfulness_stats.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing dataset: 100%|██████████| 1050/1050 [00:04<00:00, 254.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 205800 perturbed image records.\n",
      "Running Classify ONLY for perturbed images (suffix: '_perturbed')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying dataset (suffix: '_perturbed'): 100%|██████████| 205800/205800 [00:06<00:00, 33349.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test/classification_results_perturbed_classified_only_perturbed.csv\n",
      "Full pipeline finished.\n",
      "compare attributions\n",
      "Building analysis context...\n",
      "Generating perturbation comparison DataFrame for SaCo...\n",
      "Generating perturbation comparison data for SaCo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Perturbations: 100%|██████████| 205800/205800 [00:08<00:00, 23843.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base comparison DataFrame for SaCo saved to results/test/perturbation_comparison_for_saco_perturbed.csv\n",
      "Running core SaCo calculations...\n",
      "Average SaCo score for method 'mean': 0.3866 (over 1050 images)\n",
      "SaCo patch analysis saved to results/test/saco_patch_analysis_mean_perturbed.csv\n",
      "Analyzing key attribution patterns...\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "\n",
      "============================================================\n",
      "OVERALL CORRELATIONS WITH SACO SCORE:\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: Normal\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for Normal:\n",
      "  Total samples: 305\n",
      "  Mean SaCo score: 0.504\n",
      "  Median SaCo score: 0.531\n",
      "  Std SaCo score: 0.167\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: COVID-19\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for COVID-19:\n",
      "  Total samples: 335\n",
      "  Mean SaCo score: 0.302\n",
      "  Median SaCo score: 0.321\n",
      "  Std SaCo score: 0.166\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: Non-COVID\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for Non-COVID:\n",
      "  Total samples: 331\n",
      "  Mean SaCo score: 0.371\n",
      "  Median SaCo score: 0.382\n",
      "  Std SaCo score: 0.189\n",
      "Saving analysis results...\n",
      "Saved perturbation_comparison to results/test/analysis_perturbation_comparison_perturbed.csv\n",
      "Saved saco_scores to results/test/analysis_saco_scores_perturbed.csv\n",
      "Saved patch_metrics to results/test/analysis_patch_metrics_perturbed.csv\n",
      "Saved faithfulness_correctness to results/test/analysis_faithfulness_correctness_perturbed.csv\n",
      "Saved attribution_patterns to results/test/analysis_attribution_patterns_perturbed.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import analysis\n",
    "import config\n",
    "import pipeline as pipe\n",
    "import vit.model as model\n",
    "from head_analysis import run_head_analysis\n",
    "from main import run_saco_from_pipeline_outputs\n",
    "\n",
    "pipeline_config = config.PipelineConfig()\n",
    "pipeline_config.file.use_cached_original = False\n",
    "pipeline_config.file.current_mode = \"test\"\n",
    "pipeline_config.file.weighted = True\n",
    "pipeline_config.classify.analysis = True\n",
    "\n",
    "pipeline_config.classify.data_collection = False\n",
    "\n",
    "original_classification, (\n",
    "    perturbed_image_records, perturbed_classification) = pipe.run_pipeline(\n",
    "        pipeline_config,\n",
    "        source_dir_for_preprocessing=Path(\n",
    "            f\"./COVID-QU-Ex/{pipeline_config.file.current_mode}\"))\n",
    "\n",
    "print(\"compare attributions\")\n",
    "run_saco_from_pipeline_outputs(pipeline_config, original_classification,\n",
    "                                perturbed_image_records,\n",
    "                                perturbed_classification)\n",
    "\n",
    "# vit = model.load_vit_model()\n",
    "# direction_similarities, head_importance, token_patterns = run_head_analysis(\n",
    "#     original_classification,\n",
    "#     vit,\n",
    "#     pipeline_config,\n",
    "#     num_layers_to_analyze=5,\n",
    "#     importance_threshold=0.2,\n",
    "#     cls_token_only=False,  # Set to False to analyze all tokens\n",
    "#     analyze_token_patterns=True,\n",
    "#     pca_components=10,\n",
    "#     n_clusters=5\n",
    "# )\n",
    "\n",
    "# # If you want to examine the results later\n",
    "# if token_patterns:\n",
    "#     for cls_idx, patterns in token_patterns.items():\n",
    "#         print(f\"Class {cls_idx} has {len(patterns['clusters'])} pattern clusters\")\n",
    "        \n",
    "#         # Print the largest cluster's top token activations\n",
    "#         largest_cluster = max(patterns['clusters'], key=lambda x: x['size'])\n",
    "#         print(f\"Largest cluster ({largest_cluster['size']} images):\")\n",
    "#         for l, h, t, v in sorted(largest_cluster['top_activations'], key=lambda x: x[3], reverse=True)[:5]:\n",
    "#             layer_offset = 12 - 5  # Adjust if analyzing different number of layers\n",
    "#             print(f\"  Layer {l+layer_offset}, Head {h}, Token {t}: {v:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piragi/projects/gradcamfaithtest/gradcamfaith/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 700 X-ray images\n",
      "Preprocessing complete. 700 images saved to results/test/preprocessed\n",
      "Found 700 original images for processing.\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "ViT model loaded, hooks registered, and set to eval mode.\n",
      "Running Classify & Explain for original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying & Explaining (suffix: ''): 100%|██████████| 700/700 [00:00<00:00, 5286.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test/classification_results_originals_explained.csv\n",
      "Evaluate Faithfulness Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings - n_trials: 3, nr_runs: 100, subset_size: 224\n",
      "Running estimator: FaithfulnessCorrelation\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x73e5f84bfcb0>, 'normalise_func': <function normalise_by_max at 0x73e55943de10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x73e554f2d3f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x73e55943e560>, perturb_baseline='black')}\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x73e5f84bfcb0>, 'normalise_func': <function normalise_by_max at 0x73e55943de10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x73e554f2d3f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x73e55943e560>, perturb_baseline='black')}\n",
      "{'abs': False, 'normalise': False, 'return_aggregate': False, 'aggregate_func': <function mean at 0x73e5f84bfcb0>, 'normalise_func': <function normalise_by_max at 0x73e55943de10>, '_disable_warnings': False, '_display_progressbar': False, 'a_axes': None, 'similarity_func': <function correlation_pearson at 0x73e554f2d3f0>, 'nr_runs': 100, 'subset_size': 224, 'perturb_func': functools.partial(<function baseline_replacement_by_indices at 0x73e55943e560>, perturb_baseline='black')}\n",
      "\n",
      "FaithfulnessCorrelation faithfulness statistics (across 3 trials):\n",
      "  Mean: 0.2091\n",
      "  Median: 0.2159\n",
      "  Count: 700\n",
      "  Avg trial std: 0.0673 (lower is more stable)\n",
      "\n",
      "FaithfulnessCorrelation per-class faithfulness statistics:\n",
      "  Class 2:\n",
      "    Mean: 0.2452\n",
      "    Median: 0.2438\n",
      "    Count: 317\n",
      "    Avg trial std: 0.0692\n",
      "  Class 1:\n",
      "    Mean: 0.1820\n",
      "    Median: 0.1851\n",
      "    Count: 370\n",
      "    Avg trial std: 0.0664\n",
      "  Class 0:\n",
      "    Mean: 0.1022\n",
      "    Median: 0.0816\n",
      "    Count: 13\n",
      "    Avg trial std: 0.0488\n",
      "Raw scores for FaithfulnessCorrelation saved to results/test/faithfulness_scores_FaithfulnessCorrelation.npy.npz\n",
      "Faithfulness statistics saved to results/test/faithfulness_stats.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing dataset: 100%|██████████| 700/700 [00:02<00:00, 260.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 137200 perturbed image records.\n",
      "Running Classify ONLY for perturbed images (suffix: '_perturbed')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying dataset (suffix: '_perturbed'): 100%|██████████| 137200/137200 [00:05<00:00, 26429.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test/classification_results_perturbed_classified_only_perturbed.csv\n",
      "Full pipeline finished.\n",
      "compare attributions\n",
      "Building analysis context...\n",
      "Generating perturbation comparison DataFrame for SaCo...\n",
      "Generating perturbation comparison data for SaCo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Perturbations: 100%|██████████| 137200/137200 [00:05<00:00, 23657.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base comparison DataFrame for SaCo saved to results/test/perturbation_comparison_for_saco_perturbed.csv\n",
      "Running core SaCo calculations...\n",
      "Average SaCo score for method 'mean': 0.4304 (over 700 images)\n",
      "SaCo patch analysis saved to results/test/saco_patch_analysis_mean_perturbed.csv\n",
      "Analyzing key attribution patterns...\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "\n",
      "============================================================\n",
      "OVERALL CORRELATIONS WITH SACO SCORE:\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: Normal\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for Normal:\n",
      "  Total samples: 305\n",
      "  Mean SaCo score: 0.504\n",
      "  Median SaCo score: 0.531\n",
      "  Std SaCo score: 0.167\n",
      "\n",
      "------------------------------------------------------------\n",
      "CORRELATIONS FOR CLASS: Non-COVID\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary for Non-COVID:\n",
      "  Total samples: 331\n",
      "  Mean SaCo score: 0.371\n",
      "  Median SaCo score: 0.382\n",
      "  Std SaCo score: 0.189\n",
      "Saving analysis results...\n",
      "Saved perturbation_comparison to results/test/analysis_perturbation_comparison_perturbed.csv\n",
      "Saved saco_scores to results/test/analysis_saco_scores_perturbed.csv\n",
      "Saved patch_metrics to results/test/analysis_patch_metrics_perturbed.csv\n",
      "Saved faithfulness_correctness to results/test/analysis_faithfulness_correctness_perturbed.csv\n",
      "Saved attribution_patterns to results/test/analysis_attribution_patterns_perturbed.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import analysis\n",
    "import config\n",
    "import pipeline as pipe\n",
    "import vit.model as model\n",
    "from head_analysis import run_head_analysis\n",
    "from main import run_saco_from_pipeline_outputs\n",
    "\n",
    "pipeline_config = config.PipelineConfig()\n",
    "pipeline_config.file.use_cached_original = True\n",
    "pipeline_config.file.current_mode = \"test\"\n",
    "pipeline_config.file.weighted = False\n",
    "pipeline_config.classify.analysis = True\n",
    "\n",
    "pipeline_config.classify.data_collection = False\n",
    "\n",
    "original_classification, (\n",
    "    perturbed_image_records, perturbed_classification) = pipe.run_pipeline(\n",
    "        pipeline_config,\n",
    "        source_dir_for_preprocessing=Path(\n",
    "            f\"./COVID-QU-Ex/{pipeline_config.file.current_mode}\"))\n",
    "\n",
    "print(\"compare attributions\")\n",
    "run_saco_from_pipeline_outputs(pipeline_config, original_classification,\n",
    "                                perturbed_image_records,\n",
    "                                perturbed_classification)\n",
    "\n",
    "# vit = model.load_vit_model()\n",
    "# direction_similarities, head_importance, token_patterns = run_head_analysis(\n",
    "#     original_classification,\n",
    "#     vit,\n",
    "#     pipeline_config,\n",
    "#     num_layers_to_analyze=5,\n",
    "#     importance_threshold=0.2,\n",
    "#     cls_token_only=False,  # Set to False to analyze all tokens\n",
    "#     analyze_token_patterns=True,\n",
    "#     pca_components=10,\n",
    "#     n_clusters=5\n",
    "# )\n",
    "\n",
    "# # If you want to examine the results later\n",
    "# if token_patterns:\n",
    "#     for cls_idx, patterns in token_patterns.items():\n",
    "#         print(f\"Class {cls_idx} has {len(patterns['clusters'])} pattern clusters\")\n",
    "        \n",
    "#         # Print the largest cluster's top token activations\n",
    "#         largest_cluster = max(patterns['clusters'], key=lambda x: x['size'])\n",
    "#         print(f\"Largest cluster ({largest_cluster['size']} images):\")\n",
    "#         for l, h, t, v in sorted(largest_cluster['top_activations'], key=lambda x: x[3], reverse=True)[:5]:\n",
    "#             layer_offset = 12 - 5  # Adjust if analyzing different number of layers\n",
    "#             print(f\"  Layer {l+layer_offset}, Head {h}, Token {t}: {v:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c53b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e719b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piragi/projects/gradcamfaithtest/gradcamfaith/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 700 X-ray images\n",
      "Preprocessing complete. 700 images saved to results/test/preprocessed\n",
      "Found 700 original images for processing.\n",
      "Loading weights from ./model/model_best.pth.tar\n",
      "ViT model loaded, hooks registered, and set to eval mode.\n",
      "Running Classify & Explain for original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying & Explaining (suffix: ''): 100%|██████████| 700/700 [00:00<00:00, 39120.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/test_weighted/classification_results_originals_explained.csv\n",
      "Evaluate Faithfulness Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import analysis\n",
    "import config\n",
    "import pipeline as pipe\n",
    "import vit.model as model\n",
    "from head_analysis import run_head_analysis\n",
    "from main import run_saco_from_pipeline_outputs\n",
    "\n",
    "pipeline_config = config.PipelineConfig()\n",
    "pipeline_config.file.use_cached_original = True\n",
    "pipeline_config.file.current_mode = \"test\"\n",
    "pipeline_config.file.weighted = True\n",
    "pipeline_config.classify.analysis = True\n",
    "\n",
    "pipeline_config.classify.data_collection = False\n",
    "\n",
    "original_classification, (\n",
    "    perturbed_image_records, perturbed_classification) = pipe.run_pipeline(\n",
    "        pipeline_config,\n",
    "        source_dir_for_preprocessing=Path(\n",
    "            f\"./COVID-QU-Ex/{pipeline_config.file.current_mode}\"))\n",
    "\n",
    "print(\"compare attributions\")\n",
    "run_saco_from_pipeline_outputs(pipeline_config, original_classification,\n",
    "                                perturbed_image_records,\n",
    "                                perturbed_classification)\n",
    "\n",
    "# vit = model.load_vit_model()\n",
    "# direction_similarities, head_importance, token_patterns = run_head_analysis(\n",
    "#     original_classification,\n",
    "#     vit,\n",
    "#     pipeline_config,\n",
    "#     num_layers_to_analyze=5,\n",
    "#     importance_threshold=0.2,\n",
    "#     cls_token_only=False,  # Set to False to analyze all tokens\n",
    "#     analyze_token_patterns=True,\n",
    "#     pca_components=10,\n",
    "#     n_clusters=5\n",
    "# )\n",
    "\n",
    "# # If you want to examine the results later\n",
    "# if token_patterns:\n",
    "#     for cls_idx, patterns in token_patterns.items():\n",
    "#         print(f\"Class {cls_idx} has {len(patterns['clusters'])} pattern clusters\")\n",
    "        \n",
    "#         # Print the largest cluster's top token activations\n",
    "#         largest_cluster = max(patterns['clusters'], key=lambda x: x['size'])\n",
    "#         print(f\"Largest cluster ({largest_cluster['size']} images):\")\n",
    "#         for l, h, t, v in sorted(largest_cluster['top_activations'], key=lambda x: x[3], reverse=True)[:5]:\n",
    "#             layer_offset = 12 - 5  # Adjust if analyzing different number of layers\n",
    "#             print(f\"  Layer {l+layer_offset}, Head {h}, Token {t}: {v:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cde51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_patterns(token_patterns, num_layers_to_analyze=5, model_n_layers=12, top_k=5):\n",
    "    \"\"\"\n",
    "    Print detailed information about token activation patterns for all classes.\n",
    "    \n",
    "    Args:\n",
    "        token_patterns: The token patterns dictionary returned by run_head_analysis\n",
    "        num_layers_to_analyze: Number of layers analyzed\n",
    "        model_n_layers: Total number of layers in the model\n",
    "        top_k: Number of top activations to print per cluster\n",
    "    \"\"\"\n",
    "    if not token_patterns:\n",
    "        print(\"No token patterns to display.\")\n",
    "        return\n",
    "    \n",
    "    layer_offset = model_n_layers - num_layers_to_analyze\n",
    "    \n",
    "    for cls_idx, patterns in token_patterns.items():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"CLASS {cls_idx} TOKEN ACTIVATION PATTERNS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total images analyzed: {patterns['n_images']}\")\n",
    "        print(f\"Number of clusters: {len(patterns['clusters'])}\")\n",
    "        print(f\"PCA explained variance: {sum(patterns['explained_variance']):.4f}\")\n",
    "        \n",
    "        for i, cluster in enumerate(patterns['clusters']):\n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "            print(f\"CLUSTER {i+1} ({cluster['size']} images, {cluster['percentage']*100:.1f}%)\")\n",
    "            print(\"-\"*50)\n",
    "            \n",
    "            print(\"Example images:\")\n",
    "            print(\"  \" + \", \".join(cluster['image_examples']))\n",
    "            \n",
    "            print(\"\\nTop token activations (Layer, Head, Token, Value):\")\n",
    "            for l, h, t, v in sorted(cluster['top_activations'], key=lambda x: x[3], reverse=True)[:top_k]:\n",
    "                actual_layer = l + layer_offset\n",
    "                print(f\"  Layer {actual_layer}, Head {h}, Token {t}: {v:.5f}\")\n",
    "                \n",
    "            # Optional: Include CLS token specifically if it's in top activations\n",
    "            cls_activations = [act for act in cluster['top_activations'] if act[2] == 0]  # Token 0 is CLS\n",
    "            if cls_activations:\n",
    "                print(\"\\nCLS token activations:\")\n",
    "                for l, h, t, v in sorted(cls_activations, key=lambda x: x[3], reverse=True)[:3]:\n",
    "                    actual_layer = l + layer_offset\n",
    "                    print(f\"  Layer {actual_layer}, Head {h}: {v:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43eef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def plot_image(image_path):\n",
    "  plt.figure()\n",
    "  plt.axis('off')\n",
    "  image = Image.open(image_path) \n",
    "  plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9daba9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASS 0 TOKEN ACTIVATION PATTERNS\n",
      "============================================================\n",
      "Total images analyzed: 1014\n",
      "Number of clusters: 5\n",
      "PCA explained variance: 0.5404\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 1 (263 images, 25.9%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  covid_706, covid_192, covid_490, covid_1380, covid_878\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 6, Token 0: 0.34098\n",
      "  Layer 9, Head 6, Token 17: 0.34057\n",
      "  Layer 9, Head 6, Token 57: 0.34057\n",
      "  Layer 9, Head 6, Token 65: 0.34048\n",
      "  Layer 9, Head 6, Token 80: 0.34041\n",
      "  Layer 9, Head 6, Token 23: 0.34037\n",
      "  Layer 9, Head 6, Token 13: 0.34034\n",
      "  Layer 9, Head 6, Token 63: 0.34024\n",
      "  Layer 9, Head 6, Token 22: 0.34013\n",
      "  Layer 9, Head 6, Token 26: 0.34011\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 6: 0.34098\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 2 (85 images, 8.4%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  covid_228, covid_852, covid_838, covid_445, covid_245\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 6, Token 0: 0.21737\n",
      "  Layer 9, Head 6, Token 44: 0.21115\n",
      "  Layer 9, Head 6, Token 41: 0.21091\n",
      "  Layer 9, Head 6, Token 30: 0.21074\n",
      "  Layer 9, Head 6, Token 58: 0.21066\n",
      "  Layer 9, Head 6, Token 31: 0.21014\n",
      "  Layer 9, Head 6, Token 69: 0.20956\n",
      "  Layer 9, Head 6, Token 49: 0.20923\n",
      "  Layer 9, Head 6, Token 72: 0.20900\n",
      "  Layer 9, Head 6, Token 34: 0.20890\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 6: 0.21737\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 3 (228 images, 22.5%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  covid_586, covid_1203, covid_395, covid_903, covid_967\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 6, Token 78: 0.32151\n",
      "  Layer 9, Head 6, Token 63: 0.32118\n",
      "  Layer 9, Head 6, Token 77: 0.32107\n",
      "  Layer 9, Head 6, Token 50: 0.32096\n",
      "  Layer 9, Head 6, Token 184: 0.32096\n",
      "  Layer 9, Head 6, Token 64: 0.32095\n",
      "  Layer 9, Head 6, Token 0: 0.32092\n",
      "  Layer 9, Head 6, Token 49: 0.32068\n",
      "  Layer 9, Head 6, Token 9: 0.32035\n",
      "  Layer 9, Head 6, Token 10: 0.32026\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 6: 0.32092\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 4 (262 images, 25.8%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  covid_401, covid_866, covid_1520, covid_777, covid_1408\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 6, Token 0: 0.33418\n",
      "  Layer 9, Head 6, Token 82: 0.33278\n",
      "  Layer 9, Head 6, Token 65: 0.33264\n",
      "  Layer 9, Head 6, Token 68: 0.33263\n",
      "  Layer 9, Head 6, Token 74: 0.33258\n",
      "  Layer 9, Head 6, Token 69: 0.33257\n",
      "  Layer 9, Head 6, Token 46: 0.33245\n",
      "  Layer 9, Head 6, Token 62: 0.33239\n",
      "  Layer 9, Head 6, Token 81: 0.33235\n",
      "  Layer 9, Head 6, Token 52: 0.33234\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 6: 0.33418\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 5 (176 images, 17.4%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  covid_272, covid_1213, covid_290, covid_705, covid_800\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 6, Token 0: 0.27914\n",
      "  Layer 9, Head 6, Token 69: 0.27465\n",
      "  Layer 9, Head 6, Token 44: 0.27405\n",
      "  Layer 9, Head 6, Token 20: 0.27381\n",
      "  Layer 9, Head 6, Token 58: 0.27350\n",
      "  Layer 9, Head 6, Token 25: 0.27334\n",
      "  Layer 9, Head 6, Token 30: 0.27330\n",
      "  Layer 9, Head 6, Token 31: 0.27317\n",
      "  Layer 9, Head 6, Token 24: 0.27312\n",
      "  Layer 9, Head 6, Token 45: 0.27312\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 6: 0.27914\n",
      "\n",
      "============================================================\n",
      "CLASS 1 TOKEN ACTIVATION PATTERNS\n",
      "============================================================\n",
      "Total images analyzed: 933\n",
      "Number of clusters: 5\n",
      "PCA explained variance: 0.6019\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 1 (232 images, 24.9%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  non_COVID (227), non_COVID (963), non_COVID (959), non_COVID (1033), non_COVID (123)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 0, Token 0: 0.30956\n",
      "  Layer 9, Head 0, Token 181: 0.30740\n",
      "  Layer 9, Head 0, Token 182: 0.30690\n",
      "  Layer 9, Head 0, Token 194: 0.30658\n",
      "  Layer 9, Head 0, Token 184: 0.30634\n",
      "  Layer 9, Head 0, Token 195: 0.30593\n",
      "  Layer 9, Head 0, Token 167: 0.30578\n",
      "  Layer 9, Head 0, Token 141: 0.30441\n",
      "  Layer 9, Head 0, Token 154: 0.30439\n",
      "  Layer 9, Head 0, Token 168: 0.30434\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 0: 0.30956\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 2 (165 images, 17.7%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  non_COVID (839), non_COVID (951), non_COVID (372), non_COVID (230), Normal (1578)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 11, Head 6, Token 73: 0.16169\n",
      "  Layer 11, Head 6, Token 87: 0.16155\n",
      "  Layer 11, Head 6, Token 88: 0.16130\n",
      "  Layer 11, Head 6, Token 101: 0.16080\n",
      "  Layer 11, Head 6, Token 0: 0.16045\n",
      "  Layer 11, Head 6, Token 82: 0.16013\n",
      "  Layer 11, Head 6, Token 74: 0.16010\n",
      "  Layer 11, Head 6, Token 60: 0.15996\n",
      "  Layer 11, Head 6, Token 81: 0.15983\n",
      "  Layer 11, Head 6, Token 96: 0.15971\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 11, Head 6: 0.16045\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 3 (248 images, 26.6%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  non_COVID (529), non_COVID (896), non_COVID (428), non_COVID (1016), non_COVID (164)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 0, Token 0: 0.30419\n",
      "  Layer 9, Head 0, Token 61: 0.29953\n",
      "  Layer 9, Head 0, Token 75: 0.29937\n",
      "  Layer 9, Head 0, Token 73: 0.29895\n",
      "  Layer 9, Head 0, Token 74: 0.29839\n",
      "  Layer 9, Head 0, Token 60: 0.29835\n",
      "  Layer 9, Head 0, Token 76: 0.29809\n",
      "  Layer 9, Head 0, Token 62: 0.29752\n",
      "  Layer 9, Head 0, Token 47: 0.29749\n",
      "  Layer 9, Head 0, Token 59: 0.29728\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 0: 0.30419\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 4 (140 images, 15.0%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  non_COVID (1020), non_COVID (846), non_COVID (806), non_COVID (1074), non_COVID (1054)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 8, Head 9, Token 0: 0.24213\n",
      "  Layer 8, Head 9, Token 78: 0.23481\n",
      "  Layer 8, Head 9, Token 64: 0.23401\n",
      "  Layer 8, Head 9, Token 63: 0.23184\n",
      "  Layer 8, Head 9, Token 77: 0.22905\n",
      "  Layer 8, Head 9, Token 50: 0.22729\n",
      "  Layer 8, Head 9, Token 65: 0.22724\n",
      "  Layer 8, Head 9, Token 49: 0.22669\n",
      "  Layer 8, Head 9, Token 79: 0.22647\n",
      "  Layer 8, Head 9, Token 51: 0.22622\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 8, Head 9: 0.24213\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 5 (148 images, 15.9%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  non_COVID (280), non_COVID (211), non_COVID (235), non_COVID (1036), non_COVID (38)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 8, Head 9, Token 0: 0.32380\n",
      "  Layer 8, Head 9, Token 78: 0.32176\n",
      "  Layer 8, Head 9, Token 64: 0.31998\n",
      "  Layer 8, Head 9, Token 63: 0.31651\n",
      "  Layer 8, Head 9, Token 77: 0.31469\n",
      "  Layer 8, Head 9, Token 92: 0.31419\n",
      "  Layer 8, Head 9, Token 50: 0.31180\n",
      "  Layer 8, Head 9, Token 49: 0.30982\n",
      "  Layer 8, Head 9, Token 91: 0.30959\n",
      "  Layer 8, Head 9, Token 20: 0.30918\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 8, Head 9: 0.32380\n",
      "\n",
      "============================================================\n",
      "CLASS 2 TOKEN ACTIVATION PATTERNS\n",
      "============================================================\n",
      "Total images analyzed: 1053\n",
      "Number of clusters: 5\n",
      "PCA explained variance: 0.6435\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 1 (193 images, 18.3%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  Normal (1979), Normal (1898), Normal (2377), Normal (1873), Normal (2167)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 11, Head 2, Token 187: 0.15667\n",
      "  Layer 11, Head 2, Token 186: 0.15627\n",
      "  Layer 11, Head 2, Token 188: 0.15595\n",
      "  Layer 11, Head 2, Token 193: 0.15585\n",
      "  Layer 11, Head 2, Token 196: 0.15573\n",
      "  Layer 11, Head 2, Token 14: 0.15568\n",
      "  Layer 11, Head 2, Token 189: 0.15562\n",
      "  Layer 11, Head 2, Token 176: 0.15557\n",
      "  Layer 11, Head 2, Token 175: 0.15556\n",
      "  Layer 11, Head 2, Token 184: 0.15554\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 2 (182 images, 17.3%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  Normal (2240), Normal (1713), Normal (1502), non_COVID (818), Normal (1736)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 9, Head 2, Token 84: 0.25047\n",
      "  Layer 9, Head 2, Token 57: 0.25026\n",
      "  Layer 9, Head 2, Token 98: 0.25011\n",
      "  Layer 9, Head 2, Token 30: 0.25009\n",
      "  Layer 9, Head 2, Token 43: 0.24951\n",
      "  Layer 9, Head 2, Token 70: 0.24951\n",
      "  Layer 9, Head 2, Token 72: 0.24947\n",
      "  Layer 9, Head 2, Token 71: 0.24905\n",
      "  Layer 9, Head 2, Token 86: 0.24886\n",
      "  Layer 9, Head 2, Token 85: 0.24885\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 9, Head 2: 0.24811\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 3 (72 images, 6.8%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  Normal (1835), Normal (1626), Normal (1953), Normal (2185), Normal (2142)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 8, Head 1, Token 68: 0.20555\n",
      "  Layer 8, Head 1, Token 82: 0.20539\n",
      "  Layer 8, Head 1, Token 96: 0.20416\n",
      "  Layer 8, Head 1, Token 54: 0.20270\n",
      "  Layer 8, Head 1, Token 97: 0.20254\n",
      "  Layer 8, Head 1, Token 111: 0.20249\n",
      "  Layer 8, Head 1, Token 87: 0.20211\n",
      "  Layer 8, Head 1, Token 53: 0.20182\n",
      "  Layer 8, Head 1, Token 101: 0.20147\n",
      "  Layer 8, Head 1, Token 74: 0.20115\n",
      "\n",
      "CLS token activations:\n",
      "  Layer 8, Head 1: 0.20072\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 4 (248 images, 23.6%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  Normal (2127), Normal (1565), Normal (1987), non_COVID (946), Normal (1994)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 8, Head 9, Token 8: 0.24152\n",
      "  Layer 8, Head 9, Token 7: 0.23525\n",
      "  Layer 8, Head 9, Token 22: 0.23301\n",
      "  Layer 8, Head 9, Token 21: 0.22864\n",
      "  Layer 8, Head 9, Token 9: 0.22609\n",
      "  Layer 8, Head 9, Token 36: 0.22381\n",
      "  Layer 8, Head 9, Token 35: 0.21973\n",
      "  Layer 8, Head 9, Token 50: 0.21934\n",
      "  Layer 8, Head 9, Token 64: 0.21770\n",
      "  Layer 8, Head 9, Token 23: 0.21740\n",
      "\n",
      "--------------------------------------------------\n",
      "CLUSTER 5 (358 images, 34.0%)\n",
      "--------------------------------------------------\n",
      "Example images:\n",
      "  Normal (1617), Normal (2151), Normal (1605), Normal (1776), Normal (2398)\n",
      "\n",
      "Top token activations (Layer, Head, Token, Value):\n",
      "  Layer 8, Head 9, Token 8: 0.33353\n",
      "  Layer 8, Head 9, Token 22: 0.33220\n",
      "  Layer 8, Head 9, Token 7: 0.33155\n",
      "  Layer 8, Head 9, Token 21: 0.33057\n",
      "  Layer 8, Head 9, Token 36: 0.33021\n",
      "  Layer 8, Head 9, Token 50: 0.32779\n",
      "  Layer 8, Head 9, Token 35: 0.32605\n",
      "  Layer 8, Head 9, Token 64: 0.32578\n",
      "  Layer 8, Head 9, Token 9: 0.32561\n",
      "  Layer 8, Head 9, Token 42: 0.32540\n"
     ]
    }
   ],
   "source": [
    "# Print detailed information about all clusters for all classes\n",
    "print_token_patterns(\n",
    "    token_patterns, \n",
    "    num_layers_to_analyze=5,\n",
    "    model_n_layers=12,\n",
    "    top_k=10  # Show top 10 activations per cluster\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37f597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41244c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from ./model/model_best.pth.tar\n",
      "logits = [[-0.09883571  5.5317917  -5.282995  ]]\n",
      "class vector of predicted = (768,)\n",
      "--- Layer: 0\n",
      "Head: 0\n",
      "  Raw Dot 1: -0.1392 | Cosine Sim 1: -0.0762\n",
      "  Raw Dot 2: 0.0103 | Cosine Sim 2: 0.0063\n",
      "  Raw Dot 3: -0.0624 | Cosine Sim 3: -0.0299\n",
      "Head: 1\n",
      "  Raw Dot 1: 0.4258 | Cosine Sim 1: 0.0390\n",
      "  Raw Dot 2: 2.2314 | Cosine Sim 2: 0.2298\n",
      "  Raw Dot 3: 1.9726 | Cosine Sim 3: 0.1581\n",
      "Head: 2\n",
      "  Raw Dot 1: 1.2653 | Cosine Sim 1: 0.1309\n",
      "  Raw Dot 2: 1.8071 | Cosine Sim 2: 0.2100\n",
      "  Raw Dot 3: 2.0173 | Cosine Sim 3: 0.1824\n",
      "Head: 3\n",
      "  Raw Dot 1: 1.3346 | Cosine Sim 1: 0.1069\n",
      "  Raw Dot 2: 0.8791 | Cosine Sim 2: 0.0791\n",
      "  Raw Dot 3: 1.2113 | Cosine Sim 3: 0.0848\n",
      "Head: 4\n",
      "  Raw Dot 1: -0.5764 | Cosine Sim 1: -0.1440\n",
      "  Raw Dot 2: 0.2228 | Cosine Sim 2: 0.0625\n",
      "  Raw Dot 3: -0.2168 | Cosine Sim 3: -0.0473\n",
      "Head: 5\n",
      "  Raw Dot 1: -0.4257 | Cosine Sim 1: -0.1176\n",
      "  Raw Dot 2: 0.1113 | Cosine Sim 2: 0.0345\n",
      "  Raw Dot 3: -0.1477 | Cosine Sim 3: -0.0357\n",
      "Head: 6\n",
      "  Raw Dot 1: 1.1476 | Cosine Sim 1: 0.1072\n",
      "  Raw Dot 2: 1.9021 | Cosine Sim 2: 0.1996\n",
      "  Raw Dot 3: 2.1499 | Cosine Sim 3: 0.1756\n",
      "Head: 7\n",
      "  Raw Dot 1: 0.0118 | Cosine Sim 1: 0.0079\n",
      "  Raw Dot 2: 0.0518 | Cosine Sim 2: 0.0391\n",
      "  Raw Dot 3: 0.0303 | Cosine Sim 3: 0.0178\n",
      "Head: 8\n",
      "  Raw Dot 1: 0.2585 | Cosine Sim 1: 0.0777\n",
      "  Raw Dot 2: -0.0864 | Cosine Sim 2: -0.0292\n",
      "  Raw Dot 3: 0.1507 | Cosine Sim 3: 0.0396\n",
      "Head: 9\n",
      "  Raw Dot 1: -0.1093 | Cosine Sim 1: -0.0432\n",
      "  Raw Dot 2: -0.0829 | Cosine Sim 2: -0.0368\n",
      "  Raw Dot 3: -0.0657 | Cosine Sim 3: -0.0227\n",
      "Head: 10\n",
      "  Raw Dot 1: 0.0015 | Cosine Sim 1: 0.0003\n",
      "  Raw Dot 2: 0.4940 | Cosine Sim 2: 0.1287\n",
      "  Raw Dot 3: 0.3135 | Cosine Sim 3: 0.0636\n",
      "Head: 11\n",
      "  Raw Dot 1: -0.0808 | Cosine Sim 1: -0.0241\n",
      "  Raw Dot 2: 0.0456 | Cosine Sim 2: 0.0153\n",
      "  Raw Dot 3: -0.0108 | Cosine Sim 3: -0.0028\n",
      "--- Layer: 1\n",
      "Head: 0\n",
      "  Raw Dot 1: -0.0775 | Cosine Sim 1: -0.0278\n",
      "  Raw Dot 2: -0.0666 | Cosine Sim 2: -0.0269\n",
      "  Raw Dot 3: -0.0364 | Cosine Sim 3: -0.0114\n",
      "Head: 1\n",
      "  Raw Dot 1: 3.0872 | Cosine Sim 1: 0.1651\n",
      "  Raw Dot 2: 4.9900 | Cosine Sim 2: 0.2997\n",
      "  Raw Dot 3: 5.7222 | Cosine Sim 3: 0.2675\n",
      "Head: 2\n",
      "  Raw Dot 1: 0.2515 | Cosine Sim 1: 0.0597\n",
      "  Raw Dot 2: 0.4718 | Cosine Sim 2: 0.1258\n",
      "  Raw Dot 3: 0.4485 | Cosine Sim 3: 0.0931\n",
      "Head: 3\n",
      "  Raw Dot 1: 0.2794 | Cosine Sim 1: 0.0335\n",
      "  Raw Dot 2: 0.5083 | Cosine Sim 2: 0.0684\n",
      "  Raw Dot 3: 0.5744 | Cosine Sim 3: 0.0602\n",
      "Head: 4\n",
      "  Raw Dot 1: -0.0909 | Cosine Sim 1: -0.0356\n",
      "  Raw Dot 2: 0.0614 | Cosine Sim 2: 0.0270\n",
      "  Raw Dot 3: 0.0352 | Cosine Sim 3: 0.0121\n",
      "Head: 5\n",
      "  Raw Dot 1: -0.0375 | Cosine Sim 1: -0.0042\n",
      "  Raw Dot 2: 1.1153 | Cosine Sim 2: 0.1396\n",
      "  Raw Dot 3: 0.6255 | Cosine Sim 3: 0.0609\n",
      "Head: 6\n",
      "  Raw Dot 1: 0.7228 | Cosine Sim 1: 0.0620\n",
      "  Raw Dot 2: 0.9393 | Cosine Sim 2: 0.0905\n",
      "  Raw Dot 3: 1.0930 | Cosine Sim 3: 0.0819\n",
      "Head: 7\n",
      "  Raw Dot 1: 0.0712 | Cosine Sim 1: 0.0208\n",
      "  Raw Dot 2: -0.0525 | Cosine Sim 2: -0.0172\n",
      "  Raw Dot 3: 0.0850 | Cosine Sim 3: 0.0217\n",
      "Head: 8\n",
      "  Raw Dot 1: 0.0736 | Cosine Sim 1: 0.0269\n",
      "  Raw Dot 2: 0.0056 | Cosine Sim 2: 0.0023\n",
      "  Raw Dot 3: 0.0996 | Cosine Sim 3: 0.0318\n",
      "Head: 9\n",
      "  Raw Dot 1: 1.9993 | Cosine Sim 1: 0.0892\n",
      "  Raw Dot 2: 9.4525 | Cosine Sim 2: 0.4737\n",
      "  Raw Dot 3: 7.7287 | Cosine Sim 3: 0.3015\n",
      "Head: 10\n",
      "  Raw Dot 1: 3.1014 | Cosine Sim 1: 0.2086\n",
      "  Raw Dot 2: 0.3760 | Cosine Sim 2: 0.0284\n",
      "  Raw Dot 3: 2.6990 | Cosine Sim 3: 0.1586\n",
      "Head: 11\n",
      "  Raw Dot 1: -0.1119 | Cosine Sim 1: -0.0454\n",
      "  Raw Dot 2: -0.0412 | Cosine Sim 2: -0.0188\n",
      "  Raw Dot 3: -0.0369 | Cosine Sim 3: -0.0131\n",
      "--- Layer: 2\n",
      "Head: 0\n",
      "  Raw Dot 1: 6.1365 | Cosine Sim 1: 0.2188\n",
      "  Raw Dot 2: 9.0708 | Cosine Sim 2: 0.3631\n",
      "  Raw Dot 3: 10.7043 | Cosine Sim 3: 0.3335\n",
      "Head: 1\n",
      "  Raw Dot 1: -0.1228 | Cosine Sim 1: -0.0367\n",
      "  Raw Dot 2: -0.1545 | Cosine Sim 2: -0.0519\n",
      "  Raw Dot 3: -0.1378 | Cosine Sim 3: -0.0360\n",
      "Head: 2\n",
      "  Raw Dot 1: -1.0794 | Cosine Sim 1: -0.0550\n",
      "  Raw Dot 2: 4.6053 | Cosine Sim 2: 0.2635\n",
      "  Raw Dot 3: 2.5383 | Cosine Sim 3: 0.1130\n",
      "Head: 3\n",
      "  Raw Dot 1: -0.1820 | Cosine Sim 1: -0.0413\n",
      "  Raw Dot 2: -0.2162 | Cosine Sim 2: -0.0551\n",
      "  Raw Dot 3: -0.1733 | Cosine Sim 3: -0.0344\n",
      "Head: 4\n",
      "  Raw Dot 1: 0.0250 | Cosine Sim 1: 0.0074\n",
      "  Raw Dot 2: 0.0025 | Cosine Sim 2: 0.0008\n",
      "  Raw Dot 3: 0.0700 | Cosine Sim 3: 0.0181\n",
      "Head: 5\n",
      "  Raw Dot 1: 0.4711 | Cosine Sim 1: 0.0721\n",
      "  Raw Dot 2: 0.7463 | Cosine Sim 2: 0.1283\n",
      "  Raw Dot 3: 0.7522 | Cosine Sim 3: 0.1007\n",
      "Head: 6\n",
      "  Raw Dot 1: -0.2908 | Cosine Sim 1: -0.0355\n",
      "  Raw Dot 2: 0.6404 | Cosine Sim 2: 0.0878\n",
      "  Raw Dot 3: 0.3147 | Cosine Sim 3: 0.0336\n",
      "Head: 7\n",
      "  Raw Dot 1: -0.1225 | Cosine Sim 1: -0.0371\n",
      "  Raw Dot 2: 0.0269 | Cosine Sim 2: 0.0092\n",
      "  Raw Dot 3: -0.0110 | Cosine Sim 3: -0.0029\n",
      "Head: 8\n",
      "  Raw Dot 1: -0.1256 | Cosine Sim 1: -0.0248\n",
      "  Raw Dot 2: -0.1516 | Cosine Sim 2: -0.0335\n",
      "  Raw Dot 3: -0.0383 | Cosine Sim 3: -0.0066\n",
      "Head: 9\n",
      "  Raw Dot 1: 2.3858 | Cosine Sim 1: 0.1467\n",
      "  Raw Dot 2: 3.9179 | Cosine Sim 2: 0.2705\n",
      "  Raw Dot 3: 4.0586 | Cosine Sim 3: 0.2181\n",
      "Head: 10\n",
      "  Raw Dot 1: 2.6065 | Cosine Sim 1: 0.1114\n",
      "  Raw Dot 2: 5.1313 | Cosine Sim 2: 0.2463\n",
      "  Raw Dot 3: 4.5935 | Cosine Sim 3: 0.1716\n",
      "Head: 11\n",
      "  Raw Dot 1: 0.0540 | Cosine Sim 1: 0.0165\n",
      "  Raw Dot 2: -0.0233 | Cosine Sim 2: -0.0080\n",
      "  Raw Dot 3: 0.0707 | Cosine Sim 3: 0.0188\n",
      "--- Layer: 3\n",
      "Head: 0\n",
      "  Raw Dot 1: 0.0635 | Cosine Sim 1: 0.0118\n",
      "  Raw Dot 2: -0.0989 | Cosine Sim 2: -0.0207\n",
      "  Raw Dot 3: 0.0248 | Cosine Sim 3: 0.0040\n",
      "Head: 1\n",
      "  Raw Dot 1: -0.1262 | Cosine Sim 1: -0.0184\n",
      "  Raw Dot 2: 0.1280 | Cosine Sim 2: 0.0209\n",
      "  Raw Dot 3: 0.0662 | Cosine Sim 3: 0.0084\n",
      "Head: 2\n",
      "  Raw Dot 1: 0.0369 | Cosine Sim 1: 0.0090\n",
      "  Raw Dot 2: 0.1348 | Cosine Sim 2: 0.0370\n",
      "  Raw Dot 3: 0.1727 | Cosine Sim 3: 0.0369\n",
      "Head: 3\n",
      "  Raw Dot 1: 0.0445 | Cosine Sim 1: 0.0116\n",
      "  Raw Dot 2: 0.2983 | Cosine Sim 2: 0.0876\n",
      "  Raw Dot 3: 0.2464 | Cosine Sim 3: 0.0563\n",
      "Head: 4\n",
      "  Raw Dot 1: -0.2344 | Cosine Sim 1: -0.0559\n",
      "  Raw Dot 2: -0.1435 | Cosine Sim 2: -0.0384\n",
      "  Raw Dot 3: -0.2003 | Cosine Sim 3: -0.0418\n",
      "Head: 5\n",
      "  Raw Dot 1: -0.0712 | Cosine Sim 1: -0.0200\n",
      "  Raw Dot 2: -0.0166 | Cosine Sim 2: -0.0053\n",
      "  Raw Dot 3: 0.0106 | Cosine Sim 3: 0.0026\n",
      "Head: 6\n",
      "  Raw Dot 1: -0.0606 | Cosine Sim 1: -0.0034\n",
      "  Raw Dot 2: 2.7782 | Cosine Sim 2: 0.1752\n",
      "  Raw Dot 3: 1.8779 | Cosine Sim 3: 0.0922\n",
      "Head: 7\n",
      "  Raw Dot 1: -0.1815 | Cosine Sim 1: -0.0526\n",
      "  Raw Dot 2: -0.0700 | Cosine Sim 2: -0.0228\n",
      "  Raw Dot 3: -0.0886 | Cosine Sim 3: -0.0224\n",
      "Head: 8\n",
      "  Raw Dot 1: 0.0070 | Cosine Sim 1: 0.0020\n",
      "  Raw Dot 2: 0.0382 | Cosine Sim 2: 0.0125\n",
      "  Raw Dot 3: 0.0576 | Cosine Sim 3: 0.0147\n",
      "Head: 9\n",
      "  Raw Dot 1: -1.1264 | Cosine Sim 1: -0.0987\n",
      "  Raw Dot 2: 0.2109 | Cosine Sim 2: 0.0208\n",
      "  Raw Dot 3: -0.5750 | Cosine Sim 3: -0.0441\n",
      "Head: 10\n",
      "  Raw Dot 1: 2.0689 | Cosine Sim 1: 0.1004\n",
      "  Raw Dot 2: 2.8854 | Cosine Sim 2: 0.1573\n",
      "  Raw Dot 3: 3.5947 | Cosine Sim 3: 0.1525\n",
      "Head: 11\n",
      "  Raw Dot 1: -0.1990 | Cosine Sim 1: -0.0560\n",
      "  Raw Dot 2: -0.0727 | Cosine Sim 2: -0.0230\n",
      "  Raw Dot 3: -0.1771 | Cosine Sim 3: -0.0435\n",
      "--- Layer: 4\n",
      "Head: 0\n",
      "  Raw Dot 1: 1.4242 | Cosine Sim 1: 0.0443\n",
      "  Raw Dot 2: 1.9363 | Cosine Sim 2: 0.0676\n",
      "  Raw Dot 3: 2.6044 | Cosine Sim 3: 0.0708\n",
      "Head: 1\n",
      "  Raw Dot 1: 0.2703 | Cosine Sim 1: 0.0069\n",
      "  Raw Dot 2: 3.8802 | Cosine Sim 2: 0.1115\n",
      "  Raw Dot 3: 3.2007 | Cosine Sim 3: 0.0716\n",
      "Head: 2\n",
      "  Raw Dot 1: -5.0531 | Cosine Sim 1: -0.1305\n",
      "  Raw Dot 2: -0.0423 | Cosine Sim 2: -0.0012\n",
      "  Raw Dot 3: -2.4740 | Cosine Sim 3: -0.0559\n",
      "Head: 3\n",
      "  Raw Dot 1: -1.7935 | Cosine Sim 1: -0.0437\n",
      "  Raw Dot 2: 6.0459 | Cosine Sim 2: 0.1655\n",
      "  Raw Dot 3: 2.7875 | Cosine Sim 3: 0.0594\n",
      "Head: 4\n",
      "  Raw Dot 1: 7.0295 | Cosine Sim 1: 0.1348\n",
      "  Raw Dot 2: 12.8287 | Cosine Sim 2: 0.2762\n",
      "  Raw Dot 3: 13.6014 | Cosine Sim 3: 0.2279\n",
      "Head: 5\n",
      "  Raw Dot 1: 4.3582 | Cosine Sim 1: 0.1147\n",
      "  Raw Dot 2: 4.9310 | Cosine Sim 2: 0.1457\n",
      "  Raw Dot 3: 6.0185 | Cosine Sim 3: 0.1384\n",
      "Head: 6\n",
      "  Raw Dot 1: 9.8026 | Cosine Sim 1: 0.1651\n",
      "  Raw Dot 2: 16.8323 | Cosine Sim 2: 0.3183\n",
      "  Raw Dot 3: 16.6923 | Cosine Sim 3: 0.2456\n",
      "Head: 7\n",
      "  Raw Dot 1: 3.6118 | Cosine Sim 1: 0.1074\n",
      "  Raw Dot 2: 4.5712 | Cosine Sim 2: 0.1526\n",
      "  Raw Dot 3: 5.2233 | Cosine Sim 3: 0.1357\n",
      "Head: 8\n",
      "  Raw Dot 1: 1.8919 | Cosine Sim 1: 0.0469\n",
      "  Raw Dot 2: 6.1501 | Cosine Sim 2: 0.1711\n",
      "  Raw Dot 3: 6.3664 | Cosine Sim 3: 0.1379\n",
      "Head: 9\n",
      "  Raw Dot 1: 1.5544 | Cosine Sim 1: 0.0331\n",
      "  Raw Dot 2: 8.5940 | Cosine Sim 2: 0.2054\n",
      "  Raw Dot 3: 7.0372 | Cosine Sim 3: 0.1309\n",
      "Head: 10\n",
      "  Raw Dot 1: 0.4411 | Cosine Sim 1: 0.0372\n",
      "  Raw Dot 2: -0.2623 | Cosine Sim 2: -0.0248\n",
      "  Raw Dot 3: 0.3462 | Cosine Sim 3: 0.0255\n",
      "Head: 11\n",
      "  Raw Dot 1: 3.9154 | Cosine Sim 1: 0.0968\n",
      "  Raw Dot 2: 4.8868 | Cosine Sim 2: 0.1357\n",
      "  Raw Dot 3: 5.0965 | Cosine Sim 3: 0.1102\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m head_contributions_layers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(classification\u001b[38;5;241m.\u001b[39mattribution_paths\u001b[38;5;241m.\u001b[39mhead_contribution_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n\u001b[0;32m---> 50\u001b[0m     head_contributions \u001b[38;5;241m=\u001b[39m \u001b[43mhead_contributions_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- Layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_heads):\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsvUuPZMt13R+Z9a7u5r20KEsgLRsc2DAEwoBgQBMP7JkBf1N/BX8BA4Yn9sCQCcmyRepBSuTlvd1d76r8Dxrr1C9XrR0RJ6uv/R/0BhKZeU48duzYjxWPE2ez2+127Qt9oS/0hb7QF2qtbf9fM/CFvtAX+kJf6P8/9CUofKEv9IW+0Bda6EtQ+EJf6At9oS+00Jeg8IW+0Bf6Ql9ooS9B4Qt9oS/0hb7QQl+Cwhf6Ql/oC32hhb4EhS/0hb7QF/pCC30JCl/oC32hL/SFFjqeTfiTn/yktdbaZrNZvvnhvdZa4zNxvO55nXa73fJhWi9L3zPP3qX8Xh/L2m637ejoqB0fH7ftdrt8NptNe3p6ao+Pj+3h4aHd3t62x8fHdn5+3s7Oztrbt2/b09PTkub4+LidnZ211lp7fHxs79+/X8pXeaKnp6cXfDnPvbZKTiqXabfb7V5blc7Jy0996/UcHR29kBHve95e2eL17OysHR0dtdZau7+/b/f392V60fHxcTs6OtrTrZOTk73r2+227Xa7pX/u7u7a1dXV0o8XFxft6OionZ6eLvV//PixPT4+tsfHx3Z5edmOjo7a1dVVu7+/bw8PD+3i4qKdnJy0k5OTRQ9Yh/Th+vp6r4+p59RB9kOVxtNTJrr3+Pi4fFMn9Z3qk94fHR0tbZAs9f/p6Wnp89Y+6bX6KOkw7Vh5ev2ofCpP309PT3s8PDw8LG1R2cfHx22z2bSrq6uFL+ZLcuvxMaIq38heZ58XTv3tvpN2NtO229vbYb3TQcGdQvpdMUOme4KU0x3Vy/+Pj48v6usFpF7bnEcaidf/9PTUjo+PlzxSQqVXuTIiORsp9RqeqntucN4fHuzYRrYz5Un1Jfmz3pGsVWeVvurDKk26Rr7kDFpre0Hd5abgz77z8qkHDIL6KPhst9vFmaa29BzCbLoZ8r5Mcqcc9Jvyke56XtczyY7go7W22GayxwooSkdUL23l6elp6Vevq7W21xcMZAwmKi+BwdfIt7o+29+pnPR7TRm8vybwTQcFRvnkoCsapaMDVh1uVFWd7ICZwJPqdeOl4zo5OdlzBuKTCGq73S4jh48fP7Z3794t+aSM+t9aa3d3dzFaz3R8ZUgpKIyU3h00y+wZsdfpo57UDu+TURChfFVP4mUkBwXrx8fHRf5yEgwISnt6erpXnogBQ78lIwZ8BQa2uRoNuLy9v0Y6PHJKap9kyWsMlsxHB+pypQ1QPmovR55C8PpdAT3+9r4m7xqVuWxcRuqLs7Oz9vj4uJTBkZtGS6PRw4gqm/xcpwZVI8FefSMfMhsYXjVSGKXlf0cnqSwadRIKFU+d6dcSCiL5SMB53u12i3LpI8chIvrXNITKvb+/b621dnFxsaTV9+np6VLO/f39sKN6jlbEaRy20dtU/WZdqb4UDFpre6g5ydNp1tGpLe5kRAnJ+2jFA6McHp0A0SP/Kx8d49HRUTs5OVmChtp+dHTUzs/Pl3sKCnTumuqo5OB67k7cZTMaZSa74SfpRioj2TDLa621k5OTttvt9uyDzvf29nY1SGD5Ph2pKSNOYTGoJlug/XmfJ51IYGoW0TvPDDwsh/3wuYKIl/8aOigoVBUnZ1Ld1/+Zcj3tmuhY1Zv4pcPjeoIrrCNjog/NcbqCq1xHLckB9GSW7nOU1do+Gq6QVS9YpmDd2svRYi8IqMyqrsSPy7gynNG0CMtOTphBIDkCGrLKYqAijxxBuFxG8qnkVfVZhR4TVcHcZdRzJMlu1E613XWMo3zp+ywYqPqSwdoDPvvS5e8A0Ps9jRh89JB0rycz+Q0GBdbj/PeC/GzA+FzBQDQdFD5XpUSYojS8TkYuJdPQ1NOmDnPDlKJ4+aTj4+Olc1Me5RMfPoWy2+3azc1NOz09bRcXF8vCnhDOmzdvWmufRgsKDCOqpgrokJzXRFUg7DmFFBB9ZDIKbr02bTafpupUNqd0UkBhPueR/FW8MCgroLN8dxIK/BoFPjw8LDwktOnyJT9c5J0x+l5QmCHvO3dMTJfWQ0TUcf0+Pz9/4eQeHh72FqHdLtmmykZJ0jOuMXChWdfYBk3pkq80Qna+eqMFpmnt5RS36tcmBcrq9va2PTw8tLu7uxdBi4vhrKOnVyOaBc0VrR4psOKeQxk1ouqMyjnNoo3e9YS0qjxEQvy4Q0rBwlEC10rEhxap6ZAqPtfynspM6bycnvwqFFdR1ZcMIK09O5sqsOkepwGqeihrli/iCEppHESMdDqNJFI6Oi4HFT2nk9qVAuTaAFH1Xwr8vCb5c0Tk61e+08rXhCrbcf5GfLMvfS3DdUZ8eXBnXZXDn+kbT6N6CW70//j4uD0+Prbr6+sXenl8fBynMXtTW72g5rJLwXBEq4OCMzEbiSpjTB2QFIbDv6pOOhbmTfWm+yzH1xL0zdEBjUa/3VDu7+/b+fl52263y9rDbrdbFp+JOsmTy7lCU8mx6TrL67V55OgrA0+BpUfsa6JEfSqkzcXR1FbKS99cXHZHnHhRPe48iEJ9IZbl8L/6/u7ubnGW7nArhzTj+Ks+T+T9xXa6XlVBQbZwfHzcTk5O9upV8FNbU93qv0rnqkAlEo8++qtsUnZLx+p8jWRW9Y9fYz9w6qi1tmxJ52jn4eFh2a5O/hlYuXbigYKBwa8l/vQ966dbWzl9pMbzeza9O+wUaVO5VNTkFJKzrBSsh5JYrg//fPdRa8+otNq2p46QEigvRw+bzWbZKcHFSJeR870GJbrxJbn08qVAm3hS+xJ/koUHUu3+YT7tGtntdntO3ackVJ/LxVHUw8PDi6kuR1zOm+8g8gVNXicoEP9pdDAaXYzIg2Vl6BXI0pRK0lMvU/p8fHy8LKCfnZ0tbfVnB+igVFbSHwcD5I+/+T8FFAVZX0tTXp9qUr+QhyTDJGP/ncCWyuMzMWl6SVNLnGITv5SjAix1yQGNBwVOUXuenr4kWh0UKIRKSFX6Xgek76qukXNLgaXiS9/J0PkRHR0dvehwH047z75u4OjCR1EzbZoJps5LklvlqLzPUhBI9TqP7oQq+bqzTo47BfVe/XRS+h6NFsVjqteDQpLtiGevr0J5M0HbyR1X0hHnvQIenDLynT5ck2G5zl81Qkj8V3qW+o79Uy0qt9b2gntCzUkuh/SFT7FVgc/BBsv2Pnt4eGibzfMalAeF1vZ3VDEQMSCSZkHJQWsKVZTvGRvTVM69MnoaouofOb3Ea2qPvqX4Qkd8tsB5T4bP+tzo7+7ulmkk5VEHajguVJtk15MrEa7SJqeWyvG2efm9YFo5RC+Pe/u5lVNp3DlKyb0c5fPRFkcTSuMO3IN4L1CJZIxM42s1/jS3b3VkGrbHHTJl2LMn3XcHNmvs1JNka3Ti3IZ7fHy8bKF2JEr7IW+cX1feVK/z1wsgPoL3hWal9Z1iSlc5V/ZHLwBUwVZ6qJHAZrOJtsz6GTwk09PT07bdbtvl5eXiM/S0vduEf9KoTdNQaYq6R6sfXqMwXFgp0iZBO0JJ1EMz/umVw3spjV/zRU8aiwROp+vlpzqUV8NGLS7pngzIh+CV/JKMesakcvjt/Hl5PRlVPPn0gYzFFyfJCxeHE7khO/pMo5FeWb1y0+I/0RflUbVNeYSmeyOeFOz9f7Kn3n1dr7Y6OqBwfUvlPDw8TE1v0lF7Pa21vTWH1NbKTl2PPYApEHhf8ZkRd8oEHz378namUaLzzzxVeRzpSH/8+SiBU1+fSgvQbB+Bjqa3/WiTHh0UFLzRbqA+VBs5LP1PQk7pHO0wXeKrVx7bo7KZltMbErDPGTv/XoeU7+HhYe9cHXUi52rdWa0NCEmW7phcTqwnOawZZ+vl+YN/bhDVaNEdbGs52PA681Y8+W9HuwoKcoS853Jm+jQy5PSKryV4UEiAKqFq8uxUBYcqXQoGLm+1Xetdms7wNTaW3Vp7MXLTteRMR36hZ/9qR6VHTCf5pd+pDT35Jd4cJFUggEQwxNH0drtdRgybzfPT3B8/flzOmPL1A7ct2oHSpLOpKjp4S2py/jQUDqe5wDUq378p8KREqRw3vCqvK01Cf6mto1GO88+FaO84NzZdq5xyr93JqawhX7j1tlTBRqSFNt+F4cR8vgvGp2Nc8Vt7friwN0Tnx4MFd3qof7S7hg8VHh0dLTvGhJhdl1Mw4EJsaq/qcNRagYEU1EeUAru+OZ2SwIB40cjWA676KQUvHw14f6o9I9sZ6aHbJ9ft1KcMRl43g8oIMFV89Ij67LrOMjiapA+VTp6dnbWnp6d2fn7ebm5u2u3tbbu+vl500fl3PRIfnJ0Y0cFBgdc3m+ftWNyl4EZSCTsFhKRwI+c4QiDeIZ6OBuDBxSkZaVL25Dy4XZKd6dNSo7a5TCpKaDSVn/phRva6x6FvVV9lgESSKaC4g2MQdRSY8qR0lAsdBJ0h08phujyUxud1nSfeo5PivRm0uiY4pLz89uCgdK29PIPK213ZmV/zDQW99LMAyPnxPmS9rhMs13fqUD4jWVKmyku5khKYrPSCOxo5MtN/3b+7uyvXeBKfvWla0qvXFLQY9dVXX7Xz8/P29u3bxaAeHh7a/f19++6779rV1VX7+PFjZDg5ARmN5tvT4pEMmMbKsr1MRu/kALkgyq2Snq61toc0k2J7PnWa5gcVPMk7H8hJCjaDUEjuSF3h3aCSoVWyVBlakBTSbm3f0FRnOrOIclG7OVrbbDYv5kK5wHx6etp2u/2nQtMIz9cIPDAp/e3t7bK4p3OqaKi++EyZcI85A32itG3Q+6Rap0h9mxyYOx7KRDJMTl/9ILmlhXKvg3wn5H1ycrLcZ3/O6HVyZKyL/5Nchbp7zwMxQLvuMl3Ft5fjPPNwwNRezqhoeujs7KydnZ0tx7mfn5+309PTdnl52S4uLtrd3V17//79siDtoDsFwlkwcXBQkLPWUQ5nZ2fLbgMi7qOjo3ZxcbEIldHNicKSU+aREyyX0y8KPur4ytAc2SUHnhwgSZ2flJtp+DuhU+VXO+gYNY1RGW3iaeYa25m+U1voXHjPg6cM3ut3A64oOTzpj+She3K+Kt+H6FWdyaHR+aaHrxyw9NC8B3LngU5Hjpl9y7y0N849Jxmnds04gApwJH1OgMGdpZeb1iF74M2BREpDUl+7byI/PG+MfHgZycEnXiuiLDxfCjKJF/3XcSoqRzsi1VatOex2n47T0cnL3KXkejAbEFp7xdHZ2+2nrVPn5+ft4uKinEfWlBKN1h//Z1ql0+hAAmBA0JOV2+12eZry+vq6tbaP4Bkh6QRSRO2hluTY02p+5QRYj37roSo9p8B5c25TrQyiQmy9+ylddW2E4jQ64K4pf7dFFdAoJ/LpZ0QxKNCwqPjJaTPYkp9k5NQt5qWeex29oNCbXmIa9S0BTtWnDArJWVUGPxpNsGymqXQu9avbAu2MciSY8g0CFc/KRxkxnQMCXVf5T09PyygljRbZx2ybL94mGaQA5kGS/yvglq77VlK1gWsNnKrVeoG3k3U44OnRdFDgjgM5BE0VEdVyP7MaLObfvXvX3rx50x4eHtr19fWycOLTBr5grUa50I+Pj9vFxUV78+ZN+9GPfrQsvtzc3Cwr9RqZ+BONKaK3tn8WfGsvldYf2iGlEULqdHYenYh441Y6L6NCHK7EHgy9fhoT1wD07Y5BfCkQaKqIozM6tx6qchmQJH8Zger1Pnt6eloOGPM35CUeHKXrbW5qh8CLO10iNAGR1toLEJSAA+XIaU6NsH1NpNJJ9hMdlq9NeJ87SKHsWS7rqZxXCnCpfN9U4QG8olSvB1guHHswY53iVcdJsG8ZwPyZFtZFeaaXBTEPAbOnqWSt9Ok/dfXq6qptt9tlSvPk5GSZej46+nS45uXlZTs9PW23t7ft/fv3e6coVHX16KDpI84jJ0Fwd4WErGmgzeblSYLc7UHjToroIwy+jo88nZyctIeHh2WfL0cn/q3yvVPoOGm4FaIbIYMURDiNwHSSgU8XVIiPeXvInMjIg0CvPAaF5KR77Uw80Oic6CArw2Pd3HnicvQ+4RqBdI+ByNOof9IiqfOc2uDko17qVypH11JfSSbV2gXlNXuvB2x6aVmm53Vd61HyJ7QTpUnAxRealY/B3+1Yaysz7ej1Ua9dI5ut8suX+poHbVHB4ezsbAHleomXA4ZZWjVSUEWnp6ft7OxsbxjDziOS8YYr3+/93u+1jx8/tqurq/ab3/ymPT4+LlNGlfMUadqotdaurq6WOTe9L/fy8nIRlhyLHv7Q+oMWfOUQiP65YEUe1Ek9pJ6ol+7+/n55xy+DlWRePY04U587YqJupk3zrryvftYT2bvdbvop1SpNGsk43zwYjGtMRPvqP440RXy6lP3Hs6bu7+/bdrtd5nG12Hdzc9Oenp7a2dnZou/SFz6Z7cFGv6lTIk25UoYMPhWgcKScUKCj4FlyR+r95vfo6BXcODpQGh8BjwBNCuYqS7L0ab1UX2ttz+6lQ5xqkZx4/Hbi0XfReV877z0b6AVuyjtdk/+6u7trrbXlkL3T09PlveD6Pj09be/fv29XV1d7p7J+ryMFInoxTIWmQ2MnEoUp+mlxmo7aFYIKWJEcxG73aX+ypqR4tAKjq96VrGGWL9DQuH0NxIfsTn6NchsR2+1y8zQ9ZF/9T4itV47kJyUkL94fjtzYd6JKNlU5PmIQsmttfwGRow7qkNClRo/c2818DBAKGOk8/uQgPU3qLzoxd/7evoSwvd98hJHm7p0qIMM+Iv/ucHWNoKLX3ynIeNDv6WriXYHB1xEoE5edSO9P9/UJrodVfcyypVP+tHTV1krWSUYVeTrppzbZ3N7etsvLy8W/aceS2i0wMxsYVgUFOmgPCkTW1fCORqttVzpXRQ9luKHNNEZRX8bNRUpGVc2H04H4g0StPS9Wc3ThbWXdiWadb5Ix5ZiQXELXrnBJKUfX/Lccqhb7e+ioCgr6TUpG42W4cyXYUF71s49OvQxfm1A6Gbz6/+bm5sWptuStQtTOq7eJTqQaGVTlpqDgMpaOcLoxjdL9vzvqnlNW+WmkWdWXAlTPLirnKtlUI1l3zmwbpxgFGjmFxzVE9gl5oAz8WkrnbUhtd1uaDRCttT1/pA0rm81m2bKqV8TqeRv53NFoRbTq4TV2tCMuCTkt+qkBTMdTAN+9e9fevn27DJF4EFS1U0k8cf87lYcGuNls2s3NzcITdzQ5slC0ba21y8vLJTiIrw8fPrwYXfTkpd8kVwCNRrSQyekByVNDx5l+Yh0JmSRHwKkALcxpWivxzPrUz45YFXj1rXLoLDhCUxkEHI6mUyCjoadTJVWudsFJ/xxlKx3zcJ3KZST9cUCkkSj1kO/ScD2lbvv0l+p08JWAAmWnqSlu3a2IbWNfU09o0y5b73ORp+ODjWsWQsmX60uvPifaLTcOcLrJn0Zn++SvpDesk4DXA0kKDJ6/ogTESALDmn6/vr5eFp5/+MMf7m3q0RTpiFaPFMQo50wTqqmQgKM4Cpg7QdRgBpEq6ibHp3v6T2ehct0BpDZ4Gh+6+XEFFRKiEqcg4Wsm/rtC1ul3lZ710xHwt9YP5AyrEUIlN9VBZ+lt9mDs7WdeGihHBUmvfAqBvLBubnMl+tXWPuolH5wU2k/TEI76e7JI/ZRsx6fsvA6W53rmO8oSVU6/t/DqMvWgmtJX7UxpZ1Cz647f43e6Rsfuwc5B5ky72AeVnSbfULWBbRyR0sg/EihrQ4/WAuVfR7R6TYFrAm4sHmFFrnSOaphHi3p6t/Hd3d0S5W5ubl4ge5bpdZKYh3zqmr9ljc5YDvLp6dMZJAoK2lJ7c3MT9wGPHLnzJwRD50YU7jynMhOCchmrPCE3PnToC7p87sPrcENXG9I6Dftd+ahLt7e3L9AYy/E53LTGxU0PXFzmcFsjRQYaHilAJ77dbtvFxcUL58894sojPun8q+lJyozI0QMN9cL7wPtT9bEfudA+GtUyUPqWbOpXWtD2EaLrBMvi6Ep52QbnqzcS8ICYgmVyrFxH4DZr2bpGDnS0Xj6nLL09Xn8VLCqqAoK31+8JqN7d3bXj4+P21VdftZOTk2UReibItHbgmoKI81nuGNyAfTdGFRx8aM6pDO4j7ylmGj2MhmEJ2XmnMxJzEfb09HTpDE539epKqCGhZyJ4Dn0TYlc5CV0qPV+rmE759KBUoVvv890u76ZxGXjfJGfoW17VF0SnDJiOXHWPGwVcxqw/BTk6V9XNsl3+qd3UFw/olAP7h5sYGFwSGBK54+QWXZ78yukD7xMFR/HA9vacmuspF/orebfW9mYZnNIUVY9mRgvVfQZvTh3zGRKOWkXuXxxY+nRp4qsKYgmAeXuqwNHa83T0+/fv28nJSbu/v39xbE+PVh+I50GhteedIEkArkwpMDCNggLPS6Gw1WA5Xy4KJjQqXlInpbZVneiOh2j66Oho2dp4e3s7fHgkOVWv24nDWu9cDzIpMOieggKP56VT6hm0851GCGm0mJCTyqMsW9s/UthHFXSiDiZYh8pNi7kefMmTl885cPHFtG6kkkEvCDoQUtksQ9cS/2k6MYEABiQFhWodjICgtWd7nnHOHqxcjzwt+zY57xQsXdbJUVb+x3/7Ncpbfe3AlMEu8aDfXANKR+54wFe9zjvbn6jnY9XXu92uXV9fL0BNm3pmaNXrOB2hqFF3d3ft/Py8VATmZeO5I6C1tjeiYHRWHp7NzydqmVadSYMmH6rXUV0KUMxDJKj2yOB09pMOqrq/v1+Ot/XFHSK95IA5IuGrOvXMQmUgaX5bpN1Xmiqio2X53JmVFto4KiRKZ3Bm31S64CQdYF4F8s3m05BebdLoVPqgtDJCXksBStfu7u5e6DINWVNqNEDpGsEARyOSg6+NuYP1AE5dTKjUZZWCgztj7sUnAtaUbOoXrim4A/PnBBxMsG7qpOs0dSkBD5ZF3hIo7YGoHnketU/PqMh/+KYZyZVTRZqOVHrvR4JRPijZAyz0aal9PpXocqHs9C6GpO8VvfrobDGpxo6UleUkQ3FBuMNUWh/2u5A5V+yOmHPBqssXD2lY7rDZbi+b7eKWsNSRI3mrXayDawveLwlh0Qh9O6EH7DSVQkXiSIxleKBwxOhozutP7Wa55IdBlNMWdK4eaF02/tF1ytV5JpBgAEzOyutz8jpdz5LBM09yyNU9t4nW2p7z4sdthddT27xfRvcYaKryvC1MT3lXtsT2Mx/ll8h1gfUTjHKk47Ma2+12bwqVYEDlST8ZPDwIU/7inzMneu6AIMZ9q7dNvmiGDp4+cuNWJNIwjFM+Xk5qgMpzNJ7mt91ReoQlOk9bLDV1wpEEFxvFjx5mqvZ+EwXI6Z6eni6L5TysTw+RJJTiSq/yfPiuaRbuxKpk3Nr+S29Yl/PANRKXB/vdA4f6yoNJ+p0CrDth8t1a20O01Bs5UkfB1A39T5QCQuoHkXSK27AZgNQ3yp9k5PZCo+5N6ZCfCjkm/smDghqPReCRy+IzPZmsequ1FwcJLofW2t4bBVPwq3SYjpTlUQZ0+IkHb0eSnU/1cnOAFmp1dLU/0CmetPFks9ks52qJP/U/+5vXfB2S/GsE//XXXy/2/N133+1twCFIoT64DlajT6dXvY4zdQ6H0ZzPJHKXc0sBwN8FS4OQEVI5fGcJndDj42O7vb1tu92u3d7eLvPpfKBNeXTNg5kCHdcQHHVQ2CqPBqg1h+vr6xfTY8mBsg5fS6CSVf1UbZl0Xnl8hfJJcX0hX6MN8ak2+OKlBw9ODbruEB35OpD48zyUk/JzusoduvcVyxGfjvx9ykD5iK7VNkd4MmLxN1rXUL2JUh+7vrjzqQKi+oz2pzUwptd934GU6nY+XO4O9KRXPQfVCxCj/x7MKhkynzZdyGZot9qMcXFxsRxG5z5Gz1QpKPDtfOTN+dV92reuc2SijSxv3rxZ0slP3t/ft6urq2UHZBX0ZtaGSKvPPlJFreUDl3wIL4b0rWEQV/clEKJ3Bgt9My15oLNwI6bzkoMWamKwYqBROdzr7SMWGiDro2PhN7e58UEmlV8pkQ8jE5Ljbym2756grNmnPKgwyY3lsj4+HOWOQe3lUDvx7lN47ljonNMah/dBCqzkmdcrWXpQ83w+1+uyddDi+avtqRX1UK7nTyDAyxKpf9J7wVlmFRBY1ygYEx0nQDPrxL0vVXeyg17QoEOWHLjmJpuQHSkg+BZkvcOFL2fitJF01In2RNuQL+L6rM5zOz8/3/Otsj3lSSMGyv97CQpff/31Uom+hXr5EJc/JOaITI5YIwlH52okG5gMdGmAnbVPxKa3F3HEsNvt9p6aVnlanVdk1jSTyKcEqi1nHAm4g1S79MxFWohmGzWkr9YR6Ig06ulNFTkvCtA8ziMFWTpJ9q2jcNePzWaztI9l6DcDEp0H+fVRpeQqWVYB2nfasC0yRu7NZx8LrfloNgUU7//dbrdMH9ABMtg6LwzCLkP2d2vP03ppBEnyEQrL0bSbbEQ6SZk7sa2pPpbvAZSBUGWn53p6lIKB6vIg4AFa8uIUr77p/H1kqLn77777bi+gsTxfR3PwRH5T8CRIpr+gvt/e3ra7u7u9+sT/+fn54kcUnKiblM1sYJgOCu5sWtufqqAjTPPF+s8FDyoZp5eqRlQCZ/l+j2VWq/6tPTt6TUfRoCvnwjY4zxyqK58jOd8u6JTQDX/TwVKpPBCkMiSPzWaz95BVaif5prI66mM9VEiiegYG7//WarSbDE7lC2jo28mNMaFe8cG63Mml4OEBQTJKTpoo0oOs24zzQNDkupAcDmWTkCJBR2st9n3SG/aL6xNnCBykMU+yYZbrlNLyXtJ32gVHzwoC2+3+MRfsa9mCwJJQOIMCg4n6pVrAT4HD1/uSHNh/re1vm6UOCcwSiCdfMEurgkLlfOkk9ACXvzeUwm6tLU/dSShaoKXTqByVU4VU5XjVCRzyJQNvbf8wPC4YEd2qI1hP5ShZPtGK+NGBgFLA1C53TpxS4vlE6gvPS8XndJoCIOslEvWgoKDpz4n4ulCafmH/ybC22+3eCI2O0JXZlZwOiIaQRlSVg6OR+nW1IY1gPFCyvyh3luk6JweitjAocBRDh8J6yCf7zvnmSJ5tkJ7yxUHeN5VToW15u31KUHy19qxnDgoo91kn1kunEYBG/Vw/TP3WWttbS9NZZ3x1sOuVzipjkNGoS1M7rjP6Pj7+9IIynnXGwKMPF7wpN8pZdV9eXrbNZrPMfrhMq0CcaPWBeKKE4jj/y0ib5lFb239e4Obmpl1dXS1TNxzSUcFVnyitPRAlEbVx6kQd51Gd5fFYDRlJ9ZpQR51EDHRgNDgFGE1VUV7Kn9CvP2Wr/qBhqp2UNacJ3EAYuKh8u93zk8oKlD5dmPQgKSCDm+rTWs/t7e0ih2rnmvqQgZpleX+L2L/q8/Pz872pSx/Z8lv6zLrUVoIAtw8HQpQvR4fen45ekxzJmyNJPqnO86s43Ub+pIMifwKc9SQnzuvVA1JVW2adlQMj/W7teW1MupNsU21Ic/ySg2TjQId9Rpv2DQrUC/af+kDAVwvXm83z9lI6e4IcpdM9+jKtPbTWlk0s7isc/M7QqqDgQ8GEiuRw+eCVK5Py6iNHQ6eoF+VIoVVP4qsiRyN0yI7skwP3OWtdZ3BRPQn9MMgQBcp4XYla20eUXJ9h0HOHkYyVTp+IMR0G6IiZbWVeBgUP1GxbNYWT0D+nfjjFxNGQ88kgrfZRFkzL65SnRmxsu5dF2brBefmpnQmYeBBnf4ov56eHiqlj3nb2KfW+tZebRLxt7uz9v8pI6ZJMXDYup5HDqsoV8tbDo9pNlPL2/JBvN3ab43/3FWlqlP2pj7a2yrfJ93ke19E0jcigIH/LNQe2m/owQ6ueaO4RK9Tvi4uLttvtliklbjdl4xnJecyr3qLGcr1jJQSfuqEgGNV3u+enXrVq7/vFk4NVvRqe3dzcLB3B7aycZiKicAdBY/RRls4r4fuuVb4WiIV6uXgvByPHomk8Bdvd7nm6gIguBRgOYTW01cF/QpeVgfUClvpK9Uoeaq/60J/mZhlpfcuNueLBjYu8sO0iyfDh4WFvDtnJAxQdjXTNiYcPimc/voW8VcQAoqlBBU45SMlRACQ5Q7VPOlWN8Clz8uh86jdHz0yTpqiqMvy/pm3evn27LLgyjY8KZgKr6xB3H3JXZNInTR9xJiFtolF96S1+Il3naEf9IX08Pj5uP/jBD5brrteUZxod9Wg6KFRCTRGI1+SI5AD9ISaWz3IUQHzVvUcJOVY86jrnOytU5g6mteczmDgC4CFzrlBqX6XkSuuGzOF9b56eqFeKy3lKpq2GmP7b5zd9jSjJWvkcVVVokPLkaIZoqTedlJxID12ngEGHLAdBp+nrRM5/FRxdPo7YfJqPvFdBzOWW9KG1Z4etEc7M6I380KkmwOe8OepPzl6gp2pLIjo1jgw0zaxpQA/qvcDC6/qkaWD2k/cLHa1GJwwKdOokrhVwpOHTgORJvHJDCPtX6x+admKfVHbXo1cFhV5lFIaEpj29REHeMY5gdrvd8jQhnZ7zlRSN9/ypV14/Ojrae09CapcvxrGTeF4KF7l0jSgjTVmpfA4/pfziR9tjKRvypMArJeFCMpWdBpQcN2XpClwZmzuEKijQ8LxOtYuyFKBwGbLO1Ec0KhFl4I7NjY9lc//3LLkx8rf3r347OqdzdZDlzjb9ljyZN/HDESPXzYiYq8BWTbkxDXVqxjlVAV28HB8ftzdv3uw9ULbb7fbWuZxS+x2spOk6tjMBD5H82/n5eXzmhzKSfbru+1pGcubqE23n3+0+zVx8/PixffjwYZnFYHt69lLRZzn7qJeOzkjC5dbP1jJCYtTUcFhP3qapD+anICokJ6SvMrjTo0JJ3iYfmeh5CDllIhp3+uKBvLrz0dQUURYVh6MDIQUqHINGcipVnzpiIYpPSDsZUi/guNHQgaQF0dbagggTSb+qttGY/BkUd97erqoub19aiO3lreRIdFqhzV49DOguQ933ej2/ZHN6ehpHmpWDZyDj6EdpvY9YJu3WScBND3Jp7YBrUb6zibKoAlnKw350P+L88trj42O7urraC6Y+Y8A2UyfdF6hOXiNfGsldXV21Dx8+tA8fPiz27+sPvpY0Qwcdc5EqcGNMCEbOV0LkfVcKCp6OQmUk43cDFa8pKLBjWA6VObWP/BEJqW4fBXlQTPmYn2V7sFI6/fdnMOS4WY9ozfSb88URTuWgKie1Zl43BaPN5nmePQEOlktE5wiXfUNHm3S5CqD+SUCmsoOUP8mFTistMlJGLH8kU+b3PN4GAS+h8LR2kORbydHzjYhlkxe9e5g7cvz5AQ8KDLIeYCubcJDa61f6HII22TzXizxgel36T3/owV398/T0aTfg7e3tMvtC3+Byr/oo0XRQ0KIxG84oljoiCVHTAd6ZSuOKTKFwisaNgwLxziSSoLIpMFCgfL+uP2uRFLpCxXwARlNK3AbJkYPz2Nr++2zJs9qvuj9+/LgohhyJ745yeTq54+B1R07qr1Hw9O9KbmkKQtMerFsBUjsuONUo3SDocDSmUZzq0xvVOEVGZOVghFOBbDvtwOe2Waavi7ijEV/sW2+HnE1l/K29fLCO/d2bUhC/T0/PC87v3r1b9Mu3gyeQ5MQRsV9zJ8hy2N86lt7PHqpGCA6I+JwS9Ua8aMpSJwxU70L34E7yoKlrmo3giM8BnQCybJd25tPM/Nzf37dvv/22ffjwoV1dXe31feqfGVAoOvg5Bd/x4Mz0kIMWU/1lNEngaR6a9SU0Qh600OZz4gkxsX5H4FVbRCm46beUQw/s7Xb774agPFvbVxgalZ9pRKejQCmHkZTDHVFCnaxXjpC7tWacfkKQjizV5uQUxBNBh9r6+Pi4N3WQkJbKYfkevJmX60m67rtNEo9qQ9I7BrNqW6Hrmwcb9g/BmDtalkHn49elV9wZl0YcRLra9MATfivbnkWiPaAgmWp3kQJCmt5NIxjl9z7nri7KkeuCKpN6wr5N19meahTtuuH8StbJHpnPp5z8dFWXpfu6FLgTrX4dJ5ESG6/vapeKGNU353QdiVdG09qzg6ChqdFpwZAGJP7IT6pTbeXTnpXwU9ucqMRaxGtt/0EsKYaMlm0l0VlpUVajL0cT/vYnkjtGVxoiXP0/OTkZ7sZR2d7vNA4FnCpAE2nrv35resyDaqpXfScnmQKqArY2QaiftJbji7Vqj/5TPmkUTXTo+pZAAacBCWT4HI+P3ugEiYz1rcCu35qTpuNQkJVuiW89ce62XYEq9oU7Tg92riNsx+Xl5bKjh7sP6RQ9P2XAujnVoveq+8yBZOB1JZCVHCz9hoMDysanOPXRphKfmaDNuF7RriqHPxuoSQePFHTNFYRDRo983gEybKIQd/aO6HRd2z/pcNMOlaQ4jo70vIKCnqOD7XYb94/PEhGEUKlGMFJ6n3+kPFSGhrtUVo0QiCZ5wJ0rTTUXTWPTf0eo5ENpUj+xjDQaYP9637DfVC53hPHhuyoA00AdgbscNK3EAxIl5wQ49BEPfIeHbxfkk8Uk9rEHWSJWP0okvZFL7XVQo3oZEIW63717t2d/HiTdmSmvELVshX1FPWI/V+2mjYpP7d7RGkK16yzZtU/Lqg69y+TDhw+LLDkVqPzuPD1gezB3G1C9jubFu6eTryHPKp95OQ2tcigb8uJ9wD6s7CXR6oVmN3AXqKMQR4gc8nmnuMB1L6FwDocpAJE7J6ekzAl5iU9vx2wETrxzrlEOz6cY3Bn5dJ07ew8mlfGwHX5dvLEed/be95SvL7KzHZ7X63dKwUkGow9Remq/SLLjrjVHX1xX4EiY0zHsCw9iPqWR0nl70zbUXlBIgZfTHSqbgYLBS7xy66SDuTT1SJnIqXofed8lJ5v6l7LiURXJtpPNsY1cbxAo0m5Af2ETR44V3xxppqCgtFU/J5r1G9Ipn+4i7wxuPIyvks9nDwp8cYgjOmeGRqp0bKg7YD3qTQfCYXuKjN7QNKx2g6OSO6leIlEGJ58mqI68TpTmkyXLm5ubpXzvUEdzvgbjvFNJFZzdgSTnLnLjU9pq2kB9o/ZpWE4DpMyV19Gt909yKkLiCa1XT2frfzpyRXpBo1NZmjLxungAGh0Pt+smBOdtUZ08W0vpFBSUxu0rgR0f/XlwlNyur6+XrYsaNfCcIO4M9HrVFj4P4yMG16UEIjhNxlEIN2Jwyja9ZZAgiv0kmemdxHr5zW63W4KNv6M8+S7pc9o+TDDGNnrQYMChA/fyuD1f/OgZIz29LP50+OWbN2+WEYbWZjWS4Dqjn9P22YOCR00KxZ2vkyN8Ooenp6cX+6FZDxeYuNgop+xHHviH95yqa47EOVcoXuh0Uzv1P6GM1p4NmcNjPgdARRJPVT1Ek9y6y5GYB8cKsfD+qH2UV2vPOqL+5L2e/BOKrIIXRwrVVFj1n+sunGKgwcpxcDjvIITInVsQlV5lsn4GIzr8BGISuKFckpxIql/5HZzx9F/JwnfIMLC47nH6I/VXxRf1kohXR0JQZmlUxDz0QZxi0RvQlJ+HTqZRkLfBgYATdcvtiTJz/SGvtFNOFdE3qLyzs7OFTwES7ZxTPZKdT2+zzT2bd1q9psBOVQM4H+nRtzJQd7Zy9DQy7X5wdKfOpmKyfnUYO440Clw0SB/Gctuh2s8ykgJXcqDzF0Ig2uQ9Hz6K3JlIKXyeUvKpFulcwd0oE+rz9jOQVU+YUj7J6SsNy+V1juT8Hc1sK+tif4hoRMyvKQx3EnQoPGaZU1usk2sbauvT09OLxWK2yxcaeyBHRDm5U9M11xeO5IjY5XS07VdtJC+UB0exI7vTf9mPUKzqHAUE9iFtUkibZ6Zx1Mb3KouPNMVHvUygy+8l0ER+qS8EtZzSIrhtbf8sLPHMo791Tf2jDTf69tkRze4kXns0HRS0F5Ydy72/SfB05hQcA0NrbXk2YLvdfzubyOdUW2vLThHxIqEovcpPTi4RldkdHh246qSzTgJPwYD1qwztwuLUiOpx5+FK5lM6lKvzIyU9Ozsrp9Uop+SUk3GQDw671UYFbw/qPlJKKC71l4Kbtvcqr/JreiCNPjQfTkfGICp+FNTcyFM/poBJXnWf7+em3DgN5XrE+5Q/+fBrHrg5901HrykLoUmVpekrX+z19wOIpMMOOtJoSVNFvk7jcqU8OTMhW9eoWsFA0yxqr5C0A1jxwf6n7vI+Zen9TcBKMMpR+ps3b9rj4+MSrLi7zafEVL52E7bWlmnMd+/eLf3gelX5B93n6QazAaG1FUGBiEEoSMKkUXJYw3QuXAqYC0RqFIf6Ka+EqygpJ9sLAAl5pPLFFx2YO3m2l4bgCuX1s25HKZ42Tb1QqRNyZFtc8bxuL59lsw3uZD1wprJ1z/nxdlUO1fNUIzn2ta8zebBjAOjpiTsGR99OSW6OKDllJHJnkuwj9bHrrPezbCn1m0gB0vtjs9ksASPZdhWEqj7nyMJ327jTTTbospfMeKwLNx74OkOSgeuhrqfpIhIBAhfE1Yea11dQuLm5aR8/ftxbI/CRpeuqy50LyZRLCtAqT58ewOvRqgPxNDqQM767u3shfDaCi0EqwxexGBiI1viAjRpL9Kbrd3d3SyTVQmBrbc8IR1GyZ5A0ON//7IvPyRmxLJFkoikQlcFFMM6bS+4pICiv6mGw5BQG5chvJ46CaARUerbJkYqGt/7mut1ut7dIqaFzcgw+XVb1lWTHKb3kBGi0Qsa+xTjVo7J9ZxgNzpG45KXfkgOPs2Y/pZHmSF/ZLk6ZuvNUXbKtVK5vAZediT/ZlkaYbAPL42K+9M/XDPSb6NptnCR9EikQaMGcdfCEYsqf8pJN0I/Q8XJU4kFIbdMx3b/3e7+3HLvR2qd1Go1aNptN+/3f//32D//wD+1v//Zvl9GXj4zY1/Sdl5eXS7t9AwMBNKftqcdK5yBoRq9aWxEUqGREg95AGpsP4Sh0MirFSE7P5+UdPTI/pxDEHx2zIx3+r6aBdI9K5OTzoV6v8+DD6hRwlCfNf7JcTq058mUZvUDi/aBynR+ftvK+T06dMkqjrF4w9r72+nptZnqiM3emHvg5bcfpHgIXOkbXY6+DO8Z4L623VIE6yTntEErt99FAkp/Siz/yJgfKPqMf8P4jqNBvHgjpfUy+PKCTn8fHx2U3UXKUHrgpl0ovCV65rkEe2O7NZrOc2MydaDpiZrvdLjuD2Dc+tV4BAJWpxWXpo9bOXEYql3buU0rs61laFRTIlA9R2AGcNxXKdaRAZ8NtVG5gDEC8z4YzavaCAgObyiP/vWgqp5J2K7AuKTLb746H85z6z1EH65TcZage2HrTD95+Vw43UjpL3/7JvnfyOhioUj4an1CUo/vKcFzObugEB5RRAhEuEyJY3yXEkZyPzJxHXde0gU9T+NqC6mbw6wVwD2hJVtKTaoSY2k6bVhm+8YPO09ddZOvkW0HB+SNvTEtZKJ1GWjqFtLV9h94DTOTPR7/+oJz3h9Lx9cB8wE6yUH9uNpvlrCa9kKq159etkrcEYvjmOA/a3JlI3thuAhAPvBXgTbTqzWuMfES4VeQXc9wRcHd392LIps/p6ene1IcrvDrfV9rV+UQQSsshpQuH/Kehq6N4tUfXvCxNrW02m2j0rvhuMEzLNJQhh4TMm5BRRa6QrFcK6Vs/Nf1CGXibEoL1tmw2+++d1Z5/Pv2rqQG2JTl76gN1KTnt1F5e3+32jzXxOvTbgz6nQDywckGR8vGgkJxEqoMBl87Nf7N/2F+J0pZIHrOituswQTktHn3BHWHsR9fHSv6cQWCbHx8fl0Varh0moMKATx1kPyoN9/j7CINpLy8vl3cq6wU6Kl+B6uHhoX3zzTft9va2XV9ft5/85Cft7du37e///u/b+/fv93ST/c0+9CBDEMzpIj41T/ly/UE+SABS/TPyCaTVawr6LeHN5vVvfeSUfUqB6Ygkvc7kCDkVpTw0bEd3PkrRNV2n0iYD4zUFH3ceLNPLJS9ertrP10KqnmQQs33ifJPSMN/nnavAUjkABgWfSmpt/0gIBv1RmdXHHW1ylqndfj/pncuaRu4Gr7x+z4NFkiXbSB6V1oNU0gPK24FOpX+cUk2Omjv+XHZ02rTHZFveDspW00QMgtX2bu+XVB/lmaabXGYCL5oq0pHdDDqt7T83Qz3T9ljfBMO69M2H6lK/sX0cxbNtHiDW+gLSqpGCOwSfYughZFcuOTqlOTo6Wo7nVuOowIrOyufz/C5EdygqU9+sv7W21+F0WEn4RFC6pjTsFFdOj+gpcFBGarPmU/k+aZ+39Skp9levPys0x2Gz2qKtif4Mggc7bh1UWT71QGTdWtubYtQcavWGKm5gYDDxoEBd8FFdQoY8hZb96vKijquvfbutB4209uPkDsDn7jWict7S6Jz80QFKblXwbG1/9CA+vJ3Hx8cLknZd0v/k0JJt0ZaEwPW0t+77k8guL86nOzHwUA89ENF+5Y98JK93QZ+dnS1PTmta6fLycnkRmHYd6Wli8kI58Ylyn9rlCIP3qGseSFrLm0V6YMhpVVBwIYp5UuUs/ZqXK3SgqMvhqBpPx+fTJXLUKbq6s/c1D6Iv8p8QMZGMBzwaAjtTPPlxHUkG5Fejg7SdUTy480jzsgmJJV7FL/vMDUr39JvBl4HBAyodG9vAPFRq7gGnsbOdaTqhcuSsywMH5cAAI7n6CCIhcw+qTikgJBuizIjYPU8P9JCSzeo6R7UkjgodeNEOaZc+jUZbUnpftPcgKn3XA13sB/LtgZtl8Dq/WV6iFCCor5yCoX4qr94IJwDrI13KlGCpt6uQPCcfyv5R+30dZbPZ7D2MOUOrX8eZhM1O4zBplugIte2smj+kA6Tj8yir+2ko6dNLPgfq7awWb3od6oFGSFTObEYWCgwcQrMuKapPwa2RO2XrTlvXk3EyKJA3ledzyyrb58M9IKgdHDVsNpu9M2DkGNyJV21XnUk+SQ96ba+MqwoKVds9UKk+1j0qr7KzSpcpC6ZN+ZPdcReNyvIA6uCF/ctAx/6WbLS7iBtP0pSe77ip5JBkkJyr88P7tDXVdXp6ujyEJ940ctpsNns229r+xgoRRyS9etkfiW+uq2pmQffln6rD8ipaPX3EbzqSSrl7jDjzbKSmdzjFw04gkqQzo8OhAvOIaSEkfdNgqwVbdhQdt5yyp5ccOKfIdjKNO43dbrf3Nqg0JFZ9jsx4zHQiv8egV9Wh+9XUhyt9er7Cp/aoK670TC+5aZGvteepJp+Oam0/WFW7oCpETcfAtGl6SqTy3RG7/FxuLJeo2csWwk466fyrXNqF8jCd6w1tRvJOzxpxmoM6e39/vyzSy2E7SpYdsD8EevgeC/Vv0tPkHB1keN3uq5Lz9X6V7nB6m30tQKi28Xkb5ZO+cgttGj3Tv+m6A9kRUW/57AtnT9LsREWrgoIqTsxUFVbGwvyO+lkPO11G4g7fnUhCjxRyetiJ9SckNuqg1AZdS1NGlXLrN3f+pMBEnmiobFMyJK/X2810ft3r78nGHeBIIcmL80HnryCcpimdR8rV253a3GuPy6NqT+W8EmCizqbAz110KRgn20r/qQuUDQOJ6qMDly2laVnWRUessnzGwHUyjYTTCMXbu4Z6smGw8P8O0ggQ9Nv9kgdZDzKqQ7Ls8ZiCF/vaZV35Jgbv7yUoVErOayltryw6zdbaC8SahK58jID6FrLhSn7imyMFokl1GtcfiDJH7U6LOzpgTeV6B2pE5GsefCyeaSulYTq2m0aaAoQ7i3S/+jhfaa5X2xVVHvmjoaWALPlxP7rPgbvecaSUAgT5YDt4jaiV9Xlw7Om5OzbJJhknjZs6wkV+6UQ1DaB0CZw4P7QDH5H5tG1yYh5U1c8OfnxBlHzoaGseDcF5+kqereUj4BNfbKvsPdlvAgyS92az2Tt2W/3F+vhwGfVXfHMqiQ+nKb3nI0/im3opX6G3OLI+AgluJ/d+7NFBQcE72DvCjY/Cduea0lBpe0iezoMBhSv67GROKdAA3bH4GknlHJVeSk3FUDk+onEkklCG765KTsBHAknZWbbQdoUq2BaWnxyAX0vp/boO+yKvrhNOdFKOqvlQGedM6cwoc8qFdcvoeJ86Qpklh+Xt9WlC8VLJycvwadDW2ouD6Ty/T4+R6PhVBqd6Egr2stOIgU6LNqYtq+44fQrSg1LinTJPgZzXOdoi7+43aJuJyIOey+HUJXXRHTWnMAlauSEkTeeQL5XrcuHzYNom++bNm/a73/2uvX//fq//VYb7vB6IIR0UFBK5cVfOh+l8gdGdSfq4IVCYnFZwBeeUjD9g5e2joVQOkcicQU550rCbhkJlSmUn51Dx6s7eeVbdzJN+9wJGukdl5n+fCnHUnbZVetvoNFyOjqhYZ0K33tY0Z1sh0V5A8DZIb3y7sT/o6OsQHOanehkQFbh9SiK1w2XIkXRy8CrPbUvTDw5CkqMmIpdeajeRHBUdMxeNk5yTfnJExDQJXFQ65v4hBSaNct2O2G4CLz5gp11ItA/vT8k26ZB/GJjevHnTzs/P29dff91ub2/bhw8fXvgY8ue6PqLVW1K9AWsqSx3uyETX3Zl6R/iURGvPUzF6+pLRleX6/L07MaVPDpsKz3rFhz8yz3YRzfi0VWv7294S4vX2emDlNdWXnJorqq65nNzpi28+kUuEXimfDIYkHtWXPOFS93jQIVGPjESy5BO17mhVF/NUc8XsL95z58n0DAR8/qS1toyOKB8+2+N66AE1jbgJfDxYcpdcsh+OELx/HEA5yGNaBnfuiWdfU3ddZzabzTKaPzk5WRaanVxHHYil9L5jMU23SQapTpWj/tE2WZe7dFJbaDebT0/iv3nzZnluQdd4hE01+1EFuN3u0yj/Rz/60SLv3e7TVK3e705ArCea5QcrWfbooN1HlSC9cjewXj4vfyaPf0uI7nATKnB0TeVZE+jIK1GZyqna4UHF1wS8HLZTlJxwcuTkpeKd9Xi+lN7lWRlpKivx7W1uLU/deZ6qHNbphsj+6vWRp63q031u2ewN1x29ujNO6YmSXY4cQSTUrTQ9J0gAxfKTjTnydcDWWlscac+WOK2ltiXekl1WfaFySZVNOPBhP1NnuNVTTpo7qXRdoG6z+fTeEspGADONztieFKB13AdHIAzGBEiuj4fQ6t1HiRw1iUbO1dP6fDbTsFMrB6SAoCO9ST5/qmvcBaEO8HJHjkmK7W+QciQnxRJqa63tPantBiZF8yFgGr209vKZgZSG+SkHV171RzJUdzDJ4JJDpGOjAXNqg/KSUqc3kqU+8Llargvoo7w0au8nL1v3k0OmU3PU7M7TZeYBoZrOZPv5W7xpgdZf3uJ2ybU2ERFw0m/md1t05/n0tH8IIOti4FEZuq8RjJ5g97pHAdN5pI1z3c772EEXAzudqt7b0FpbnuLWWoH8hU4deHh4aKenp+0HP/jBgtaVTg+i+jb7CtjJn93c3LS//du/3dOVk5OT9tVXX7XN5tMZTZwWV7vOzs4Wvir5JVp9Sqo6gL89AiYHmtCFO8CUlgpRGRvTtrZ//Ibfc0OhQkiZ3ECdtyqvjFbp+CSnrx+QDwUT7cRwR+xoiUHCh+4pnWTCeWwaNvmhEavstCDvsqScWDZJ8vCjKei0t9vnXVqpHzkFwfpdP7bb7d65/iR3itzd1Fpb5tDVh9UIwA3ag1E19830PhXFqRY6tBREEqKlXkgufEaAcmIb0tEJDJY+HZWmdPXhlIumORg43K4Y0Nk2L5s6WAVxypntYF8kGyQfrmsEjTc3N+38/HzRB+1Mau15RxVHQGdnZ8sRNe/evVvko3cveP1s33a7bV999dVe0Ly7u2sfP35sT09P7fr6enmng0CmpowEAgh2q5Gi06oD8dgAkkdpdyApb0KuCXEmx5wcPK+7MVbkRsVOcb68vgpx8GwYoRMaOct2tEV04/IiPykIeBqVkwKayzMNmRksWJ+XVfWX88/01dPIrFd1uvPx+eoU+Nkn6oOkX+78nDxgUa88MLju+9Sl8+r/yaPABbcke1/TcUomHjjcdhL4IiKlQ3IZpH5iv3jAqqZD3T9IRgoKDgR8XY997X3p367HJNp01S9qCw+jlIPVexP0SQFRstQ9nROlERX7zftEvy8uLhbHf3Nz025ubpZTH3S2kmyKfahrkuEaetX0kQvWlaSiSqG8TM/D+ySPgHwvsKM3GQDL5bSDOwpHKuSZw0yVSzSsoR+Po6CRKQ8X4chTa21vLpP3PQA6anW5+lvKKF8tlEmR3HG7/Pzj/c+hOsvzOuhYlU+GpXJ9ek8o3nXF9Uf94nO4+tYogjtMWns5EuFIQTLg8wMJmCSnR71Kjp6Lgz7FkECTO8RULnXbp3KUjsGXOpVGVz5C4MkDDII6XVR1pXc9067Eg0aQLLMapZIcGPSCL2m3qx8mExhym9JU769+9av2j/7RP2pv3rxpP/zhDxceFSB+97vf7elza61988037ezsbHlvgts9Sfmurq7aZrNpX3/9dXv37l3bbD6tV1xfX7dvv/12eQf05eVla6216+vrF8Fd04t810WPVu8+coc+ixiTATMtFdk7YiadU4WS0vXUlqRYjjqIIEU+/5wWgGiAFbpLfFTtTUbjTpppU1+ldqWyJAMpmA/jHRW6Y3bkSXTJYOlTBr2jHipHwODq8ktTEk6V/FNfJerxpftyfAoKle77fzpwEXXRp+R8morfCXT0eHY5JkDDERTzVQBGPFftTYiavKUP07HOpIepreTD/ZeOoXEZt7b/KmDZgEhrngxI7pf4W+uj33777YsRq47uUfu060mBq9emHq16TqESIIWbFjSS8fjwN61ZVE5A19xJs+wqXyq/WlxuLSMkl4WvI2y322Vxh/LhAXr+fl45vsSHTy3oXgpylIXvkHDZuTy5IFchbJ+PJ5oTr9yC52/dohwkOwZP7oLRKMmn01K7GVBEHMUx8LSWD/JLMvR7jnCJvntBQjz4GgAXKJ13ytX73/uNzme3e35hEHWS7alAnAd1D/psP/XVHzAkKuXoy3nwwC25JFm6Y2ebkr7yd5oS8zyuL9Qb9rd087vvvms3Nzfthz/84XJInt6joPIcnT8+PrYPHz7sPUiYRgyq++PHj+3q6qp98803i4zfvn3bjo4+He3t8vnqq6/ax48flxkKXXfb6NF0UEjK7w2XAB15JiNzlJhQQeXUU9o0NK7ypLLTvLnKowJxP73K4KFvQn2akuHUFBXTnRKfAuUiI/ngNJVPmY3QDuvtOS32m3jn8J4IR+1J/e3XnAfvF8k3ofdqayP5TPWon+hkuHioNnGrn5CYrqktcoKUvesy26fhv8+lp2k4IsA0Teky9r7WfekIea+CgMuN6XhMjPSNz0CwTp9i5MjHg1E1EkhtPDs725t6cXBQjT6rNvI+g6WXx2dihLgT0G2t7b0NUcfZqA20Z18f46YGBu/0sBtlIj74sBrfCsfRwuPj4/K+B01BffaFZjd4Xud0CSN5LyiowSmI9HjoRTsPCKOA4v+rQMSpDTfy1vYVz+dXmcfrcDnScSitG7WUx9vscqhkpWseHBigqaDVojcNKpWfFJz3+Z34SHqU9MQdn9/jKCvpKOfbObJLc83uINypJmRJJ1EFharPevpOB5f0yOXh5bhTrRyst0OBwPmlXlGPVFfSgarPW9s/tDL1O3lIfeUBwNMzSHmfezBOQIW2obXE29vbJSA7UGbfsM+4q81HVE60TZXN+qTPWs9R+X6U94gOWmiWMBMCIoM+NUDa7Z53WLT2cnqiakBl/Cw3bWX0umeCge75VMHT06etaaqbuwp0TW9gcqdEtFkZvHY07HbP72a+vb3dUyROL7hzkdIklNYbYdCY/Jsoh1MF/k4JUVooJP/UGaVTOZJPeuG5856CgLeb9Wkhl6iKC5ySUXIQBECJhGxVB9vEo5Q9aLAtnL7QdTniqt9cPskR8TdHAmqnyzptjZUeyGFTTkS/rj8cjanNtHv6iSqQeYBnoHAfw/6nLbCMKhCmgJ/Ws1iG+v7u7m55FkRl8f0GzM8RQmqj2yV1TGU8Pj62b7/9tn333XfLDqU3b94so4evv/66PT4+tnfv3u2993xEqxeaHZmIUd6nI0lTBXS0ykfHpWvsdEcJiSony/I8fTJAdjTrdMfKdK4sjiLJR0K/btSUIYeirtC9ERrRPLfIOS+cuhDR2Sutz8F6eakf3JApL6+zkgfLTKjYUa/3CctgP/qoL8lXlPqYRCfqfZny87+jcVKFyBPg8fyp/6hPaSQkhy2nk3TSR5MVL0rHufgZ3afdpz5Mo1yvuwpQvCZwkAJBqtvbmYAn66ra5mCJcma57Pc0wmTZPG1Wi9lq33a73Rs9jGj1QrMjGXdGHDZxaOTp/U1ariwJLTCt7iWFIFJwSoHDlSXVqUUhdpIETiPig07kJ5VLZMohIY2HSI4PoLW2vyjrWykpJ384K7VNyspr7gQSGvR+cmWVPnhbaRhu4MmYSLxHx56CpfO23T6fW8M579b2p7w8wKS2se1cS0p1E6W5M0gBMjk2tctl4fdoA8orHfI1B9XPV+HKwbS2v4DM9rrOUh6iBPpGQYEjEsrG5Z10wfmgH2BfS58pO/kryoTy87S8R1I7yZ/rj9YrKl9Gu690JAWF+/v7dnt7u7xb/fb2tp2dnbXLy8vlTXEzdNCWVDcyClwPVvh+5ORAqCwVJSfuvKQO7FFSxqpzWtsfMqcnan1YVk0NOTpkwOCiFDueDtSnHJLz4W/vK1c6l2caBdKguJPCnRrbQuNKvLGNLNvbKaRDh0cjlOHw1E9ObbjcHZ3pHu8n9Ody9T6VkXuZqTyfinEnz773OtlHfp19uts9H5Wu6VwFBJcJj0BINkGQ4m0g7/52MR/hSi/8WR0vJwUzyoVEZ530lrKRXAiqXI6SQwo+rKPnY1ivl5ue2B6NPnqjSG+D8vE4jePj4/bx48dlmnSGDlpToKKo89UAzYH7Q1cyWnYuO32E1hONRgIVsqjaVNXhw0rvuMoJ+zd/u5MTKkjBLpWRrqeg63JyA/e2umNo7eUDb7zv0yXenw4AyBOdhQck8lEZPZ0hp0R6QTFN47ANvaDAul3+aTqIYCjlqah3rydXOlS+PlNBQfJg4PWRDetIekhHTj0WMTh7HtYhXzAKwpXz7MnFfclM+QwInsfzpzoqniTDXuB1Pj2IVQHBeaKtPD097YHzp6enzx8UiIrVmVpUaa219+/ft9vb2+Xsjd4Ujq73OjxF0N71GfKOqByOiPNxjob58ekidzrJgBIac+TvxpgUXGnouHVN6NudvY9SqORpCkXpGLRYD6cd6OSdZ16Xc0p76NOIxfslvSXM5e8yYt/7lkF3UOxblcfnMry/taWVD6H1kCXbyXTcduzEPmO75IQ1RZCeWufUlnikLfMwx2r6Q86dBzi6XCVbjVBUlqY/yRuBYhpdV061tZdTU66T7MekX97PKpsL4G4LKQiyLqZNOuw27YGdciew6I2SnDi6Fmnk8Nmnj7zT9V8jA00bedpeWZWDT0as36OoXVGaamG+VGdaiHQldHJnlIZ/6XpyZB75acRef4WynRfu+/YjKOikNB3A5xSouI60fTtdCmSc7lE7fMEzBV1Scjjiw4MD+7NCd77I5ySZ+FSZB6EZRNcDIN6XSR/dcZBHfpwvn3pk+ZzuSbblgc1tQelI6gufTiMaT+1L8qMeOLhSkKxo1B6V2XPgvf5MVPWd8+W+iL8dUKY2sf9cJiyTgGe2Launj4QqJFCd2qfpIl9M8rw9h1rVl6J/ay+Rfrrvgq6UMTnYtEODDo5UOWLfH0znrO/KqbE+N6rkoN1o+eF0gf4zKPgOJxkL+8BHf+LfH+hKMuX0Dh2t93XSEfYv58h1TQ7bHZv3ddKPanQm4pQnjc/7neUkA+zpZg9cUN84ImV5PHbceSJg45qPykwolbxx/SPJNV1zOWlqNCFetYF625OD2xlHrymwuQN2Z8pg57aTtqIm6snD+0TXEkhlm1ynvCzKJAVnDwzUnRGteqKZCvX4+Ni+++67+PSuM+WMEpXqekJxvDcb5VxAvc509ONl0IG5Y/IdO57XjYCLmb4QnwKKL3q19nyIG9GdGwIRlTtKDxAqX2gyBQWd+EgwwLro6BXYGGQ8IPoRBi53ypxKLx60qMz+Jd++MJ2AQaUXCdCM+ieVQwfDNiTHkIK7y0zPFbC/3c480BEEtNb2Rlc+MiO5U9Q1zgJQtpUT5sjKp9YcgHAx2R1hCuwV8HASH2nE4EGrApwuE6bRPV8crz4q00d0qa1pOi3V3QsMJI38Z+igs48eHz+9MEJ7YeVARh3kEZFl85tpknGN+PT6evl65dHBMFCwk6u6STTStJ89OSspLvmTYXlQ8DlTRyFEJr4IKnI+fKif5K9AQT6I2FLwV9mOTh2xpU+aT3e+Kifsxpd0IzmdyvH39NnLZZoEgFi/j9C8nwm+1J+uM9U0kZfDPvAgSoda6aePJP23yvT58dT31JVKni6vJGenkY1WvM/wQX3t8VoFscpfeAAa+UsvM/FdjdISrQ4KrX1aVL65uVleKEFjpbPxRruiUcErA0pz6D2jTnx7uVX7lMadre7zaW0vL11Te/mEK+/1+HHDksNQQN5s9l/m7Yhd7ZDc+PYnOhM6dj9jSHXziV86EbVZqJUBwtEYZcSHanhuFPWDepECAhct3dEl+bqxJOeQRlVpCqFaBKZcneggVV/iSfLglBBHCqyP03detr7Zp7QFtzuXHflVm32O2+sjMZhI97kr0cEV9VBpq0A+AobOh5NP1ap857unP5JhogpIcG7f+eK1nl+o2uZTUsknzpa7avro6elpeYsQh2U9J+n3+ZGjUxo/T6cXhb2O6v6MIBLySNeqYZ/zvNs9H+Gh+Vx/UCuhL1EPrfhcKNNR6VwxyQMVx51hQjUpSJJXX/jjLiMPrGwHkaZ+a6qBax5eL0FCLyiQJ8qsQpqus5Sly8bTez6mo6z0TfBBnvTN4xJae/muiaovkrOZIfYFp4q8z/jfF9dlz8n2BWj4Xg9Ow5LPBCxGaLjnZGeDiNuk1+f1VvJONqZ7BFasZ42fS2lTe2kjs3rQ2sqgoNfIMSi4Exmh8YQed7vdniPhdU4/MI9TStPLV6EAotSkqBUKZlkyLL2er3p3biJXKueTH97nyMLLcERJR+uBIaFX75sU3GTwm81meT1gOiqDfe3bPcUH104o8xTM0rRICqrOQ5Ip0zFt5ZxSv/f61cv0ulkW5a0toI+Pn17a9Pj4uIwkuOCuMn0tJ7WTfHngZdCqeHUw4OWxTMpQOshXsoo/IniuubDckRNNjrqX3vmv8nhgqPydAzR+fESX6nI9qfyY+1Llr0Yvs4GxtRVB4fb2tt3c3LSrq6sX+9WrSr2D3Ej1X87k/v6+eySDl927V6E01V3xxfvqWO6JT+1goNB56tfX1y+mHmbqbi1vn9W3kDQVs7V8bgtHc56e5fKI57SQS8fNsslPa89Pdt/f37ezs7N2enoaz3z3aQuVozbohePedx7AGFzcmZB3R69O6Z4vhlbp/R7rrwzUA3LlrG9vb9vd3V27ublZ+ND0S3o2xoOw0wwqdaK8PUDoeGvpgwcHlkHgoLZ58CNJ/ho1rkG6qc0pWKyRg5c3SuP10u7SswRVfueTfUh7pK6mvGvkNx0U9DxCNbR05hO50vCjSOqGX1GKoDNp3Bk5T2kBzB+68vvKqzl7jaS8g5KDcdn07vcCbK/MkSyJ+lJ5dFwpWDlfnCpIxuFTcK5LTFONyDiySY511gioD/5bTsllMFvmKI3Xl4I6nWKlP8kJEGmmNlY8Oxr29nhgcGfU45ELzWybB88EuLxdzlfVnko+qa6qTAeyKX0CUZ5XaX0zgfM4AiFuK37P868NqNNB4erqatlG6fO3zlwl4FFHEdkSDbrgZow/OfCew/VtgBKwFkNFRC08Z+fx8dNLLThd5PX7Ql3iIymEK5yI581Uc8wsJyFfla82+Pk0R0dHe0+uU14KouwzBsenp6e9aQIhG76NjcFGfPXWX9gud3ieNoGL5OyS/DzYJEfVc9Cej4FwhN60OcEfCCUwSYE+9a0/H9La/im13BzgiDxtGmE9DAwqm3vs6QRVRtrOymPm3T64zpgWUnuoekTeF72AIKrWFHVN/HM0QBmJ32pDTrL/BBjc3zqo6wWWEU0HBU0riDGnXgRz5nqRiwJTY73cEVrSf4/wKZj0nEiaSxdRFlp89x0TVfv4yPkIYaU20pGzbb7gyn3m7qRUDr/F22az2XuTE+XAaSPK1J2e+OMWWpEvTPOafvuiOR9Q40N34p8OKPWpB35SAjgJ0Ix019GzB5OErCUHOotZPns6wzZLZk5r9W3ksFp71gvXD5an/hR44JSxAkN6jiA9AFcFhBknn/wCy0l96Hl7cvNvlsutucl3OTnw6l2vdv3N0qqgIOfA19StITqhJOjWXs7Hef7RteTsWY+nTel6CJIOuLXnl2ukg8VSG8hfpbSJ12SYVeDz4F2hV2+vlPXx8bGdnp7uHSnh6XiukjsHLRYzKDAwcESoMhj8/Qnp3W73YtcNjWDkLCujr675SHgUMHidC6SpXsmNgdFPb/VRK3mYCU5qgwMsb2uym0SzoMV1r+fA1aettWXkyEVzL9cDagI0a4lO3wOByvbA0KszBSXaIHWDW8JnnHbScZKvA1ZlzNB0UFD0Pz09XRRX5657gKgcHu/37nEP+toyqiDRIyqdD7e9PCIujRB4bDLLc357uw5ay4/E67ecq3jwxdTWnncZcUqACpyMW/3qBs1Rho6V4DSQzi/ik9kMoD4PTgd1d3e3V5Yf3+DTMxx6s00KFBw5pJFlhfBU16zT9+kNR3pE5B5ovb91nbLRN0dK3AVHJ5KuJafBaz514+1X0GKQ9vO2lN/rdWcteagNzpd+6yBFIue0TVXlsR0uT2+v95//rtKmwOBrG7zm7Xae1J9+FMnT06cnzn2zhMqg7FL/UtfJiz/YuJamgwIfT2fj/AldDvtJM+iGpAb6gkxFhyCGpHhSTHeoFaL24yqqeqo29Oanq/aJNylbyksn78bsPFWo2p1V2uXD+ywvOZEUINJw2B0fnSPb5W2qEHElS3em/N/L63n8Hv9X9pAoyYmI051Pcs667uWmxeqq7zkac7BziJMZoWGNHH3kWZWzxsH3eFqTNjn+Cvz6NbdvtsO3iY/aVgVh/079NNt300Hhw4cPy0iB7wNltNfe/JlpFKck8FH0n6GEvhNPRClyfqkjW3ueMtLHt566o1R+P8+cDk5yrJSPKNUX33yUxnOCRBqqu/OmctEZkAdO3fB0UqX1E1LJOw3d0UsyFsqFvJ6dnUXHoWvsIw+Ijqb8uvdHOlyOaTw4SjYERyJH+prjd/1IlJy5I23VzSkvT+vbOh3cuL75aMH71oEFA5PXzdFCAkB0jHd3d8vzLb4oToDoU3CjoDOimfwpIFYAKMlEIDKNhKQ3HI0zH0cSHDWzPuXhFvFZPXNaNX2k4Y46kg8YsTN5XrsrMRtA4VLIyQB6fLEMUtXR7pha2385iHcwy/ED7ZTOHZ46SMqc5OC8utFQsWgkNBTV4wZCB68goocPq9GF18fpMx6RQaOsji3gPnPx7Uoqx+OH5LmMlFftYTtTG/w/66O8qXceUDyQELHzaA7WwdGz85NQenKSCfl7f5OS/JJzplOjTlTTngQpSXbJ+bvMfT3O9Zhl0mkKfKhc3zDBUaPLpfIZLjuXV6VPLJcyZEDweslXkovbmNrOqTrvEwJWHXvCulW/P0s060dJq47OpjORUzw5OWmnp6d7KJhC8UU1p4REVNcoeq8NHMzj+ejUHBW4ofi0kfPiCuaOvlpboCzckfl8vfOWypIBacRwdHS0vATJRxgJNTPg7HbPDxkKFCgocIeSKJ0iS50gEqK+uLwos7Twr/teB/vQA2YyZsqe9ThgYdBwNOf9UwVel7nK8QDkRu9OhbIh725/zj/LpMNlMOR6ESnZh7ctBWaRrx9J16VfflaT7pMP6qTX5XpcgTEPBAmkerlrnGsKppU+itKJriyD52GlEYMHuEMCQmsrgoIvhOx2u3Zzc7M8candSQoSJycnywKsplgYCX2BywWgOmRwVYCojMw7sfrN9knojqQpYB3qxfcIEG3ROaapnaSYiVKAosNKyNoDD9GK+Lq8vHyxDsSyE58qi0dZVE5F6cWXb4Xc7XbLaPP4+HiphzLkkRyUBdsjnah0o3Je6hMZIPnzaRjx6KMzBoAURFz+/lFdFQp19MvnXvhsDOt33Rff3r+85/3P/1zsVn2UT1oAp0wYZNh3SsupTdcvydJ3vrlebTabvfeRvIa8DRWxLe6/km1z1OMzC9QTluO/RfShR0ef3rQnQOYAz+1iTXA46OhsVkRmXFHVuRruMF/qhCTcmRFDVUYKDJVw3EgdrdAJpikcpiUvVcf0AmJPwT2fvn3hV/VxWK50LMv7oUJ7lIu3OQWISl8cWeu/LzwnZ857SZb8n9rWkyfzOYKc6VPx7mso3nbnz9NQryQX9illRzvjaC0FCfLMckXi3R1WZbe87qM3pmFgqGTvQYMPfqmstCGhBxZTXWsc42z6kY0ncJdAQvIHTkpbHYrY63PnrUcHHZ3NaC3l0cs8pKAnJyft7OxsGTkIYd/c3CyOSgruQ2I2IiE63VvTycznHa7yFXFlHORJ7fSXYUsOLJ/UW+j2TkzIgcgyKRFHcOKNwYX5yZ+jMMlaaDEdSMf7nPsV33d3d0vb3EEJiXrAU3mSIfuAcqJD6gWGngN3J+gfOjKmcxm6LFO6Sjfdme12u2Vk9PDw0G5vb/eMX9e9bXrKXJs/jo+PXzwprvl4Bqynp6flKPfdbresA7rD8j5QmXTY3I2ovD7Nw/sshzrEdSfyy3Y4GuaolKPKJG//nQJ9ypNA6mw5XiZ95Gbz8p0nKU8iAr2Hh4fljLHU976GN0urTkntMapvGT5Pujw9PW2bzadh6/n5+XI/IaVUtqPT5BydekjN20Wn4IvjIl8MokwqFJDq8k5K6RggksKyfBlXtZ/d264yfW6XiGyz2ew9vEYHob47PT19gXgqJ8l6eF3Po/A++U5IlWnZft6vAIYHSaJsOrlEaxBp+vZRDmWgaVa21/sj8ewoPCFvyoNPEbtuMK3vpmvtefca2yn9ODs7WwCGT3VxNx/bwzq9/1wvOAqiXVCfFPRm+mfUl/Q1vJbSOWKnXBWs0rlxiS/P36tf5SvAt9b2nh9qbf/tflW9iVaNFGaQOY1Pc1+tteUBKL0YRtHSh8cqI5XbCwAVLzPtcuSWymDAq0Y2I6VUJ/lQ3ZXKg4y3k4ZMhO27XpJD9YDh9UoWOuZCRucjCl8gdseS5Oj8c0qoIg/+qY4KLHjwdFmyvWmaIwX3GcNy55x4ZJDmx4MdefLRDBF1r55UF6d32ReyS++DFPgfHx+XXYcauVAHHXClgMvgx77i/LuDhdSPbjcu/9Q3/K6o55w9gPMa+fe1R4LJiofkA5wXrsVwit5HMrPBQLRq95EoOfBUMUcNmq4QAj07O1vS6YgIogyWm1br0xCe/90ZVI6Hu3OqNJw2EkISX1X5yVGxDcznUyhqm+//TwZPY3ZD57C+59yk1NzqpyDOraUMBGkbpA/5kxHvdru9I0HOz89jn7T2PHfqbXClZztJdIaSK0cF7lAoEwIb56FybsxTLTT7u3Id8XJKUjbD+liH+odTtyK9d0HX1Ye73W5vp2CSqcua13x6U9OG4pVvJuTvERKWzrnc1b7Hx8d2fn7+IrjwmaJKR1iHX/sc5PLY7Xbt6upqz7fMrn/0ABLTuG6rvwXoNK17yLbU1UGhcrqkhLY2m82ys4DogAaqRm42mxeoV6MORmXVlYLUiKggRClJiahwqWMrhezxkhxGNR3gbUvOj/wlPrwsR6UuE8qAQ3Q6Vi/bgwNlkoIgr3N6znlw/t1hVTJNaVMQSHJOH68/pa0CQtqYkIJqAhDuqCkv2VVr+y9npyw5ImM9qR1JHhXyJF9prYl5k92men2aLfHLkbbypV2Dr6FROZUfcD3mul2yzdeOVCj/zWazHJtBndLv2bWFg0cKlWMiJeSl9zo/PDwsEU2I5+TkZFmLUCM4n03k4fUko00K7Pk4x3mIDFJAYHkpeFbOgot4yRmkxT+VwbqSXHz9gzuSmN75V14ZPEdVbrxcWOSWXToqjbqEDFUWz7+ZlTv71+Xp7eI0BstKxtkry3nRNxf/OM2o+x4I2bfeNyqP/eFOkM+J+AhWgcIX6zlKcr2hnghl8uPTiCy3tbYskO92u+XlSprSqPQz2Y5koYcid7vnhwW5+cGD7PHx8d56X+o3yv3Q0UICIq09I3Zuv6duEUhRbhUlYNPTRZ0owT7iOs8amg4KvSjj0V1UNYJTRQoOciZ8ao+LcFLi3jBsJlhRKbyjUjr9TtTrWHf8FS+sh0NmKn0qW8Sy3an6dA7zqB4GRvJEooPz9GyX6vepEA8KrMcdu0+vJJ6IRqs1CTo5r8PvJ0ecpgb1TafKeV3pqWTAqRDKIQERypSbAbgGxdEz31zGfvKFXDrApIdyGLvdbnHibF9l07zmUxRCq+yj6ugYLzOBHtYjWaW1FNUjh+x8Jx3vfSdeE7mt0w59ejfpQ1Ve9bs3StFUXmvPU2ualpulg6ePUtRzZNuL1lI4da6+ef4HDb5qVKWwbhiJ52ScPRTRi9QpnaMtkSO4NCKogmzigXP9qV9oRO54fGRSKVzlwFQWkWxvvSe1nXWMprX04SJmJW9f4HQUyb6vnFXSPxq/z4G783G9dXmrPA8Y+l2tzWgqVtOqCcS47qcg52sm3i/JgVHfPDiqzdxtQ5v28ipQRkp2xMDLfkv67+WOQF7ireKr4tPtjPzOjlJmArLLZrfbLUFZfDj4HdHqoFApsytlL/qTdrvdsr+dRyacnZ217XbbLi4uFiTCYVAv+FTO09ugiOodxU5kedUnKXYVEHpOPuWh4Yk38pnqSKMp/ecUHJ8lENHBpPlxJyHYp6enZRNBQmLeduYXz6pf9WprohDgdrvd2yrrbXT5EWWnvmK+XlD0aSSOXF2+TO+BxvVKiJw8Or9qA3eXsW98PcwDiYKGy0f6r2katen+/n5v5xn7k21mMKSecCup3jOy3W6XjSX+zIL6Xm3gaIt+xkdxDqZo076t3HVxFCQqPekRZag2uU+sRrU9ctDK+jydSFNY2tijA0zTBolEB60pJIeTBEnEQ2JaGo8fmeDzmEm5e3OIzh95cmdV8d7aS6fglBBaFVi8zCoQVO1UPTT6ygF5Oc4rr/towQNLJS83NDcCXiMvMm6iziRXGhn3q7usZ4Jwaotf9w/1q0LgXm513+XnsvKpNcpKUzEe4GQXfHtZ1TZH9H5feqZRSAq+PdlSb9w2td4i2/bjK1J5rb0EOAyUSSc9mHjfzNKaoOLBNq0R6X8FPKq6SRXwdr64vrHZbF68TndEq4NChUIZGGjIycGJkoPinl4pO89VYllSYHfanCdORuuKkwIGpxwqx1JFa90jElTbuAjp6wHJeZK/hMZSXvHAhVxHeLquxbv0kJGjzu12/+lTV3KWLcTvh3yRFz6lyofvXAaqO52FQ3knGVZEJ0KZJaN1XfL/HkhYPstOQVr31EafplI5POtHTlGkJ1p9a7UHd46cnHdfA1GdevA0OTiSb6eWbimdT3fRUVX25R/avdsaiW2hLJm+BwIrqvTJg0K6JxlJLlXZ/t3jzftEJN9yfX3ddrvdMuvCp557dNDZRyMmabT89gYmAei/yuJWN86DE21wCsOdQ+qo3mK1D5db259/T+9h9vl61k10JoP24yJSx4oHLuIlo6hGCronPnSfozHJhsd2KABzn7z40OIm6+e8vWRGREhe2CbxzfooZ8pAAU5D4OQIvO2960lWlaPv5e8BHnc+Dph6bRBxCkdggDohWemJYtkIZa26qgVoyZpPEUtvuIWcx4V7MG7t5YGZSUe8bC5CS2/Io+sCgVq1gUD1sa4eeOsBgR7xPgGey4XkU7XUieQD1hLlvds9Hzx5dXXV3rx58/mnj5JTT4JMip8MZIaIKpOS8H9CYVW0dafP6ylgJHRUKZrzzsDgH/JblcfA1OOHMvJg1pOPy4rtp8FUw/XUfpaVyma9aUTG+vTbjzrw/ushwR4gcapQa0LJVVrPl35Xwcvr8YVpjvhcLsyfdKpyQt7fCYA47wR/5DW1wZ03bcJtOpHXM6LZNM7byD8lebJNXr/f7/mWVOeMn6x8k8CDXnx2cXExJZfWVk4fjZxAlafnQNc0nAeuCWHyYDAuvgmR9xw/H5SiA3LDSgaRFGS32z/7ydcNqoVb3td/R3et7b+rWKT/aS8y93VT5uLPR0Xa/utnHvlcNKd6fE8+5ZyCthYCfYTDoKA8OhqYi2RVQHdd6Tle3fe+IwJNASc5gRQERs6lClLSn57D5gGEGsm1tv9aXG3l9j7yLZ2yAT5PQhtQX7vOVc7QryVdFz09PS3v6r68vNzr37RQnIJO5aQpt5FvSr8TVfXRNlgO61ea09PTvc0BvYDwGlL58oMfP35c3lw4Q6uCgiMwp2pkQAHxmg/v3AC8bn77EJpKRWfn86TOD+tLC+LKm4KLB440GkjBhWVVQYL1Oz/k251rQmSu/N4f7px8LYD1psDJPnC5e13c0SLH5nk5JUUkTIedjH4mICRdTH1eybzSA0fTqVy/nvolLTgnp0iZu56munhd5ftUhrfRp2iqqco0PURZODChrBSUfETkvFQ+wfXZfUwKFFUfVJQCAuUxKkt9Q3lwGpd5ewEi3esBJPKpnZ0ztOp1nFIoIgfvxGS07oz1nebT2ck9IfOdw3IevpWOaw0j4hBcdeg7OWM6Po4OqAA+VZSQSe9sEudbdSm/ByKXvYxtt9s/V4lpaVh0LFxQZv0KuinoMDhXAYlBQX1Gp6+1IvGrdOyfpGPJWbMf/V5Px1LQTuT8eN10wCl4eFo6fup1WrcREtQ6F0fGKdjTWXMhOYEI5ef2ZekE9S/NkbuTYxscdKkuOSx/70oiByXUxaQDSd4um+RYe/pD31Ady+Jls096gKai6n4qj32ouu/u7oZ1iFaPFFRp1biZhohSp43KcQRBJdcWLD6pywVTR0M0rITiklNXlOeRBnwqlE61QpnJEfsag6MdD7oJ1bnM2MaEtPSf56VwqkZTEOLNjZuOSs7c+zQdVpcQL/tJPMgxbrfbF/us2b70BKvLgu319ie0NnI0bEtVb1oHSg6KiF/bTiVrLgAzKDjSTBsSvO+Ul0FWz334ETLqT8mcAEM0eihKZWjqogqIPDpcukC5+cgmgSv9TuV/bqJvmHG04p8HEqYdSKmeKliR3Deon+i3JOMZOuiJ5oT8nflkBKkMljOqt1e+o3EpEBGn0jOQEJ15Pb0O5/ytG3/PqSSnUOUl3z2ZeJokG7Yz8UQHTaXiqzF1ThXrVBD2YMGAIdJ9Ojfm9REDeXL+HYU7+p8BG5UMewGh+s1PyuflMb072zQN5G3k6CD1W+KDMnU7YXoPVuLJ2+lAhOUx+CRgQKJz5UmrSU8TuHFZsw0pv6cdUQUa1uRNwa3yjd4O75eqTb32zc6YtHbgw2teYbrn0WtNOSPEx3xCF7rvDlWOhtMUvvOBwvZhtq9FaBFPe4C93sSDOxyuc9AgqjlbGjCNMS2kJ37kQDeb52cXHO37g2FCo3oqVeUIVfqTxVz0VLkefH1OU/yoTuYXjz7XzLI5/06dcBo5Al+v8AV/1l0FCueP38kRuzycL02LpLaL+CIr9hnL5IYB5tcIlyOJqn3km6M2lcs6CQT0Rjjpn6dzW+F2b+2p53H6PlUpSr6Gtt1r0wh0VfY1O0rwPMkfOO+8PqLK16r99DWzZR4cFHrDtCp6zQQHpe+NNGZ4o4HzP18Wz+kO1uXfCgacMnKFrpxFQhnOa4UO5Pg8vShNXYjXyhAS8vRpn6pNcjqSqaYGVB6nKFwRK+fJgEFUyfs+QkhUoaWeDBI/DKQOGhwEsD6mrxZye3z00rAcDyxJH9KmiiQHBw4+sku66SM61pVs1TdeqO4EgFpry8iHz0WQl54cKxuc/U/qofgE/kZlyna4CUZyqOpjmT1ee7rfy1fRqoVm/+1MrI2cVcSsynOn5WlTXs43O3pP57okx7jb7ZZ3TOugLzo+8pJ48+sJvbhzkdHQITiC9cU71enDRHeC/O0I3xfO6Oi4mKmzVbhAyAfdnF+2PU07qCyfp1Z6ydrnm9c4Ah9pzRgMpx97BpwCV+WYXR6t5T6rghjbIl1SX/o0D2Vd6Qr5SfP5DiA47+8jdTp7tYkbMNIo1/X+7u5u76FGB2FPT097I0yV532TnKnL1IN9j9YiefeTnOrzwEz+0m/3BcnPVACgN12V6KCFZlFaoE1M0eElJFo1JtVbOdTqfkITNKKUhh3Y2qfnI25vb188e0CDcuQgR5ZGFbrfWn6Cmo6QRsqhYCUrDe/9uFy2mTy6vJwHjqz8TWgyYL2vWfXpzWrJsaW+Uzv5pjf1gRwQgzynX6hTPX2ifEb6pv/ON6d0OAL1D6dJeg7Hp8akL+SBo0Gvj88QyGmIR2542Gw2y2twqZOsy6dKkww4SvA+FK9y4qqX8qAMGGD9aemnp6d2c3PTjo+P2+XlZXTc1Bu1vZozTz5j9r7fq57LqYj8Sndbe/l0s6dPgCKNBNI15z8Fxx6tHimsGQ2QsSrfoYEhldOLmlWeVLYL0nch9cph0PHrPv/NjqfxeyBl+oSMPT0VjzxRRsk5VsGhQlyUDaeVOJLyNZtErMPn9z2vI1uXSzI05zkZWuUMqyk6X7SlXF0Heg4ntcH5rICOLy47b+wDOs0qQI/4S8HA+8KDVKU3SaYk7nZSucxb2WxlQzOAoScH5Xc/4O3pydTl5ch/hrdZ/5v6ZpZWBQUpHw29WszpkaenEqW0SjPDX8rvAiHP7qy5EybNzVb1eADgSCMZNxe6fTpDPDkaJUKuDKO159GHHAG3zfquKxqNI+4kS33TIemMFZG2BotXlxHr5VZUpfUXsygP5aJ0ThwqV7tjkj702qjyXE9pyJvN82JqekhotIkgBSGVSeTPdCcnJ+3p6WnZbqg+dp2XfLmTLPGg9voIhg7MA11ycuo3TStyZJICnNpHvW3tU2C4ublpZ2dny0u3vC+U/vj4eO/EA2/fWsfoJP5nRwgpP8vwgFAFhdlg0aPvLShQqd0B6jeZ8Gu850ialKIbBVPlTYJNCDCV7eXI8fDYB77aLhmrt7HXCY4i3dm4Y3LFTkHG63Nj5U6EZNCUYWsvz01yB8i2Sg5pWuL09HSvjN1u/41vdELkfYQQkw5Qt1zOlZPz9P6f/ZkcgvcH5ex9mfJ6u0huZ2n3Def3Ob2XppV4FEoFllzfyAfl5XrlZXGayb8ZIBIfrJcH5+m6r2M4L97Gnk9g+3p+i7qRHLXrY68M+RQCq2THbnPJx66h2TyrX8fpzmK004FUGTHr6Dnsqo7UGW6sIkd/nv/p6fmtUXrvLE+nVLl8upP50xA78asO92DrqMxRrCs6EWT6v9nsv9Q8yTvxnHaKVMGOys4AwfZzYZGI0heXPUiqzhTIKiOpnKw7M6VV3vR0qvcD+XD9cpRffVeApge2GBhYPx0Ly2NfcZ2mapP0hOsmVXtFXGx2x+a7bEQEDs57sn/ZInnrjbocKCWbYX/4717fJJ0iOSBI6eVfCIxGZY/qre4nXZuhg0YKCXX1kND3wbjKZB2Vk2ttf2isvJxjFR86Ivrm5qbd3t621vaNSnuv9dEitDsDrkNQ6elAWS8dcdqWSYSSZO0oVuVxKqy1tox0aIx05uSl6lfWobRSdPKjBUOfrmMg0C4T7xPWwfKSM+ZUnfq3GuarHAYi5uU0lTsd3qumTau2JCeU1kccdIkv8iR5i4Skt9vtskuOu9f0lLje3yud8HUGylNtTMFEU33n5+cLn3yXujt2BrDdbrf3gJr3DeuTfDUC4vHP1Cf2j0ZEricJJM4i5946QuW7UmDXb8pXz2Ok0ZbSz/LJPE5r/OxBC81VJBw1IHVkYrhqVMXPjNASkkgOhnPwaZePPjw6gzsSesGxWrQkEhk5/1R2pZzJaKo0PTTk8+qUhWRGh0b58hWr3q40r0oicqR8lD7xSfmltvpv73/XcwdA3oaesbksWI//VppeffrvgYNTSAwe6nOuk0mu/E/Zudy9PV4e87TWymmhFID139MlfyD7IrCrZMdrVf0ztpVsYqRX1T1+EwxU7WGbkp+aqdtpNrgctCWV6K33JKT/T0Ek1dEz7BF/lUN14buz3G63y9PKPCdEjk2LqTQKve1Ki3h3d3d7yqv0NBKfR2Tg4Zywo5E07cVy0xCeyC8h27QuktCVjvy9ubl5cU/8aITlUwK3t7ft6Oj5ndtyJkKbQoKttb0D0Sgb9huf0KXj4xx2hfSdd/aHZMPjS1TfyGm583dHUhkuF1ST80mjHjpI0fn5+V4bKB8/50g6nqaUfJ6bu8r0FDNHJa7PKpvluW4SJVeBh3Jk+/X+aK1TOQmspRdh9XxJlbYCSz2AOlqIphzIb+JD1w71h4fS6t1HSeGr1fTW6kXXSsge6dO95DhTflLqaPLXGyGQH+7B5gLa6enpYnQa3ittkkVCxo4YmN6nlFJQk4OlMWnB3B2u76XvBVTW68HFHWuSseTB/ehcGKQx0THxzV++tpKmttSPLjv/n/J7e0aUdM/roTwrnaUDp0PnhyNR/U7PAZCSg+HzHqqLz+o4cJLTUl4fXbDf0lRY4ikBGh89eFr95z7/np4SdFX9VFEK5iP/4nWkulzX1Ic82Zm62wMVo9FCNVqapYMOxBuholmmKiTHeylCJrRWlZ9QrTsOGZaCQgpG1eKWRgx6slfGq4fdONfq7eshEHe2SS5EXFxMJvKUQ6aBJ4PhHLTzkgIA54/lLCqk407MgwvnyIVidU3olDx5n/p/lyfr5D133mxjZXiVbvcASoXyqAPsuyooEJSwT32B3O3T+6615ykizu2n9QPqVzXaTg90uZ77Aizr4aiD7WZZDAqVXZNn5Z9xij2nXtmnBzf+nwkO6jO9A9unlpN/SzpYUWrDTL7WDjz7yB2TKuwhhF6EZZoqbcpLZKgy5Ni807i3X/focGVoKSiQ1+Q0id5kPOfn54tjU2DQAiCVnsrrCNXRdhpdsJ1+dhCnwShbR6WaGquUW/f4jmR3Lu6kud4ikowkazoBBQ2uQSQ5sI4UoCknBi03PAbI5Cx7SLOSk/QjOSTXPf/v8vMypaPkkwGVes8AzR1eaZqKi/S6rimg9JS580j95NSpynZdU/DntBZ34qSpH9YnfT0/P987TdXl5W2bdYgkD06ipI+J1x5RJgI+ulYBD7+2NjjM0quOzq4QScVI1UGOIHoRlv97dTqaUH4KnWVWCCWVlWTCAEkHT6X3BUJ39K4QPi9eKYPzRsTH6RcGBjliluu/PQC4PN3J8R6H8MzLetxJ0VH2gISX5W33Pk51e5m87nImPxU6Jb+zRp14oPzkMOgsqFeV/fnOKjpUP4LCdU7lkY80/+/95tNgHvQ8D9vtwYY8p75Ju5yqMisf0fNRifdenkOJdWhtwfXawUjio+dPD6HVC83JETgjleMkucM9NH81f8j7PCOHeVl2GiWwDDeM5NCEYlrbR2iaz9dTmdzGmp4wJV9cbCWipcH6E7S69+bNmz0kScdwf3+/t5WWwYJTBtwySuI5UK29fELbg7DzKllxcdidXHLAbJ8HHPGs6S3dS6MOliceCQw88PWckOqhgbujrPJsNvvnbHF/v3hzm0jBSt8+96/RqZ67Ub9zHlv5EpDqASGf6qI8XXfZhy7/Kih4vSrv7u6unZ2dtd1ut0w1+nMwbsMMjMnRetuqUQLb0aPKgbu9cGTsQEpt6QWzSh9fE8BWLzRX153xFOWSU64ale5XUb/id2TcVFYqAZXLyxT53Go1CuBDOqpTb6KSM/DFRJarOjXdQsOXLJICVkbpTtsdPndF+OiC88p6exRly4BJOclJMaj1UKPz70Gl0hlOXXj/MMDrO+mt/07TfGyzU7IHBSnnW+WwP/S/tf3dO55HPKnN3q8qy3e2SJZeH0EP+4EbLxhIaDN+SKHLnLz27NaDO3WAck/B2xdqdS2Brh449A/LS+1yVF4Fg1S/2uKAic+g9KjSv6reWXrVgXiOznmt1/kpUieme1FwpqM8T4+nKihUypWcjtrNhUGllSPVt4LCbrdbRhe+GMfyiRirRamErByF8Vu8JdkwICiPeKeDd6So9ou0DpEWKskj62C7vX5Hnd7+CkklFOzlOLF+BxUOMJSGcmDaqo/YZg82PmWkfvF6fBSpMtwRqyyuOTg4cJv23Xa+oUHrQ+xnluuy83veT+TT7dGDIYNAKiP5iNQHJMpuLSVdSoHHAzv9xIz/XFP/IXTQSCF1ru5TwdfQyKn30veUjIuW7hTciSuNI7XdbrdnNGyv8lOZhNCSzMTP6elp22637fLycpnOubm5WQyNQYDl0tnIQVP5SVRsOXlf2HXkrd0QetJSvDOP6pbhcgH94eFheYpZQYR9kgKDeCUilfNxVDujg0kv6DgYWH2ER2PVtwcAlkUHm5yw2uM8+ly+OzYGfgYHdyBEmkkPfRrNHQ6BCnUjyUZ1cKTgzt6BiGzBUXwK0N4H4pm2oLRcE0skHa2AlpPLTWW4zZHSyMcDoPct/STtiqMtPuvB/In/2UAwCoakg59TcENyxqsIOUMp79o8vNYLIN6BHEa7MTu5TBK68DQ0Nn/Slwd/EaG5Uqcy3em1th8UkuElo0wjC7bd5cU28a10ohRsU9ler9K7g6EM1gIP1u0L0mwPnV0VFNLUYoUU3aF7e/m/SlO1lTxVC72VrBkonD+2q7V8IGbiReS2wP5s7eVLgjywJhlUzprXnBeXq6djuS4zfjOd50tycJt0+VBO0jMfZbkvdbvztn4uWn32EZmqomdCgp+bXOjeQVTCqlMdGQkhJwfqDknfRId0gNwCSCXXcFuLrKpvu90uT2rq6eCk9EJerbUXKNwNPT0hzWG5rmt9gKiTZXq/M1hplMN3OdP4dYw2y05KnNZJJBfqkz/vMGsQjj5PT0+XzQXe1474HanKeMlX5ciSc6p0lTz0grbPpafRVKqH61Y6DykFY3dC6me12fvQ+UiLtL11C1+jUL2cjvLRLdMzqFWy82k3JwdsapfKmp1OUp4kI9blAVRnh6nNDq5YRhWMPhcdNFJIyuPKy6E/jcuNpYf4eo1PAqKSjYzQ6+CbypJz8KBAFMly6XyqOXD9lzLoP9+VLMfFoNXa/uF1dJAMLtUUjepxhU1bZsmz6jk/P9/re/HMMpKMiEY5MmJf+LELlVMckaf1urT3Xruq5PAo17S+5GVWdSTEnXjyhVHeY9vT3DqDiDtZT582OngQam0foScdcNvmteR8HUjouupNzpe2Rv68vR5AKzm7rlY0ul/JpFdvD+WnvPQlvshe1cV+Tjw4zQa2gx5e6xGja1J2T/N9kaOHhNzYUXRqPmdaTQvx28ukEVSORUZLByrHudls9nb4+KiDBp/alhZ0ec959SBKnuXY0zlAdPgMov4QkgdJ76t0P+mH1z9CufrNOhQYnp6e2unpabu9vY1TL8yf+o73WH+aa/Y2zOi/2xB/++Kzvh3YeHsSWBEvCUB53WwfZZqIAUeUnqofyXoUFHrOfyYosKyKqrKrNJU8vc3UV93TOsoMqGW5PV7X0KqgkAxvZLhOCXmkRo8aVS3U6Tedq9fJ6Nza/oMjPedAfumgqXiUjSNfn2Jg+dvt89OcejJaB8npqGEhWk3TPD097e05Vx6Vo0VjBRU6DB37LTlWjmyz2SyL4i6D1p5HWHqmQfzf398vC4xHR5+OWb68vNx7nzOfAKez8qkG8pI+vJdIhnZ6errskrm7u2vb7aftwVrY65XBfpfz5ZDf3wJXOQR+p3vOh+skF+OZnt+ttaVvPWi19txn1CXphHRI91WPP6HuiF6ghSDn7u5uD/36hg8fsabgxH7W5geCGu6MSgFA99J0jPdJ1V+ja4lm+tjvSbbsH19Mn6k/+dg1tGr6qEIuVeVropVH2LV5PFA5ryNBVciKEVzEdle88rrP4zt5eTR+PZ8gpWeg4xwxH7yr0BERZTWt5Wi02kqqdGk+m3U/Pj4uQY0Oh3X4XDPrSCOBXrAQH+SBQVPX+eKWqrwKGFCXfNrLZeiBIDmhnj5VNjealvS2+4hVTkd644BBvxmwOXJ2sJVkprQcsSvQ+HlW/tuJdVQ655R8Fu8xf0LuKb3zNJOud51g0vngzisvw3X8c9LqJ5ortJaEn3Z3eDn6T0pRdC1JeZSfqEbki1NpTSFFd30TfXiHJV4cTXlbHQFxqxpf7HN+ft52u93ydKqO7dbuJfHANQoakqZPXP6UmfjhC1E80Ck954m50UCKrVEE+WNeDzD+6W0pdp4TaQ1Bp9jq6V61jQGj6mPvU65NUOZ0gr4WQJ1yvUoAi1OQykfnTp1W2Wqf8vtDiHTO2iDgO2DcUVOPdrvnNxFyulPXOIp1m5A8tNDtfkNl0tFTT3w9hLIlscxqhOt8pd1SPb+TfFTqV6decBAPPEXAp2HXAu1eoK1o9UhBlJR4lN//V0HDKSGvCmGMkIGX6x3pQ27l9cBChU0Hf1HJHD2x7NQOPgOgPDrc7u7ubu/8/LOzs2VBWu1R3dr5Q0TLh884l+5yS1M5lI8cCBGf5ME2cheVO8RqjcH7KDmPVCfrpb46/+wvjWSOjo4WXh0F61sO8OLiYnmXhj9TwrwOOCqHUf1Wmb1RHdvpKFMO3ctOes1r6tvT09O94xfIC3UjPQ/gZXq7+E4HTQt5XxLMsE1sd+WIZ5C5ByDyx7Sevyov1TnjxL1u2TJ35HlgqAJFBajXBIfVTzSP6NAgMXL8owjsZXknzdTX4y+NCNwBVLuVvE3uBNI9/fZdMa3tn6sko3GkoyklysIdvT6+ra+1l9M6dKycV3ZUpvwJKSb56ZN2vug/AzGvezrWlYCCB2fJlU/j9s6iUvDgOo8/pJgcbi8gVPwnOaX/LldH1hzFkZyvFHj9uRmWT3lst9vlAcZECRD5VuA0mnG5VOsGKQjpu3LsrgczfiulS0Eo1Tvyn2yvgjKn/VKgqvxWasus/27twKDgSukKNUuOXFhPr6xRJ/qco5edHGnPEB1Fsb0aKaS6OJ0iI9N1Oh9HtBwleFly9hqma1rm/Px8z0C1B9/RuY4c1oKvTwOxDbzGHUhHR0dL/Xrvr6M4ORQdy803dnG/Oc9e8rWOSq94fYSyiTBVhxbtnf/Ly8u23X5ahE56oPdzPz09LU+fS158voV95XqV+OyROwCWl2xF/KZ3IKtv9P7xu7u7velJ6ZJGgNqC3FprHz58eAEYLi8v2263//Q+g5B0h6Mpn7L1+tUuX3fytS0Pvmx7CsI+8k7AbaYfXN7kwfmuqBcwnp6ej7LnNK/rpLf9c9KrtqRWgWCNk0+O97WU0ERyHgmdVciJ86Gexw+zS0qiTnb+HG3rviME5iMxyMgZt7Z/jgrva8qIQbFSagY+b7vLIE1fyQlw3pl8eT+wLhL7MgUDllcBBm+LL37KkZ6cnLSzs7PFYZIY1Lg7x5Fnb0tqD2kmVFtRQsoJTbIeOUbubKEOsp84Ct1snl/J6n2XHKHbfOor/ndZum74FGYCBUmnku14X43IdWoEfHsOfyZ/a/vHpdBeUnmz9L2NFEaO/TXkRn9oHVKiZHyuWI6+3LB4rg0NnsiHToBrJET3leNvbf9U0tRW54vpVPbj42O7ublZ+JVxMx0PL+NUAMthgGut7S2ibjb721qJ6ImYn56e9ha9hTyJQun4E8plWUSnns77l/1K4yel0ZgW63/wgx+8QLKOWDeb58VU9YcCrI8AUxt75COA2TISeEgOUbtZNIrU9KJkq37iyE9I9fLycg9ctLa/g0ny8VFDAjfePr66ltuG1WYfUTJQsL2VbYu3ZMvJr1WAo5J7ApOpndW1xC83mYh/57cCEfRDh/jmVz+81jPOXtrPNexxdJBQZGvPxpsWbhI64bema7TLx9GwvnldUzecbuIUixtdQpsMQDTgs7Ozve2dcsT6Vnl0wuRLKFhTHnRkRCiSge5zJwRf5K58nCaT7BQMLi4uFl6IUN2BkFfKNaFIT+f64GWwnrOzs73puIeHh3Z1ddWOjo7amzdvlmmkq6urJZ1Pk7HPuFss6eEa8uBIx9YbrSkN6+ZITQHNpyI0TcH+4xQr7UHrLhxpcLTkz3zQ5ryfRGoT1880dUU+1AafDvTy3bbJD9PMbHSpHG+qK+X19PzukfRSzxoJ8HkZHoD43eO9R5/9ieZZ+hyji8qRJ6fRCxh+39MIDfHAN0cHSusopEJIvhAoft1Zel3qbO3aIFLjFBYNko5BdfD5Bx/1kB+OivwsJX9gi4bKdnJKgo40zf1WiCw5GHecrgsVKlMw4wjK53L1wB5HV8nhehB3EDDix2WX2sZ2cY0ntYsy0m/OTW82m2VrLjcY8DkSn65J00OyC8mBSJy8jNrnNqIy9c4RX+fyMmacutfv8usB2Mq5+v8ZwDsKMP6fZ7JVsx/MOwpSs3TwO5r56XVMUmxd/xyBgcQ6KoefojV5JApRIND0QjVX7MGgtZfvchbaEdFIRXoiWE5e9x2tKY0fWa374lVHWGunzNnZ2Yu3sYlX8c/rHNazr11JU4DjVJNI7eD5R2lI7A5GeXy9YcYhKK/Pk2vRX2Vqu6+CwMXFRbu8vFyONtcIiwGCfe9PjFNWCbgoHeVHHRFv/GbwduRLnfLAycPvjo+P2w9+8IN2cXGx927uzWazjOrYX6qPusa2erDncyncRu06kpyq9IJvBdSIztucfifH7P6nN6Xb06tDUPdrHbSACo9lqaYoZ+qd9bfTQSFFqhmqhDnbGWvzJcUgYqYjqoxX9zVl5GkSeu9963cy5qTsbtTuDLno7bw4uufiaGvPwcr3QHOxj46JRkSeUvt5z2mE9ug0PCDMjgC8PiJnfrwfuRbTWlse7NKUheRVIXR3PN621l6CBPHINs4gY8/H62wr9UF8uzz8aWwep+IImSMhBwfSGYIXd2DJ1qhDlWPnyCvZdpJrRVX/fR/gtBphzBLlTlA0y+saG3RaHRRmhJiMI33P5HVyB8TfrnAkohlOs7hyEYXf3Ny8WOx0xDYasvGenIyjTJerP11LJE3U5ojBp0N4thCDBZ+M1uIgT2tV4PSFRZc5jdZ5ZNqejJLjHjkLtZWU5EXnl460oAMTutWo4Obmpm02mxfrN75mwLq8ne7s1yBTtoOyUv2eV3Wwv11HNBJ1uYj0PyFR6r3q1LqSdEigYrfbLaOqtAaiulSuy4trFHqrG/mk3fhaYUUO+EZ94fras/EESCqbSNRz4OoLnoI8U97IL/VoVVDoMTAbqanEM0yvibYpIHCRTURHrzxSuuvr63Z/f783tPYA4PxwHp9t9dGIB9aUnuWR6HQSD8l5cwuonL725csBnpycLM84aMjPKSnJgsh7s9ksgYXy5KFpacHagwT7gbuTlEbtdjkoEBHRqo4UwDh3ztGNrvH4DclSaW5vb5c1houLi3Z2dtY+fvz4ok+4XpOcTuWAXGf1252/qEK7WmNSeWnOnHpD1Mn+kHP3Eafq0Ihju31+/wfbIt4JNHxkkoj6yjScPkmBN1G67zY/46QPdapV3rXlsa/5DhW+vtf7kHU4OJul6aCQ0P9MZaNRwWxgEI0itkdmThkkR+35fA59hveZNjCt55Pz9KDgTmVGkWm8lAWnEVj+brdbFvXokDlFxfUKR/YuV6+vMg4fDcyMRKuAyvan/8lgGCiIshnI5ODUN0La6URUjq48MDkvPlJJ6Vzn0/308fb6CIVoXO1jUJBs2BYGBZU5GtWl4OvTH9V6kuutPtJP6vZaIoJPwTvRa4LDIeS2RD10+fTyH8r3QQvNIwRU3VvTkaO0qTOJMnTPldedlRsIj/v1dLrG+mQkPrXgR0QTfXN+l+USIRFdidzQyRedHHcLabGKfAsJ69jtx8fHdnZ21i4vL9vZ2dnCx/X19VK2pp1cfsrP9iuPpq+EGhlESJLTCAkmlKv/vJ+m9ySH5JgkN57141NwRLncvaP6uZuJATjxnxwmr6tfGXB92kN6kBaGOb/Pc7L43A1HBOJTo2OfMiUfrT0vaNNhUw5C9re3t8NFUbY3yeDp6Xm7tQdjysl/U+YpcDEY9Xg6BN2/prwEZiRj7YiT/CvZzoLoig4eKcykH0W0NeVWKGqGh5nIyhFCVU8aGVQoTR3miMvRJA3OA4QHBa+HSkZn7EiP5IvLT09P7erqqu12u71pNh2FQflwNMX1Bne0CcGqvgQUnKfK+VO+Xoa3keg0BeBKhzidxGDFI0oqPfLRliO+RB48XC88L0GM2sT9/Wyft5+AgQCFI0fvxxQUvCzKk8CGskj94M6ZOsL28zmZ3ojSgRJl50HB+4BlzPqtXt96GR4QvM6R85a9EeSOePC6Zv3m6qCQhoipM2ZHE5+TvMPT4l4SnlC1n2HEKZ10vhENgShV6T0IEIUxyjuqpVG7o+ZoyNNzcTFNY4hXEUcvu93zS1bk3IiAiSzVPrXbF8/puNQHPp0l4nk3lBf7j8GBjs+du7eR/S+5uQP0Oe7N5vn5C3ck2rLqOkQH7Q40pXc5VM7fiWjf62C7GAy4a4WBjluavZ38eFDwIO4+wLenKp0HKKVlOWmNSPe1I4xnJCX5JHuvnL7LvOqfz01Jf0bpJQOODjWidfCRgNMa+mxnH6XoWyl2736vrvQ/RX5d90UrV34JlYKlg0/K4Y6+CjJpsZhG7c5D93e7XTxGQYjQHV1yKI5OyA+fj+De593u046Ri4uLJUgq3cXFxYvpl9RGOhjJkkdlpMDa2jM6d4VOSL8yKKJMtl0yT9ddd7ht1x08n+L1/lLblYd9rHR+PITrBWXI6w6+ksNlwNR1TuMonYKa9Ojs7OzFq0ir9qfgzL5Q8FH9PkIRLwRLuu7TWMmJbzabdnNzsxyDwT719CwzBWVRCtaHANg1QWRtwPHg39oz6FFw5M7BCoCsoVcHhfQt6o0kqrJGwhqNRtzonRc3ViKUVKYrXELpiZ9e55A3X1TuOT3y77xVjq6HHLwt7tTZZsqKc9apLjo2D8zu9FQO+ezpAPs3ySldUx2cilNZTJscMkd2o+25njf1yRpnkAICfzs4oPPmOghHhETj1GcPdt4uXVN55I3Bm1MbCo7cEuwjE5bH+pI9pqlXl5fLn2CvByB71Os73kugJeWrwGYvHwMD18Gqdbq1+kY6eKF5FBBSntmy+b2mUe54fZFW16W4PBiMUxacd3VnyQPQqrIdCbpT9EDkaYnuEjLrOd3N5nn6g+/f1T1H1uSP5ytR/qxbSE2KqR05RNQ6W8enZkhu7OQzjbJS3uQYvWyh9Nba3rCbbdPHz+1h2z1oMJ3IHZDqob6kgOblJQCQ7M0XHfniGi2a73bPTwjf3t4ufSbSaFH1Uf6sXwvuqpv3tJ3ZR67ilZsuXB/ZZj9GxackFdj4hHSSIUcKPfTc8y2zqH8GxK6ph33gIEn9om3lkutut/8+7NfSZzn7yBFNa3l+dDYwVHWMqEK3FbLksQWJf3aIK5cbCBESnUFVVtW+qqw0j6v/RO3uEBWkfEqAbea5N+786BB9WovvZZDzEa8jVOZ8OuKaGQlQzj1Dp/zJPwOZHI6j8DSlkYj32R9cU0lOqqcLPTm4YyVS5+tT+W6NxLMDACLeFGT1n+tdXLfwjQKSB3ll+cl5VyMA/ZfN+hRS5WBnqOdfUn+t8WUpMLg+Ohjo+R+uAUr+BI/O39pg8aqF5kQpKrsg10bqkdE7uaJXdWuOVU6T931B05WOqIhDYOVnef6of1JgbyvLlhGmJ0R7DkY8+MmemmtVfT68961uCgo8FlmBhEFB5fGhJW9X+p/QsH/YPjoKl3eSD/vUHZ8/AU4n5/3khlY5IZVPufszIK5fXr4H1p7upMCg9urhQ/Y3yyPo8OlD540AiHKivHxjRWvPx8N7mzgSZ56Rg76/v1/e7+DvD0/9VaH16vrMtTW+q5cu8e3XPJ0AHReeR/5xTWD43haayYyjYOb3a2ujWnImRNUkXb+9vd17Ulc8UEGruUuWS4fqW/vYJjlzf1I0oUc6bqXlQl1rbRkq6qOgJkXhzqHWnh9A48KbIzzVwdcqcsfOZrNZDlGTkxFi4zsTtG1QZXBawZ2F9yEdvBapEwKiYycAYN+4POmgfEqI5aUA5Lyyrp4RVkGFdattrrtMn3hKOpMCnfb4s1yOEt3Bex1pFKH+4WhZ9blNbTb7p+k6IGG7+a5mX2fgIrraqCMwXJ/SSNfXkyjjHrDydDMIvPIX/GZA9Dzs2wQedP329naZzuVpAkrvIGzWt37Wo7MrYczmmY2+o3JSgOI1Go3KdsVwROllubETBblzSYbOulJ5CTHJaLlg5waQppLcceqaXxcfDHC8xx1CLieVqeCla75LJsnInXty9mxjIndgKT359Y/q7ZW1Vr+T3ni/JgQ6o8s9NJsQuDsUr4NBJemkX0vB3XlhEKEjTO3ygNhbj/Kg6uV5sKyAiLejBwSq9o6cbdLFBBh6gcltTkRwySDtMvA2j2g6KKTdJqqoqsyFPVKi3r2ZBjnaYhTWHLIW5EYLM0n5K2N2BLXZbPaOnXblJfpOh995nVRKLSIqLREakacfv03H7Ubjxspru91u2QKoF9afnp4u21O5q0Vt14tBNFrxqRkSAwnbSbQ4q8yjBWrK36eHXBcoS/GZyhIlQ0+Blci2Qp49x1vponTBnXtrbUHVSQb67c8/VPLQqICAg+Vo26mvI1AHqvWx1LZKB1RWsk8CkqQTa1DzmrTOO22q0jOmrQKD96fuy5e19jwi52tkZ/xuos+2JXVtxaTEfE9ZKmMhwnQnR8Xktq6qs3zNwI3dRxlERK21vYPllK43FHRe6UC9rRyOS/FlrESJWjhlHWpPMmZ9KEs5DD6g5kbrjlPleR+4HMV/dVCaO0cPcB5M+e3lpGCr72q0wG9O0SWnXaG/ChFzh1lywmyziNNyCXUm5EzZM/izzISEvbzKHhkcdrvdXnD345496OjDKSyvL+kFgwrBhsuyN9ogrXH6VfoUpKv0vZFAL53LsbXnqUDJ7vT0dNlAw7RrfPTqoEDj5P+UrleGGB6lSf+TYbdWP3RDx+j77HttFPlcq8gX5khclK3SJ+Ng/RV/vuuCTlnz/TKY1C539AwKfCI1pXV5qn4aYpqa4uiIMuEuFjektUhnhMIq8NEzymTcqc/SLiV3tpQp8/n25OSAvUznR9/qC+oIp29Uhn+S40iy8Xzk0fOynd4uDzris5Jh5dy4TpWcqAOJSpYjGac2pDb5vVROsn1f9+nVSRLw05llOpcrzVDMBr9Vu4+qeXPdVwMODRLpv5eXynEH5miB0wWcZlF57kDTaMMV09vcWnux7c+RLBekdY+8yJB9eK78VCDO3RMpbDbPU1cKTMn4NpvN3tPG4l9KxvPbU5CUTDz4qa7r6+ulfQoqQpH+1jf2jz9ElZxUD5BUzkH5PZjy20cNzMt+pjxT4O39Z9/zGQGWRSehdKyfPMj5in+NEOmUlU/lOCBI9VP3Va7sy3VCOqv+I+CSvmtrrC/st7a/w65yXMnneN95P6ls8bEmMMzSTP5qhoBt4IhbtqLnLR4fH9vt7e1em1ivFp31jhT5Bb29bm0bD9qSmq73fjutYbCH5r2s5GjTSKFChkyfnCnrdb4cCSQlJVIn0kwIrldX4kUfGbx2IbkxyGBp2D6CUTlaJ0htpCPyvqCC+5n6KltEJ0OZjHSpulaBEvI3MpJeGbM0ys++kw5QF8SH95/rEJ2i5OYLzAQiDMLuXFQnnXYvwLJM1kM+EyrujTzYR6rHZUXZpk0Rzm9PfxIA6DnSCpRWRLtK6QiO3r59205PT9vl5eVeQH96emrX19ft+vq63dzcxPVQAUkG7x647tGq6aOec6qch9NrDa7KT0WnYtJQiJ5TG1zBK6NI01SjziefbAvRladJjpFGQTQpZ8v1htRW1qOpJgZKtfvp6WlZNEzv/tVvX8xTezjX6ej4/Pz8RUBzlOjOouoDl494cHJD97zsP5eTp6nKGVEK8pKJ0DYRIacFKX/l8SMrtCW4tf1RqwKEnIVGgRxdprUv/ue0lPRG+qcn3D1Q9PwF+z0Fhl6fUyfS8SNVXa/xOzP6xd8jn0D+1Sc/+9nP2h/8wR+0P/qjP1p8FVH/n//5n7f/9b/+V/vFL36xbP0WydYFCrW2IPmsaf+qkYIP+7yB1f/q3iyTCc24AjHKJz790K0ZJErn60JN6wwzCJRlU6a8nuYW0xoI28JdLSq3GrYm5KX76cG19PARyxMq0Z54TUFxmkL8+HMUfACKSGfGmJNjHgWENPVBmXm5PSRZ8ZBQqPPj5YovTrEoLeebxbujdP1WuvQsAJ9c91EFRxaJaAs+CvGHKl23qwVuyoNySTYhfUo2IB1NgWjGGaY8PZtO+ua2zPtJV8T35eVl+/GPf9x++tOftpOTk3Zzc9P+63/9r8sOSZ0K+/bt2/bmzZv2J3/yJ+3i4qJ988037a//+q/3ZP309Om5FL1CVj5ButAbUZEO3n00K2jv3Cpvr7zUKW6EScnc+VKhWWdyCL02qb40F105Jb9Ho/QgwHUEBr6ERlhWCow0zNaej3dw+fT4ldzo0Mmf7zB5fHxctrF6ICHC9MAg/jwg9Bww//f6ztO7/qSAkOoaXXNn3wsMTMf2t7Y/D01QkoCQBwfqI08t5ZPrHhT8pOBKZgwIyYmnTRCz/eb6zXp984IHTQ+cuuf6uYYq23Nek22mey6XzWbT3r5923784x+3P/7jP26//OUv229+85v285//vN3c3LSbm5t2dHTUzs/P249//OP2z//5P2//7J/9s3Z9fd1OT0/b3/zN3+zxpACth9k0yljb9oOmj/hddXSV/5DOSWU4D9V0gr65XZPIyRE188uBJqdE59rjtbWXowrW6WmJzF1euud7/jebzd47pWUkPoXQ2v4Rx45IJSdvs4amRGy+AN5aW55j0DSWnmlwg64WmjX1lYK1X68Cmvf7jFG440pAhpR4cqrawPuuE5vNZjm+wdedqp0pTpI5z8cR2lQ5DAxcCBZfQpgEUQl0OcDgfQUa6iFHpWkzBWXhskoAgaBF05wEa94PVTCfCdxMX93zMhPYEm232/bu3bv27//9v2/fffdd+8//+T+33/zmN22z2bSf/exn7Re/+EX7y7/8y6Vv/uf//J/tF7/4RXv79m37t//237avvvqqffjwof36179u33zzzd4IUWsO2pGkMr63kUJyvNV/R7oJ9c2Ww+spPZ1UKoeKUk2DzPDgfLgCVEozQhMspwoYTOvoiYEmbUlNxtvbkZECYc84icq4vVWGWrWHxu3B3dtV8VjJ2NOlIOs66vwlnpnfy0v8VGhR19OogWsGVfmJR4EdombqSRVYld4XKRWcfD2J05mpbUl2lW3SuacRQtK7FFQrmXg9FdhII5ZeOaP+SGUo0L579659/fXX7fj4uF1dXbW/+Zu/WRabf/KTn7Rvv/12r76Hh4f24cOHdnt72377298uo4erq6v2u9/9bq9NCsR6iNQfKBzR9z59pN8zO0pmy/J7abWdJKFKKOkQrRH6q5Akh/uVw/Ey/DeRoDtI548oT8a/2WwWJMA9ylUg4M4G8pmmblinO3g5bC088s1wCgpnZ2dts9l/n6zrAh2/jyp6c92zzjs5FKfEE2XjOrgmUHmdqS3UTY6eekdAk0eOBHUeTnUyqjte5VGdOuSQQcb5pCP1kTb13jd6sJ3k3UdFDGa+0E7euSbicvZ2z1wj9UBjL38vSAms/dN/+k/bj370o/ab3/ym/dVf/VX7sz/7s/av//W/bn/0R3/U/tW/+lftm2++af/tv/23hY/j4+PlbXn/5b/8l/aTn/yk/bt/9+/ahw8f2t/93d/t1cdTDmSD30tQSEgxGQEb3yurSpMCwEw6372i624EdHzVonMKFq4gPUTK9GlXUWv7D90oqJFoTLvd88NISut5ODfMxTdHW94mtYUOQt8ySK0PcDFYZfGdFOJTTomH4XkwZTvI19PT04tnJOQc06iB7aqoCgqOkr3vUzmUl18XeRkVWk3Tlt5n3N3FRXgPVvrWKE1O4fr6egkOnPbzd4mkANNaeyGbNG+/3W6XOnz9w+WSHCYDCKe4BC6SHL38quyUlu3xfvF7Pd1aEzTYxqOjo/bDH/6wvXv3rv3Zn/1Z+4d/+Ifuaa8i9f379+/bN99807799tt2dnbW/uAP/qD9+te/3jvBoLXn96nIHqenIKdStToosMFVPjWyl45pK7SV0vGTUJDqTter8pnHHVql1JWj8BFBJQu2gYFLCNuDgYzHd4K4gad2VW3WdY5CWBdHFww8fvS0kA3neFNbPVj5RgCXWRp99dri9aW0FbDx/uulSddnkalf43qC63aq2/mnXmw2m3Z1dfWibyhrn2J05E9nRjTPPKqrQqLJFn3djDrBUakCXLKvZPsJgIx0/hDqBZVE5OH4+LhdXl62s7Oz9nd/93ft/fv38RTXqs+vr6/bhw8f2vv379vx8XH74Q9/2P7+7//+BV8MEtVRMok+25vXqnS9vK2NndQoP/MmR0hFTo7ay0gKJvJtdyorKajzI4XnNdajnT1K61toOUcvA9QR4ETqNGweu10N0V32nMZRW/SENJGqtp8yvctcfLu8fc7aR3kJeOgQwN7oLjms0QgiBS3x2FrbWxBluYlGjiGl8z5gv7tjpLOW3lGnKDM92Xp7e/ti6sDBg0jva9ZctPiSI3O5Jf32aVTKU2m4GNpaWxZEGRD4jgA/E4k6kNaskqwTYKuCt+edoSr4sIynp6d2dnbW3rx503a7Xbu5uWnffffd8kY82m9vdKJnRf73//7fy+6lv/iLv2i3t7cv1hi1geD09HSvD3v0qoXmNWl6qGpN2SRH1RVS7wlYaVLZKT073of/HDEkhXOnndCNGxynarh1UB1Oh806Eopqbf8J4qqtHrjUtoeHh72jOMiflFUGyu1xreXTWSs98bYrP/tsBDgqg/c+T3pD+Xm+SmaeN1FPJ5nXEbt0gnmVP22wUB5N5fHdIQwIHhi4a80XqtnPqi8tDBPxu5PkVBh/sy0Voq1sNem4KI0aRv3yWnK9c5C42Xza3aUHFavNHj0+5Xuurq7au3fvlodBk46qP/1IlR6tnj56DfXyHxpsuEjLdMkx07j0PymSozLWrQ5x594rU+VwV1ByvCIeECdjVB69ozZNtSQjVH1quxYUlT45H+ahs+JowUc4elhGvCtYcSukI0t34nQkyWEw+FROmk4p9UGSues2RxycyhGltjgf/J94deeenK3krTUWyVX55ESFpHlPMnj79u0yheRzzs6HeGE6yp1TU24jlLkDG8qYzonB6enp+Ywsnl9W2XLqN/JSBX/X6dRHVZ+toVT2brdbnjvQuUSHBqLHx8f24cOH9gd/8Aft4uJi0YHUFvqMGTp4TcGv6f9MOTPX0n1PJ+VLiC6hlWT8lXG29nKLHPM5Qtd1N2jveA8kFWKkwYgUGPh2q4QY0w4ePs2anjPwIENk6A6WaxlyIKyDyI1rIvr2qSvlZ/k+WmLgokNMcvN+5pCabVY7fW2DTwOn754xJyfv99kv5J9p+CyH8tDw07RW4o/TMencLz+AkL8ZCConq9/uwOnY+USt8nOKSn3m04qVY05Ab3a+vArgXnYv0PfKlhxGeaTTySd5/akeB6cjfZS/mqHPNn2UonaV71CBJyOtUJ5f97QpIHh9fo+dTbRE5eYCXlVHhVj9vjtpBpzk4Dw/HTEX7+jolY5lpIW9So5sA42TxkF+HFH2+onBoucQHPmpDZXT1G8vK4GPHiAhVcacnKn+J0emaRVfB3Jn68T2p6Do8/LOV9qBlRyuy8zJ8yQQtNk8n/fENR3qPdcUeK+yV58BGPVXohTwRs42tX/k00aO34Ntul/xWJU5GxBae8UTzekzW8baoFDV406BCpPSydB6B2ildpJXV3JdZzBIqJtOgI7RgwedodejBWXyovr8xTucn9X2UCIxykAy9MPraNy6zzWD1j4tEuqxevHF9hHxqbz0Ih9fCFU79CG/bhDUA+oCpylcXyrHUekZqQpQ7BenXnDwdO6g6cQV2NX3lIujc/0+Pj5uZ2dne1tQva2+vVl8aPSnsvjsgz+jQ/mSOLIkMGBfaHpL+qyFUT0zkcCQyzb1qeuMB73KX3xuYkC/v79fTkKlHqT1hRQYJMe3b9+27Xa79zQ629ort0evOjrbDagS5owD7uWv0nrjvYOr9JVzT/W5Y3cjVRrnw/+rviqAppGEo/e0fuGKrvyaFvF0HnCc1yTXZPBytGm3T8rjozd3DC4LTuukfq0cOqedXIZsmx/nwfJ7v3vUCwa6732V2u79RUdI+XqAVhpuTqDD19rE3d3dnrycF9ebXvu8Db45oOp77rRL5RJgVTaTfI/3aUqfAkEvX7KRFFhm6Onp065BbQLQQ2k+WqLuuk219ikgf/XVV22z2bTr6+sX973d31tQ8E8vrRoj6gl9DSVn0Fo+6tj/0wg8iFQOXyQkIyL66Rm6d7JPGXidzhv/sz43CEfalfKrPD8LhVsCffTFB9qUvwoK6bmK5PiTs3B5jBw787ANlEPVL2m0l/qddbIudxRKN3JKqT5P09MT8c2RH/s6rQVpE4C2gvr+dQ80HFlVlByN6yifdfG8Ct6+7uY83N3dLW112fWcOPlPfPbaMxP8qrJTWtq+jqvQgjN3h3l6nzoVafPBH/7hH7YPHz4sR2L4yMP5nQ0Mr3pHc4+SIes3vz1touTQe/X47pSEooVEetNPfChLeZKxJuHTIJOzqBw828EpAPKQnvjV4jPL4H5vKhm3k3JdZLvdtrOzs6UM7ioiKlWgcIfNBUU+T+FTBUrDtvu6hjs7d8YpMLhMKXun9FDUyNBZ1+j3KF+PPAilOnxxVqAloUqVqSNHuBWSsvcgLtnpbH/qHHlgHeRPASE5b2+X8nNKard7nq4i0JF9uc4kPvy674oaBQLneTat16t8j4+P7f7+vn333Xdtu922n/70p+2v//qv21/91V8t/ugf/+N/3P70T/+0ff3110sZ2+22/eIXv2i//OUv269+9av27t279od/+Iftf/yP/9H++q//es/nzO4yquizHojn6Txi9wLDmnr1351Cmi9OKME/7qzpRPlJ6VkH62Yb9QCXEBDLSmhZ+bbbbdxl0pMlHYIjdA98RCRJXjJSPWvgR004X2nB0ANtT3apfc6To/LUNjqXClEmgOFlzgKX1waDyg56QcqDmaelU9dvBcJqy6fK8IcofSSheqjDFf9Vn6dPkoX0f7fbvVh8dlmktox4SQEkybJHVRBK6dSmDx8+tNPT0/b7v//77f379wuw04txvvrqq/bTn/50yXd0dNTu7u7at99+266vr9vbt2/bycnJEmAkgxS41gaxg55TSA6nJwT/PVNXVXe63nM8jkiSI6tQA/MlVKLO8qkUpRVS8q2E3FKaHLdP6+x2u70XcielPTk5WfISRel/mpvlQrT6VC/o4I4lBgXteVYdDHTijYed8YU77B+iTbXTdSz1WaXgvsVPzo9TLJxeoly8T6s6UhBy6jlyT9eziQQ+/L70gU8Lt9YWxOl1qV/Oz8+X1zom4uiZ73VWvTw3SfXq+Ref5mFQ8Z16Dh7Yf3ymR/VcXFzE6Uj/PaMvM6i/18drHG0CWn/+53/efvjDH7b/8B/+Qzs+Pm6/+93v2m9/+9t2dXXV/uN//I/xIb6/+7u/a99880370z/903Z6etr+4i/+ov36179uV1dXMTCnEdEMHRwUeD2lISMVmvVrvbpn+KHDqTrU0zuilaOuFiwTUqYDTjx7FGcwSQHLUVwlpyTvNPLgvnvfadTa/m4lDvfdKBkIRD79prI5daByKK/K4SX06/L09jNguww5Nca+EF89pKjfCVi8ZuSQ7Gitk3HgwG8HSJS7Rn6+ky3Jg7Lig5DOq4/SPOinDR1qQxo5p3Jba8uTuX7kBttcAa2Kev5n5h7lNKqLeW9vb9v79+/bL3/5y7bdbtsf//Eft//zf/5Pu729bX/5l3+5Z2ebzWZ5V8k/+Sf/pF1cXLTb29v2i1/8on348OFgParooOkjN9i0g8F/izwgjBARBaP8zg8VIe2QUT43bC38+FHTRPfc1ig07MFD99NeYA8srGOz2eytBaQ5cG7fVHnJybs8WH/aksngcXp6+uJJUiFCBg6+TY3X1X6VqxGGb2Hljp/kJKhbSc+cRulc5gwOHhiq8l2mI33tleN8k8+Z/OSBbeLoMN1nO46OjpbtqTryXHlc51vbP7NI6xYMxiLXMT4sR1DBNghwOMhiIGYg0shG21SdUjB0H+Ay9etJblWaqn+8vxOvt7e37eHhof33//7f27/4F/+i/Zt/82/abrdrv/zlL9vPf/7zPb6Pj4/b119/3X72s5+1f/kv/2W7u7trv/3tb9vPf/7zPbl+joDQ2oEjhUrh1pTDfAlhJ9TB+x5JeS2hTSqernHxlvPhd3d3e1M8m83+cFblcDrHRxw0UBqeK6YMkaMTvUVNxuXy4pvQ6PRVhnZ9iD/uTadcGRh8UZBDeR46puCQdkboeQUFGR8tiBKy5CiEDtv1xneyqN3JKOgYuECu9O7YXJ4eAJznEfUcf7WOU+X1AEf9ktPVNCAdstutpgs1HXl1dbUHqij35NwIBvggne7pmttCNeWz2Twfrkj56h55oi67nbvsPK+uc2Tr6deMKBKoqSjpp/T4b//2b9vt7W379a9/3X784x+3H//4x+1P/uRPlh1JGhm9efOm3dzctL/5m79pP//5z9t3331X6shr6aAtqbyWvkkVkz2DqMqa4a+i5JTSg2buxFW2L5qyHP5OaKRCFlJEGo1vKeS9VJfz0Nr+SMcRrhs8+zUZLq/RIaleD+gKBGmqieVUDqCaG+UIxyk53wrpucy8vZRTz/BHTqRHhxhv0iHvdzrLnj34VGGvnZSX79bitKnLl9d6voO/WYZPCbJPkg4ncoCZ8sz0wyh49/SiAgZKd3Nz037729+229vb9qMf/ai9ffu2vXv3bpneEyA7PT1tHz58aL/5zW/ar371q3Z9fR3L/Rz0vW1JFc0YT1rEVd7qPx1EhSxayyiLC6YiKrErf3K8UnwusKa5cjcGd/BEbhpScn+3thG29nwEgpAgjx8WTwpoSkvnTHnReWjLKZE4yyVy5qKg6lNaHYHMc21EfP6BZUkGjiY9iHF6ik6J97xO1w/KyUeOlbNwlMky/H5CkRWyZBvTdbUrAQ1H//qtU2z1BDt1lPl3u+ennG9ubpaRZ5Ij+9vXMSqAqN8+XehTXErrowvVq3RKK7u4v7+PiJ88JjvU6LlHKd/If80GmBQcj46O2u3tbbu+vm7/6T/9p3Z8fNx+7/d+r11eXrbLy8tlR9Lvfve7dnt7u9i817kmyI1oVVBQB/liZoVCRX4vobgUYStk6GVXyCghIJ8uqspM/LuBent990vij8bAzuW+cwUC7uYgApPxVMGUO5xoTCq/MphkAL4XPfHAdpJXXk+6QVl4Pudvpn+9fA8eiR9vA+VBh+TEwOL8zAQH52PULr+fgIp+c0eS6yPzCZBsNpvl4Sn2d+obOu2E5it79aDDvtEUqR6o9PZ7//gaoMgdY893jHSnh/69rpn+miG1S+9Y+Pjx4zIFfH19/eIp/ARIZoLYiA5+yU5aAE7Gwzz6dlTGNCkwzPDigUo8ubCE7N1IUr2etxK233eH0Zsrb20f4ejxd6XxXR9SEpXLb5WjeVcZG0cCvR0qrmyOqMkLt5/6SMTP4yFSpMzSbw+mac7ff3vAGX2L6PSTflb1MC//e9lOSYeSI0r1OVUByTcAUDcILHRPW5B9FxD7TBsylDfpkOt3WuD1nWDKywcdvW2pXxyUVD6i8gWvJbcT/810M33p9vfx48f28ePHFyDFR1pex4jn2favPhBvNgiMynBD9Ub2Olvp0uKkrlPxVb7vnnCeKmQoh7jZbPYcntI5mt/t9p/4ZVuk0Gn/PAOtnK+Gi1zg5tvM/CAzGi8NmAbJOWU+nEanwQfVKMMUTPQOWD7jkA5eS/LlGgT1oKKZdGkUkNIw3W63f9ibGyAd5oyDcYfE+XdR5dhTcO4FQPIiPvWiHB5Rkg5BVJ/ppS+SgfJwKpU6zHYmUOFInsFe8vDpHm6TZvlpZkJ8np+f78nPdbQaTTtVo4RZWovQkw75yMt1122nV6ffW8PbZ11o9t8zZSZDmCmjQn8V4iO6SAInP85DFSy8HgUNURpN8btqE526nKtvO/Ryemjf2ybeuG2UaC45PgWm5BA8yJASuk4B2WVwKM3qT2qfT5WRHwY2Xq8QW0KTFR/pN/NXI4heOx0UsQ0JkB0fH++dv8O6ky2xbHfaPb480FXTVYlnypjAJem9l5HAjNKnvKP+87Qqp1dej7ekP0mOo/b16pqlg6aPiHxnDTohCt6bUfSqvNb2UYLfI+IW0vZ6VUZr+SlnT0MenKTs6dwgftMoeE286jeNkOjN51aFthx58y1qQpCaT+bQnWc9MXgwQNH5c4TDaSI5GcqDbU07ZNIiZwpo1QjSg3yvLO9HP0pEwZ1BT4v7kkeF3it9SYvGFfV0jrJM7WSb3GGqLeRbQfz09HQBIBwxJYfNqZt0nAjl5Qu/Xk61S4n6IB3zgKINI3y5U5If6/d7Iwfac7izjrcXdCoe1pStvpBMXkuv2n1UIYNkjFXe6j/zp3sVMvZ7nIPnInNyOEToVSe5AvO+r1e09uxUxQtRPw2g4tF/a6sa+aWBclqK9fHgNMlEDy8lh8o28gE/okMPBlx8lDGnAEgH3+vjxJP3Na95GbzWM+4qgPhvR6ypTRV/vXaNAFHPkXm7CYzU13SurbUXDlZgQs+fcKrSnb0+0iv2M4NEqott9Okk3k9rT1XfcfRPnh0genBKNAoQzkf6T35TvzgPiS8fOcwCZW9DL0j26KCg4J1Ahvz3rLFXwq3yJOVJaERogk61VzcDxIg/71x/6QnRNp3r4+NjPFbYA5N/0uhBdfAhtxQUuJuGaw+O9tU2XwfxZzqUnoeUcUTjDpTzx1rDqIJ9RelehQppWEkvyJsHRZetfjPg8r4j2MTzrPOo2ub66GCmCgxK6+tWDnzUl09Pn87797paex4BeKDnA5wjWbp9pTn/NJdeyUc7rcRnCu7ul6o0PefpfZvSV/rs6yQzlPqVdcw4+qTrM3TQE81iam0E8w/LcbRVlaFvOiQKUIqv/b1Cw25ArNPb5vP2dKq+y0L3xRffQKYPj//19tHR0HEqr5yxtusRyalO3/mjem5ubpb0mu45Pz9f+HTZPz09LQuP3LGkIHJ3d/filZ6cqqLjURoPsJx+4gK99wF1hr/Torf+87f49jJYlvJQnmn0wGk/tUH3JUefj2d9/J8WUvmdRhtpRDVrKz6i4VQM+ZHDb+35GRc6e7WXwYO66g98eluo427/BCyqjzZbybO1fcBC3aTs1P4ZmTlK79EaB+3p3S6S/q6hFADXjhBEn/UdzaM0VT5P3xs2pcCSkGClWEzvypjKSG3jfZ8qEtGRuAL4wpzKSiMF/udUWCULGqeXkWRJWXEEQ365LsJRBb85leSy9E9aU/Bv5zMF8hGyc+CRjI19M0KCIk7/KW3aAMAyqvpTW719h9hWSpf0MOkTp4d89Oe/SQn0OE+UGdvpQYEBp9INt5mUpudbvD+SnoycbaWviRxwpH6mLlb6mupL7UoAZ4YOXlMYRaEqiianwTJnGkDEkxaqiGx9Cykdkj+401oOFM4rF3qFdIjAlJfrBEqXFoKl0Fzo80BQnftCxK0FdUfsaheRnkYDaj/rUdk6Nvvy8nJpj3jSIjUftDs9PV3ay3pFfKqZvLFfRn3OPj6UXCfdWepazwkpvdqgEYPkU4GRHuCpwAu3N/fy0NmkcsQfpwqJtJ03TjFqVO4jCgcxPPyO8nFeaCtVf3AEIt1lfWyTP9jldWrbbSUX/ne5jij1qzv4ESjT/7SRYYbSaItljUAU6eAtqcl596Km53eaDTLqYEdqDChcGE3l06DVEal+lcHXF5J/DsNVbloLYD5Xdt6n02W7HYmr/XLa3vlKn9YZlEeH1rlc5XC1bqFhOedt9dQ1p/AcLTuq9CClNBUK9GtswwipeXr2Vy9dz2E7ERSwDZw28+DQQ726xjQcbfK+89GTRZpuY3l+Muput1umj6QL2qigdDO+gPykETTve4B1W3HeU7CmI62cdE9XWNbs/ZHOuF9KfZVGCT1eRuS8su4ZvW5tZVDg756QR2X0DGOmjLSQSX644DviM0V2EVFUqtvLSAuyVTs52lB5zOuOlk5ZTpoPi+lYCzphrR+449fZOHQYCiwKqBytqBwGHY0UuH7AIJkcQhoNzASGpG9p6O/9UVFC+j0DdN3gbzqptJbiC60j3ffr7kTTNEFaGK9IPHn/8N0KPDfLn2SWriReKyc44zB1jQCCgcDBWWoXy+7pWcWL/z6U3OF7Pb0RJPOzjEN8Jctbk3/1E80kXzRay9QoejEfheOnO7ox8slMr4+ojUabdg2lNuuaDIajAc/LJ4Y3m83eAXyabvAdQl6P0vHZBb3XQMdhsB1pEVjD7s1ms7wha7fbLYvXPCfJR1Gttb1z99PaAdvs02iUBZ2YB5merGcCwowOsu+IQNNiZHIqFbEsTu/xeGnf7DBD1Hk6cTpT35jgfcLpwITYdU07wljW2dnZoifckkwdcWDjOueyY197gPQZAPHJvmHbPKgQULkMRb1+rUYJPYQ/SwlYjHg7lBywer+N6LOckromKrdWR79RgGht//iBdF8KVC16eVAQeXoasCuOD6HdccnR+JSJK4bQOdvmsvMtq621ve2saS6V/CgdA5fPI9OoPW+Fbrxd/mGgSk49GUQP4bHcSm8qo/ayZvKNKPHqTqsKRKMFWS/LnWfFR1VmklnilWte4lNrVO5YqjodpDh/tAG2S/X7KIGBz0d1ju7TdG2SE6/5/2Tv1f0ZMNLr50qGvf4cjb6cL8p8NugcfCDeLDITY4k5GnqvDEdKrhxSKHd2aWRQITU6VzpL54VnJ202z1tQOYffWn4HLZXXDV0oi/W31hZkTz44ylDbHJl5UBBPQn3+vAYDTeKtteeRDz8piHif6X+vD/z0Vg8SlEHVh+5wRwGhMvBZ4yGxfRxVcT2otfZiLSlRL7gl554WbZNjow7qmnTRN0DwDKvdbrf3YifK0vubtlOtIzn5NCT5Zp16uE71cM2FmzKq4F/p0oh6QWAmfwWCqoDKewkczFIVjEd00JqCKHV2xbgrT9VxvfLc+Xia5HQ4akhG4aODtN+6cnjOD+umojoy9Db4uoHvuKBTIW8KRKxf11Wu2sTnHcSfyuYzCSqDDp/bTrVQrTdC9frSlTDtqqC8HCRQ3j3FprEnfVFen9aiI/NRW6IeSiOfTK82c0rJeUm6WDldT8vppLT+QKea2uOOXgBB5amfebQ2p3kkO9c5B0RJftQv2kEVsH3EoGtue7rXmzJJ/iY56ZRnBv17e5mHfLkuproPQfup7M8eFEQJKVS/xZgrXXIiSTjeCSkg0BGsHR2k9G5YVSBKqMmNgQu24pXG4/PD/p/18iwhGSgddpKh+OK6BY/IYNmubL42od8KCh6seg6b19MoiXKTc059UCEufqeFbd+9Uxno7LxrMszKaBO/nJ5xx5nadGjdKVA7UR7c1dba8/oRH8hU/0nOaY3A2552HLl+p4DOtnke8u56JHJdYhnJYVdOOcmv51N6lOwk9Zv7mbU0q0+JXrXQ7M75NeSKncrju4KJ/vTfF5qEkuWgHb1QGRwdcYGYZXPkQZRCHliu9u5vt/mNZK3tP2ugckS+tzop1Gbz/MwF5cFtpTRu8ahr4lF8qrxkZCcnJ8tuJPLAb9XB+8n5qEwPLpS5UxUYHEzQWfnhfPpOfCfg0jP+hPJTWl+38cXYNTuIyGeSxSFlsH6NDsR3a61dXV296FM5XV/sdvK2e/3cLUiQ47bnjs7/V+CIQEt8vpYI4nqAk+lHdbM89ytrA8MaPXBaPX3UcwYzyKZK60aahMhOH0VudyoeEFLZrbXFIOioq22FLJvtSwhIjjblocP2+nzU4/XoN6cnlJZTQB7g9PQyn0GoFoY5okhrCZ7edxclpEe5+MencRKKHDlhfnr5nHdeo3wr50s9deSq6+l32hbqgKVCi3597UjHiUGb9sEjLU5OTpbtyuQvBSe3X6atwCPrd3DjMmSgSLu6Kjslby475qNMevJKdaRAsJaqAFLpVe/6Ifwc9JKd3oLibBkV+cIUhe9BISEdpRXKcRRfrRnIYXPRi/kcqbhyu8PTPD0Rq08bqDw9N6D6/HRTN1giTMqG6FOGrHR6pkHbde/v7/eeStY0lzs3lannIvyhN/YZ+8ZP2uT5S1zDYBmUIduZnAzbnvrD5/JVLkeTzDtypklnvU7qYeLXA7zrDPu+Or46Gb3fd1voLWp7XuXXNJJGt2/evNl7RaT6McklBUvKq7J/XZfeU2aUL6dlOZXKkXwKPh7o+b2m/ytnzUDj5Y7KT/d91HBokFlLr3rJjlMVPWfyuuF7NE67GJieCIOItto1kZwSDYqKJWdWoQryw3lZR1Hu9OS0KvSUFJjrDimtBw99OD0mPuTgOVXggY9y4lEYabeSzy+rfd6fHGnQ0H0aqZoPZtuToUsOPp3AQEd9SfrmvyvERUc26pdK/13m7lCrkWoKCH6f92adCtsrvbm4uGjb7Xbv2HWuPfDIFwIB59PllPqutfYCvBGs+DSu8lOnHEzwvgdX3h8h8MqXpXy9QJDa7wGEcp0pO107JJC86pTUVHFigs6Q17yMXvkuPFcAGrycSxrR8FMhbpbZWkY4SalUN4NCay/XBdgGlp1k6vynhVrywzLk8Pn0MtcuGCw8SLpDSTupkkwpr9Quz6e6JCPyR16SjlVBwuvxOe2qPM/XoxljS446kTtJ8u26qPQsMzn/KgisdRLSCz0oeXp6urxE3t/FMeOoCEqcT36PtuwS/FS+w2VaUbo3O3KoHPHMCMFlMKqzojWjnBlaNX2UEFWvcp839nTu4CvmiSB99EBHRWevoa+uc9800a0b3cnJyYsXygh1c2cG2+Fz7K21F3Ovu91uzwEnJEp5cAFPbfIjN5g3GSe3kqaFbM0Rc1qF+9LF693dXdtsNsvBeEdHR8vWVvVPNfJK/Zr0x52eO8LRug6pCv4+bdTTX+pHz8mm9NW96n51nQfPCZ2PiOBB/9Mophcw6HA16r64uNh7jkbTkOp7Ph3vGyc8+KtPvO3eNz5K0HU9jOnTRG7TXs7IzyQ5qrzk6Ctg7Dx4Otdt169kN5wOTfX1aKS7TtNBYRaB9KLzDHJJBlStM/hv8qlPQv4jvlw5Oa/uQUH3K4fiyL1ySM7fCP04D8kpVY6Q89et7R+FoG+uL+ip1ouLi6V8BpA0MusZUBo58LcbyCi/lzWDWHl9xlHM3J9Bep6ucmT89jWWUfv9W30+S5Q59Uc78gS2uL2ZeQlyyEuqJ/kT6kCS1cjXzAIHT5/yuKOe4c+DmdeVAkNqP3/PghKS98tsYFgVFOQAkpK5YY8UIt1LaEZ1EbWTfDeRO1ai8l6HVE5VC2ram+8IKHV4a/trFMpTGWZa/Haq+PWAQHkILXINgA+76dWerT1PJWnUoJcU3d7eLkdlsy7OLXOk4OsK4sN3FLm8vG101tXW1PTb+9H1cMahpkDUo8pJ9Iy+RyzLp/2qZxucqGvq08RTkgvboXq0KaG11t68edOOj4/bt99+G22JTiwhedpgsvkqrU+d8pNG/yznEOoF+pET7qWd1SvPs1afZnQ+0Wd7TmEmEvU6aoSONVXE/JxiUXoKT4bEBWcpVzIqKZfeEcDAwqkY5y+1Ud90kj5qES9s/wi1uHzoIJKzqIxeaw2bzWZvBwdflcmtq9whpZelex/5Ir3kqWuUQ0pXBc3eaM9BQNXeFKwTuOnJfw1Cr9KP7vs9rkdxl5IHh9lAVjmzpHssl9M+2pF0c3Pz4h0fHFkk/XbHLdDkTj4BAT9FWNNIPlL3trFdDjBT211WybeN+pZtnhlVVHpBX0dg/n3Sq55TmCEKpIcIUtlVGu9U1uUKwG9fe0hBwdG00vmj+O7cld8XYvXtCr826lfOMAWGGcegQLfb7faOJFY75fglCy5Wax0iydBRHWVfgYHW9teffFsn26vrrhPJ6fg1ImZen9FptrVqB3W8B5J6TiiNNBx1u5yqUQCv9VBvjw+OGOSIBQi05dm3H9Npibe0a67Xp0kGHmTSt6dPbXPdqfqqJ7vK2VflpoCb+O7J4lBaW9ar3ryWlID3e0xVRj2ruK60dLZ07r5AozyOqnlsgxbXtFhMNEIj4W/njYY608kyOJbnMk5O35Ey83C/uQ/jN5vnLamk+/v7pT6NDM7OzvamlvQMBHmjw+JCoG+pcx64XnMI8PCAUAViD1DVtIYoBe7k2GjUPgpJjirlS21Owdb1Vc5ZaH1mGtJpJq0cP2V5fHzcLi8v90bwre2/ga6qJwXwyoGqLAd00nWCCRGnbFOZuj47qqqcfwKnlfOfqVft8N2KTj3A8Tlo9UIzqefsk+EcYvQp4CSDnuWB+am4HAlwfrzqcJVZdXByIMw34tGdvRyyj0yUJ625cIusG4540+Khz/tz1xKffE6jIzdyH5n1UFvaodaTSW8UlmRc5ffyE3rzNOzPxOsIAFS6kAI7y0zEPD7Kosx7iLTir5eHNqOdevp2+aTAxrqUthrpeBt8fVDXevqT5OWBpXLe/N1z5DMyTXxUba7y6r7rTI/3Q2hVUGCllTHqfkKmjgx0j3UkI6kcgKMz1sffrqzVYrE7NTliTju4TKikyWEl+aW6SKzXlZdlsS0sh+ic22h9hKTR0fn5ebu/v19GCapHgVKLjDJ+ze1uNpu9bbaUp3hPp8S6QXvQcr3qObSRAVCnUoBiXUTDaQqrChbOY6/fPX8VaKjTSZ85Pcft2hox8PhuR+KJB+c3OTOOGDSS1LWbm5sXu9i8XPJBnSHfla+QratsgRjqf/JLFVjgvQrs0UZ7z02kcg7Rhwo8+f3RSKHX1zP0qnc0pwr9CITWXr48ZtR4kh+QRXSRkAR5UWeyk5PypOBG58lnDqo1hQrBJ5RDHpnHF5MSQuP1tBW0tbbntNXmKqgpjUYB/tCd1hZOTk7a2dnZizPrGWh8IZ6yqGSfRjEpL2VF/l2WlYH2Rgk8NJGyYF71gTu2ikaOJ93r7bv3fB7gWZ/6kPcZSBxtj/hykk1oFPnmzZu22z2/oS3ZaVrgTWlnFlFdd3Qt6Z/I17Qoh+S0q4Dt6SpywOi8e37fIZZsl32YePpcdFBQqJhJ93pIqzJSd+IVJcP3+qr/PYeUkJM7/gp5JupF7SQfl0NPTr5N1tta1c12SBZ+2F1r++fnp2OyGRBcZomXpEdulD396qXr6ZqCbjJKoc70TIfrgk91VP03QnPMUwGLFPScEtBQf3ofJfnNgDNvBwGGHDFP1SXfBGbJ+e52u72RjreZ/cXv1I8jeadgnsp2+VSOnO1gWWsptcMDUuUL1rR/lg7akuod1Vp+KfuoLC+PDaejSsriPLX2csHK69H/hK6T4aUO8Hn9Xtrqd9UWjnSqgCOZUD6+CM31ACLgSq7cPZLegqVnNDab5y2rcqJ6kpUnaFaByNc3KHM6LUfjqntN8B0BELUhnfrZy9dzDu5oU5Bnme60xdNa43ad4sedMvWkNyXSAyJMo/558+ZNOzs7ax8+fNgbYapNVfmUl28U0Xci6TxHHyMg1PtfUerv1P9VgPLg0vMvqTwHGj3/8bnooDeviSnOvfOeO/teWSldCj6qx4OJvt3QlC4Nr6u6nKfedjrW5TQbvSu0xnanfd4+F+/tZr9Qmdwh0yEyrwcaBiL/8PWkiV/n3Q09BfKEmlL/uiwruaeyK8Rf9VcK0Ew/ox+9NFWwSWClul7ll8wTwPBgLL1PjqxXFrcut7b/fEUaCbgMaOO+PpXax+DBe5XvSHrjbez1JctzmVQALpHbxSgwOCV7SVTpywwdvCVVVM3j+fx+ohQ0KLCE5quA0DMI/ndHmtKozLTbYQb1uxF5PqZNOy/cedMAtHDsQc8XfnnfHTz7jIvSDAo0ZL5zwfuEoxaVw2OyKQcfKSRjckPxgDBSdhpMmtKqDDgZa2WwKYAkR+l1JyeV2jGqN5WfZESnyT7y6R8vp3KW5IOgabfbLdNHp6enL0YG3KaanuNJ11iXr0VwupL89xbmUzuSPDw/fURVbo8op14dM+WQKt9D3g6lVwWFXjAgVUo1KrtnBInoDOiIfNG1RyxbUyxyZpom8d00s1G4Qkn8TorrgdLbt9s9z8tyod+NX+lUBqd7VJYHAD8ae7PZf5KU6wxSRqLPtNWXVAVOv8driSpU5QbiwTTVcYhBjfK44dNJJSfkVBm6l8GgR2foHzpYAgYvy8tMdcvZt9aWoKBF59b2Rwqyn+o5n9mA6IGfIC7x6kCN8kwbMXq6WMmhx3uvfk/Ta7cHRV2b9UEz9OqRgkdPv7a2HDeW5HwTEk+/08cpKY+3SXxw2sZHEs5Xz0kko0tUGbQHBEesVX1sj0/FeQBgeT059uSaDGGkG1WwPQRJVfqTeE99VgXq1xL7fTboJRLPPb1O7e/Zl9uhvtOIlvmVjiPNtE2851wT7ynopX4b2XYv2PK7kllPj3p27/xVYCDlSXwmHp1eGyQOCgqzBl7RiGk6YBKRgPjwISAFTkeXnLfXqXy9oaZOiEzvfO49xez/K1TgedL6QUrvQ2yXkW9l06hAIwZOS7ENHFm4MXog8eDEdQhOJ80gcZU/Sp/6auQA+LuS21oaGW0FBKrRivTwEH5oF+SHa2SqzxeDPRASELGcKoBqXeHi4qJtNpu9LcyctqQNuXw0Iq903qclabMV0GL5le3N6qXKqYJbFRhSOcyTArLnSYH4c4OWV48URCMnP2u4LK/XUSMHmeblVS+/U5k9BdI9ISGOGFKASI5IyEt5HEWNdlRUQafiNRmS2kCjT+tDDEj8pDUjyYS7u1hu5eQrRO7ycqqCezJcl5G+6QxHTmEmSCUHNaLZEUkv0CXn2nNarkMcdabpHA/4lGOSHUGGTuLlA3f+zITzx91YVXDw7zTCYPrkDyrq2VPqX9eztE4xOwIZ8ZZ82CG6U9HBb15L15MDHDHY6+yk4F6fo+LW+lMePYSTAlcSfFIu3dODUDp51B174sV5SM7H21rJL/FLR+/GzakwOm4asK9rkEc6CO5aYrpRUCDvI+PvkcuzytNzaFWent6ltMkpV/X0gMosJdCQAkWqR/2kNqURubdNlI7VUP18BSwBVGv1U8IerNNTzskXJHmQV7eBntPvyYrp2Fbq/MxIoUcj/aKMemuvnmc2MBz05rVE6XplnFSOqoz0eyTc1KkVb86Po/ZZZ+GkThLaSUNkpeO3I7cemna+WKeX5e3yRerW2t5icdoxlJ4qT3yml8C44fr/Hqrz/7OG1QsG+ox2hHwfROexxkiVd21drdXz8v7NdHxTXZoqSs6WI2TqwHa7bWdnZ8sxKn4EC/kgsY8SMHCd130FIS/HbbBna4mXKjik4Jb01fver5O33ghE7Us+1P3Xofp80JvXZipkw6r0hzBdoYPK0cw6k9lgM7rn6Lza1VDt9BjJJNWXUBD/u8Hzd8VXNcJxZJJ+c/SQ+BnRqI8rWY3qcTTL9lblHErJOKuAUCHPHs2ObvjbgUOVxx2n89tDz0xDGXPHG/PQqfaCw2azebHTrZJTD9j1HPbnoOTkxUsvMCT+U1lepo/oXhMMRKtHCrP3kpJUhur5KseTOm+k7CrPH9Sq+DgESaQytDdbSj8ypAr19OTjawAyHJezP1BWbQ/lVrc0UqkCEq97Ga60DGJpay8/FY2MeCawfg7HP1sf0804/STrQ419DXjza765oIeYUxoFAL2g6fj4uF1fX784Gtqnq5wvXyD3T3LC7kRTvsRDJZdeAEp+orJdpesFLgIytx19tBjfa/da/yVavdCchDqDWryMmfRJKDNpPf1aB1LV1Qt8PpLi1AyvV46y4ivJ1o2j4l31pjUFpktvsKoQdPVhmmRgvXbsdru9nUqpXF/crJzBSKY0OsqoR6M+GuUVVSMFR3p+LfFwKLKtyqiCwyEBVFOOWl/TU+9cfPa1COfN7VdTWb1F58R/j9zGKr+U+qWqtzcCmxmd+Qi9KlcyHPFySP+tPvtohGAqoVWMVR2cFCRFWqat0FQvmlc8eJlrFay1l2cZ8SGfXjuSw2I6fx9t4qMKGF4WHTRHFGkXUvpU6djGRHTQbFOPf04lpHbxfxrxeDBg+hGfvcXXhKDXGmLFi6PKnvH3qJq2SCNCflcbMCqZSV7cdPDw8LB3qOJms3nxelzVVYGl1Pe94DqiBBD8fpKLp/H+cT5m/YbbX6p/FrwcKhPRq968Vk0pOPFa2srYS6//1Y4cOiX+Zgc5ImEds8KqnLCXUT0ARtJzAT0+fOg+w1dSClfcNALgjqGe8qVFaudFaRQAuUedToBlVG1IDkDTcrOUDJP8sG3khWk9gImfGUMd8cJ7/F0dVpfQ/cgGU/tnHFZr+1M3+pbsfC3Ay2MA0I48vupW+kHdSKNo1xveO+QAQZdFksNoraNXXrWzytNV1xiQ3V40WuKWXb4e93PQ6gPxqmDANFX+16CnNUGkUlJPWxlTTwlG7a5QVWv1TiPmdaXv7dDoOTCvfxQEe3yPeKzKIKXpguTg/BH+mT5Jdbu+Vm2ogqloBsSQqtFIrw1MP5rKmKm3R95u561ykmlUm/SMlMCG/o8OyUs8j+7NBl1P72DI+y+NBvy30nuZqb7EV5W2AiXkIfXlWv0hHTRSUPTy4V5KVzHUczq+1933v7MM5tO1GScw00bmnx269cjfS0C0pXZWzs0VN9Xdc/yz99NTr56nV58HDPHNQ/JSP1IOacTg5zQlRy7dSTriQ3Nuu6z6LpVfTW9wanCNEc4G6R65E3pt/e6o6HjSulMFwji64PrCdrttp6enSzpOJVU8cQdTr8/WtHM2j8vWA8MscJmtb2Zky/pH73ReS696R7MfsTtS8BECcUfTM1ZP72Uy7drImYLNoVQ5edVTOdRR/TOy6dXP675w7cGHTmA2APnDbX44nwfHytk6L3RAPl2YdJEIlaMQb1NFvf6q2uykuqtRdg90VPV5epdRxYuX646459g8eCcb9QMZPQBz2mOz+TQdKNnwdZ7V9KTSVU5SfFKXvYzk5Kv0SpP0uBoReN4ZvmbJZU57GPmqWV/2qofXfG54bRkzzre32yA5jySk5ED9/+wQthr+zeRJCKtawEzO0a9VhuFBJaFIH+Vxm6orP9OkwE0eed2RHfnmdtoRSnTqobNkeD2Hmfh3SsDC0ydD7Rl/6ruek/HrlQ1VqH3WEVUOU2WmoExHpUDPPqfeeID2e2yb80U5cbTQs81qO3hqH8nb7T6nknuPWN8okCTAmHyYT8uu8cUVHfzmNZGjh/RqyJlyXQD+LQGkvI7EkvGMkFCvoxL67PHv90bbO1VedRJlVa4bmuepZOo8+W4mDvO5jTAtfldGJafHKSOfOtI1d5DuhFJAVB0ug/SMBI/JrqaXvN6R/HvkAVDXvJ8S0WnMon3/vzbIVuW5A3MbSaMG7iLTlJFGA9pX7z7j5ORkmWKqAmX6/fT0tLzUJ6XjSHQ0xTLTLz3/QOoBjRRoPR/vyzb4dkSCN8mhWnBPvmBEBz2noO/kKEfRnkae7qeAQPLyafxuDL1A479HiDu1Y4RoXEYpXbrfO0yvospBVMR+oEKls2x65c/ylWQxcpK9slle1c+Vc0/9fghocIc5yp9oFIDcUSQUPwpso3or6uk586ffDPScLpRzo0NjQEnIvtoWm3jV7wS6ej4pUQpQPUq2XPmVGfkrrZefbGoGcMzSwUdnc/jfWp4XpqNJCK3qJKVlnkq4fj5LZXy+TayHspLzSjwfEthYvt+XPHtPX48CUUVMwznc1vafEXB0vdvt9raB9oJZcg6aT07yEQ8JYFQy0u/kKNLiOEdfo22CyjPj2JO+jZyLt5H3ew64x+vaNvRoxoFVZadTTXsPblIHNRI9PT1d3u/M+jTadMDS608PDL01iF67UuAd5dG91vLT2lUZKZ2XQzvl1CzlskaHEq0+JTU5A0/j12is6X4qe7aOdLZQxccaonApdL6VLLVBVM1bj+SgzpZyeMCrAlYiVzgvz9vL677GwPz89nnhqv7Udu8rypzGmEYsvmfd5dEL2FU/pbwVKOk5inStMnaWnxxdGhmk+4fykcpxgDAiT5PWkPTeBgUC6qGAgdJst9vllGE6deVPAXXmuYKqTS7bKghWv1PfJb0f2WrKy/tpS3uyh9fS6qBQzY/3vv23l+mGOhN83Fk4jVB96lz/nxQlBZ0KjVT1V8qnb6ILT1sFuxlDSE4ntZ+BPLWflBS0d68KAol6fez9kAw2GX9Pr3oBJVFPd2bSVrRmpDJbXxWUemXMjjZSvzvA0HXO8+ubD3PqvkbLCVBuNi/fR8LA0NOJNXJnnl7fvpZ6Nu42lOxI6T4Xf696yY6jadIoIPSoMtyEqkaGTB45BF1LLMODo3eW0nne5BArRV17rXI4DASbzf7iG58spRx96ylHDE5Efv7mtqQfSbHFQ6+dXmcyeN5nWZr+Upt5j/w6Eku8vEZ3ZgLDaLphDS8jwMB0vQDSy9MLLg5AtttPb2Xj6zr1pPNut9t74llvOCT6p3PmFtEeoPSF2oq8/TOBstK/Xh7KgvWM8jNtqm8EntbQZ3nzWjKgtYwoTw9dp45LyJ1pkrMeKUjlfFO0Tuln5DG6V7VrDZrtKbc7xN79Kg3vybGnfBWvSaa8l05R9TSz1JN3j8dq3rqSzUhmvSBDWbizmClrlK7Xh70gW6Wdlb/roQMP2jKDd9X2HkJ2nRq1q3KubF/lbFP9PRkk6tl6Lx/zj/pL5cz210FbUlNFVYWM5j71VDmDnhNReYcgfiLBHjJNRj7aoz/iPbUj1e1pZjvSp656hjRyaF6vn39TOeeqn1PwroJBtQ2zJ6fXXk9BTDz7oqe3rxdck1Mb9XfavNHbiu0OoedYRiCg+r/Wzpw32Svbwa3rx8fH7fHxsd3e3i5pTk5OFmCgs5NUJlG2t10y9NHumqCX+u0QlD5Lla2nYFcFwcTnobT67CP+7iG9tPBBhntMu3OiQKQkSRlGgpBCjRZlkuP33yltr22HdlyvrMoBVErTc0jOf1L0akGZbeJvDyzaicRAmxxaFcCcXzrpnmEmVCfnS2flhu9lspxRgHN9TPrK9o1Ga5UTTGVXdVb1kBLQGzmjEbJmWo3StY7AnUrn5+d79ahM7WLirjzqqfeFt2Gtg1Qwcrn4J+XrATNPl/TA8436WPqfnvFgeWtkcPD0UVWJG1bV8CSE5HRGDkj/R45vdC+ldWN3vry8CknP1lWd/8Nr3pYZ+VRp07BVv6sFaXcGqe7qXKxKOavrM0GMvCV+HfW5Q3EE62lTG9PTtM6rB9eqHxPPPTnMBJMq/0xA0PdIh1N7K4fI7ZQ+8pFTk/NP/cG1L/LHj4+yerxWAZr/eX0ENnpUyWRGD3q+c62jn+W3tVcciNdaRlQjx5kMKTlgz9PaJ3Sx9vCn6pgMf27B+TmUXpPXHamjr9my04Kp89dDdk6jfklU1d3rZ/LfCx4VL2kk6vKkg9Gxw1Ue8eLXyA+Nt+J7pt+qvqiCy5qF+SpdFUjTvZn7VZ2p3/gQG5+c17bUtLtI11MQf3h4WJ6MZlt7gGHttZRmZsQwotn01AW/Jl40Iq8CygwdNH3kNIP0KmdQBYY0xTPz8JGX3UNZPZSX+Ev3U9tSnVX51T06mzXOe/b6IY5kbVv8fkJ3vfS+N91l7Ho3EyzYljWG26tjbXkJCc7UldAir68dNaR8fi3ZzExbe2WntnkfJzl7gK4cdE9uDhJ6NIvs19JMIEn9W9mOB00/bXkt3wc/0dxzNCM02LteIcTWMkro5a0EM3q6scdL1cZegFlj+J5vRhldgaggafjq6CIpmVNliMm4vQ5966iDlDY5+NSOlKaH8Py+t8N3ucwE7OpamlZKPDFf5QwqR09ZChmS99GUxKE0AicjHU+64OVp9MDTEtj3zKNt0N4+jTwSDx7M1gRTz6N8a2Qx6wsqfeDHp+RESSZr6bNsSW0trwtURlQZTW9XR0KKTJt+V+T19xBr5ah6Q7iKp14aluMOLRl/j8+qnVW+KjD4lIXq51EG3qb0hHBVnhuq97G3JekBKe16SgElBQn/Pwp+PdCTUG9qY+WgvJ+qkQ5txuVY8ZycewrsKVCPeO0hYPGq73SYXmvPQSDV4QcqKr3SKSjzWZxKzhWPM/rgbSIPPbS/duq7AjypTS6/1IYZ39jaZwoKPYQ1clqk0dOLozKTofYcfrWNM5Xr13uBr2rf2uu9YLc2EFZ19Qy/MqYeEmLe16CyXhlVer9frRmx/PS/CgwzPKT8vbb3Rjm9OntOu1dHzz7cOY5sqdLJysG6zVSgJSFw5tFuGzpIflLQm7FV1pv0wa8nvj3dSO/X2EpVt48Uqrpmbe9VC836XZ3zk6jqnKQgFM5oaD4ipnF05WeWJMH3jjGugsZa8kf03YCo+DPkSKW1vqJ5OxIyc16rfkmjDN5Lv8mTlzNLXGjc7eonWdWnFS89x+Tpkz7SoXAxe9SukRMZyYKHKvZoFOTT/eSUqrIrhzpj+yQ/MVhTS3oy+v7+fu+tbrvdrp2dncWy1ujRGqqCSQ94VFSBsSrA6jdPa9A0ezVqH9HqoOBIYq0jrPK5ElYCJDrole0dlXgcRf0ewui1+5CA4G1wHmcRZJVvFtWldo3a0wsAa+i1+cXLqI9ZF+fme4aTdJTl9OTr92dkVfVJ5TBGOljZw6icz+VIk7yrdG6//lukNSry39PnQ9vjeRIvqiuBDAdzlT6OAJv7t1SGyucUb9pp2aNVr+PUd7XNs3JAiWlH7j2kUEXhxJ9W3yv+R47Uf/eQTWWgvboOcXze7pkglBCGy32E4ipn4/1IhavWlNbKMbW9R5XhJnL+qpe7eHry19NFr6t3j3bVkzXTVM6DzpR5qw0HhzjIGSfbA3MKCr1nCvThaFSObrPZLMdtHx0dtZOTk+W6zlBSOWlDyei/y3BE1cmovFaNChONbEHfCXTQHtOzILO0OiiMHFDP+NeWS0UYBRyWVQm2h94SVc5tDYJeEwRmZDSLMkfIQ/99isiPAqke7CK/VaAhL6PpNzmKkbPokfc/DdJ51Kfa0Zba1mvn90UVGBihSr9XocVROxK4WFsGSf378PAQnZzIF6J3u/1pOCFhHYfBo7l77TikDRXAGo1kUt29dClgpbrVnxolpcV5v7bGD60KCimKzhjriDyoJHSkdLOoceTQla4qt3L+hwg58TZTRi9dD7FV5aag6O30OhPC5P/kxF3+M+2tZD0bwBOPlRHz/+xDYDNgZI0tjJxCCmQjQJb+p7Re3iF5R1S1r6cTlQPkdZeRXsCjj+f1vunJvUL0a/xO1fZRWQnI9Php7eWLd1xOMz4h0ao1BVek5BDWDFOUnghRv/kijmp+LDmpyiH16m8t74Wvgsprg2BFlVHoe3Yo2lMkova0hZNp+X5ld6Bepl+rdpKNHE9CuYfKm46gFwASIKh4ZJrve7TgIGmNkTt/LEej70P5X5PX+ZTO6RwsttGfxE/2LdLpBvJDOo5bOst2sl4vh9cqfzJLFb9pJFG1LwUHJ8rUN/nIjz08PLTT09MXgHuGvvctqbrfWn+OLOVJ+Wajca/cChmro5Iz8/Sjul9jcM571Y5RfaOANkKOns539iSHlVCgDF73Dnky3WmNkjMPy+sZ6Iif1wSEQxxqlSeNpkblp4DxGt5IvX6pbDr5hUoHnc/eq2u5I8d1P40a3bckXzMbKHqjAdrPoWWpnNb2AwPfg30orQ4KVYfT4NegO3cgRHVCAa7ss4GhJ3R3kv6EoPNVoWpvR9Uu5kuGk5zpqG2JFw9gjtwrWbqs3Mn3+t3bk4JtbzOBl+c0Yzjkf42hjXSkV9/aoFTVP6p7pGsVrZXlbHBJgUjpkz7oHsvz04qVL501RR30PtaMgutpsoOeT0gonfUwcFRy8dN6DxlpujwqHpm2tfbiaIs0Kp4N+J/1JTsz6I1peXSuiEEh5WO6Xvn+e1YgI8Q9ul+V1+vsqryE7Cuk7XJMAcDrOATtzgSLZIgjSkHj0BGFy+g1qP4Qqgw38XLIiMdprdErj3RgFv2KZvWXaZNzrYAU/yeUz3vkRQj5/v6+HR0dLYvPBEbamcgD9yrqbZtNgboqqzdq8DJ4LwXclJdy4lQ8Adn3siV1RD4c6nX46DcVaDbgVCj7UOeXylwbEEbl8n+SQ2pTxUNV5ozc0giBZXgf0FCroFCVUfFQobg1wT/xWeU5lNaU0QsII7kfylvPefTKr3hJvPbqT2WOEHPixdvizs35Vfr04Jby86N1y8TLjBNPfTmSkweyhPyrEexoZCHyGQG1dU3gP+jNa27As2inciDqxIR2U/lV5/lUU3VGz6yT6vG8po2z6dKT4b10PbkTHSktv10GPQP2fj8kv5RTPCmdH/Pr5Y2o6h8aoB96p++RHszU9X8jnehzBrkKlfbq6AUZ5h85RvZP74VXvK6jtf34/AQI9AIfL4ubWvjMg47MGAXDmSDnfFXBIslpZvTgv1Mgrk4XntWXVUdnVwXPoNGR8er/TETzyKwOr9DmKLjwN3lwnj39DLqrjG9Gjm5sFc9rqWfo3h/ed86/I7oRbyl/kqu3+xAkvVY+qb0zwXKGRjZy6GjWaca5pfrYH6OphlF5yaZ7Zc2Ur+s9P+L88ON9qjx8q9vMuUEzQY91pLxVQBjZol9P/oG/07E5M3TwMRejezSwyhFWQcG3h6aGu2B8Ho3pZ5VSv9N84yHOuOdMU5qkAJ62Uv7Z+r2ulH4UBGZlwX5wWaZye20cURoJ9Ybp1W/NO6dh/iGOOwXNSvazYIjUK2skx0rf0siqB068bO8D7wt9z9pl5Qt43becuh9hubrvu+laa3HUQCc7Q+7X0v1R8JkpP5Xp8mVds48LHPycApmrnH2Pqg4evTMhIe5UF4VzCH9V/V6+XxfNTPGk8itj8yC7xkmtGdEwz4zDp6JVz48kPtJ7kdOnQrSeR2WlgE4D4YdTln5f5ftuukruCbisoRkdWVN25cTVJq9z1oFVtjYKaikwVACpCuKuK46Wmb5qG7ep8rqeb6B8+HY4R99r/EelxwnkJp7Tf7+e7MjfXjdLq59oHt3vCcxHEum+IwDv+EohenX27id6bcAYXa8MqNeW5LBmUNtafkd1pg/Lq4bgo/6unoxew3PPGTj//tBkcp5rjanHV+KH9+lYD9HZQ/gRzfRXJQvy3QvivfszI6eeHlbUG+FVwc6fEvaykixmHbjXOwqkI779W/cT72sC2atGCr3oxbRJyV1ZmG/GGEfBQMQXb8zmqdJU7ZgVdmo/f/voYhRA071kfIcExMr5617aQuqo29NXQ3yWn1Asy3GZVNdEfmw1gwF5mtmi6HJhO/R7hmaBwiF9WAW3WaCQ+q61fGhgqsfr6znAWTDDOnjKqtt1RUqvD8tLMxP+oCVHoKLeqQrp9wgYVGlS342CCXnn92cPCl4BG5Ea4IjHjdiPQZhpqMpNW6xm0dWMcNzoe/zMBhq/3/vfCwi9qJ+UsBeYK4Vm/6S1Gv/v9frhZHQUaR63R4nHFFy8PBqyj1APDeSj+2znjC57u3qU7vecdA9Y9UBDpS8je0h2n+pKZfG7AhbM68fiJD49T3Lu1AUHKSqb/PtidAUGZoCCB9Eq7Sj/KN1ut1vWSWZp9UghMUAhaxsoBZM6zo2TjewpKdP2Glo5nZ6h9P5XZa0NBr101QhhxPMocPXKcMVyVFb1VVUv0VyltETn6Unynp5VQY33aODucFwWhzjxHoLfbDalEa4NRD0UOlPm7EhjFEBay++E9nocCPrv1Hee19NV9u/6yetVm72vWY5GQkTVanN6r/jI6fd0KgXlVN6agFKlV1D4Xo7O9ooYXRNaqpgUcaqketAk1TlzrSqrQrdVWUrf20vt6WfQbxWAHJnMUtotkohG0XOolJOG5zIS8euOPLXRdUF7wnXcsbfBnQZ1jG3z4JSexUjtpCNJdc+eGeMOz9up3UuHPJFd2dXagJDSrdWrVEZP1xI/SU49wOB5SFwklox7vKosP4abU2G65sdQ+7MQHDnrPqekZsl12u+JB6btkcsqyfLx8XHvoMARvWqhOTmGkbMQJeFURl9dr/hiHVVbUrnMVyGOXp5enamDqzJ65c3Uy2sVIvP2OPLw9KneSvYjFOT1k6dqoc+JbaSjol5pJCIjc2TpvHjZParQ3tq8o/pnHN8h91Nab0/vWu8+rycAUekHy+xNM7Lv0+nGvfZXzpPAx1/uk0BlmsJMNAJpPT/o/yvwNRs4ZungYy4qZSAlw66uJcFWzoh5Up2pPnc+MyinatOheXo8pyg+CggpfXrrHIf8s+jKv3lA4WuJPKQ36zmyS7x6MCSaU7mt7S8062hlb6vXP0s9Wai+ns5VNErH9q/hN4G66n6v3AoI8l6vPAbyFCgqXkdBa+aek+va8fFxe3p62hsJuA4pnXh6eHhoT0+f3hGdeOiBoHTP0834Wm8/61eQ++wjhZFjEwPJKc10kiIzy1Lj/KP0RIisp6qXAqqcTe//IajS7/cWxvz3DI9+z5Fyj3fyk0ZjLnOXH+tjPb1g3kNE6f4sSuJIg/cp73SMSCrTdb2HVFm3O0Evp3J+MygzyfpQ6snU63VKedLJpqO6/BTPpEfuWHs6kNB8crLVbx8BHB0dxdeBKi3BBfMone9W6oGD5Py9fdV5TpW8XDY8DHBEq4NCqtyv9/L3KCHU0ZHLs2id5c4EuEPr6pXpSlQFgTVt6tHsSMrTp4BQlbnWsVRBkNeSMSWDkM65AXodI2Nwub+m3VX/++L7yJ56fM7SLLLupUl1Jltn0NO96jWnsyOU5MQd+PBa1WcVAmc6/tfuJulNWogWAPZdehyVjwL5qK0un1Hf9ezdt4T36NWnpCZHW5GjSyLa3e5569RahDxLaVric6EvlTUqs9e2tcNEJ8+fnqruoZLWXu7jT/y5ka2VpyP2GfknxFmBk5lg6GX2TpIkj6NgUfFV1eNlJ+f6ufRzRK4/M/VWo6DKIXIzRSVv+QSlr/peYMGDgy9Gj+ri74eHhz0gut1u2+np6bJJ4uHhYfFV3ldE5BppKI+PHlJAGAVRBiWXR2qfglp16GRFqxaayWiixGxCph7pVf4haKwy1hHR6KpA1OOjx2uP74RKe3lGfHyu9FTqJI/KQc04kqQ7PUfLPCn4jPSP+SonnvqLu1u8TTPBYOae8+vOv0LgvTLW1lmlH9lfCmTejtlAwg0AXo7q6o0qRrrjPqZqb/JDPsVM2+Duo1R+mr7kVFP1nEPFJ9uZ1t96Mk87pmZodVCYcWqbzWZvaLWmjpSeZ9R8DoSfHlD5XE65GgkQuXvaQ0YFa2i2fMo55a+Quf+uDNbl4P2dnLrnrfge6YLz6dt/ydfMaZmpfbo/yuttOWQU0kszynMo9YK3O6mRHJKsGSw8/6jvPU9Vf6VHnpd8SVfk0xTMfK1B7fepJ45qHh8f2/39/Qs+UzCYCRQuH947OTlZ+OMi+IgOWmhW5R5Jqw8bw5GCNzKRO9IRMp1F8FWdMyg0lVU5uMrxz/7vOYakNN4nTpUS+khhVj4jZXZ9SSiztbwAnxa1nd/W2os95T1K5Xhb3LFV6Wfk4Xkr4DNC6b10LmdPl+qs+tjTjhD590WUvfe/dIO/2Z5eQHKqgI6caWvPD1mSD+1S2u2edx8pnx8J4gBUwcF3Ofkuwao9qX+Yh097a/pqDUA/KCgkQ3ChObGDW3tG672dC2v4qmgGjVbofuZaMr5ecOiV12tLlX8GTSbHREUb9Z3nTY7+UGIwqtpV7Vl3R0D+2M4kA6fKQXr+BIaqtKncSh9e42BnQFZP11/LA+vvgZle/sSLHPPx8fGefiabnq13BlRWn83medeRbIZP5TvfHgx89OBTSRU/LLdqi8uTQUCg6bPvPkoVu/KzY3xRlwyq8UmYjg5G9aeh/owBrHVkVfo1dRxiMKM61vJCJJEo8eaInWVW88J09urXtOCVggIBg09ppafLZ+VJAEJU5jszdN8Roxv52vrZ5nRtppwKJc4QkWQFJqqRiJczqqfHu+sN01PuSU+qcnu+ILUprWmkdiivHKsfxHd8fLyU9fDwsLeonJ6O5hqD8krH+LyDl5GCg+us2qby7+7ulrq/l5FCNXzppe0hliryUXHTfH8PeY+GWCmvByLSGiSvsryO2RFHRT2EO4uCU3kz8js0uBKpEN0RITFtZfAzfTLDD9uWdNPRfnJKKe+MI6+c6uyIwZHx2sCR8vTK6PVDctQsk7zOBiqmHQW5BChmRyg9XzSbvrWXAIl6rt1O3iZ36q29PNKGzly2wkCUFqjTc10aDRDM8NoMHRQUXAHcqNTIKm+65hGRZ+7MOIcKWSQjS/y5Y13ruNMIZzaQrh21zJaz1qm6A3KZuJxSvyptOmvF93KP2jKDxjkaGcnRFwTdqKuzbDyQ+bbASqd6NBMY/P5MwOgFxUMC6kw+52UUNCn/yokqv+rmvH7ijc635xvcTyS/0QtOvs4g5M9vX4h2J+67m1gOt7Nq1KB1Aa5V0OmLVAafxN5ut+38/Lzd399//t1HTkR+a8id9WaTD6jyunTPr/G/K2NlsEqfFKDXnl6a6oG0iipnPRtI1pSzhkZOpXISVQAeAYbEd9VnVR53MPo9eqhN9blxpVFCeo6hAhy9NLPtqdB9Qstej19zu0k8VbIe9ZXTjK2ynCodAdZoBNGjXh7XuRHwYZ7W2h6I8LacnJy0p6endnR0tCwm6xkHX1QmQPH2Hx8ft6Ojo3Z8fLw8K8FpKR4/c3x83E5OTpadRufn50t5d3d37e7ubkpmBx2I1xOUO+MeVQ7DnUkq341kpvM/FyL3cqv/o2uz/FRBcm29s/VUsnTZM19l0F5m6r8K/c1SesApOcbksNLDQD2gUOlihYqrelM6Tz/S6zVU8fc5yuk5fadqZEOkr7x01CNQkepJfB8CmhyoeP/4Gph+OyglUOG3t9enXv2ab+PVYjxHGeKZax339/dT7X31m9f0Py0KjpBhCgoUoKh37gejNeuuHO+sw6mcTCor7aBaa4A9tPL/ino8VPLZbPanjmg4ypO2vVaIfiRHykzIrLXnDQ09/t35+8YHpq3K4nZIR3ujvN4OzzeTdo2jPMQhVvzM8ifHpDyjoOKomXlGsnQnrO9e8El8pKDcs23pnrZ+kheh/Nba3tTO/f398k37cFm4T9PoYbfbPz787OxsaatGFDc3N+3h4aHd3t62h4eHaZ+yeqTQCwxraBQoRml7+dYEBg9OM3X1ypotZ6aOmeA6otn+qtBwciTptyvvawJkKsP5YrkenHnN21I5BQaXURsqWSldqrO675T6uur/mRFbNXpJ+XtlJxAwGhmN+Eg0K5teG5KNps0Nqa8PkQnJ69ntdi9sQ1M9SisAw4VlfVfrV7rvowc9HMdnJ3RUx2wfrHodpyM8j6gzqK5HHCIROacy6IzSSGItzShX73oKCGuc4cyIZqSwa0ZBawPMTJu8vyrHm+4lZzZChdS/Xv87T6wrjUBH9Y6upcCg6/xeU89sYOnJX/fXgIzUT1Udlc7O2sMo6HOaRv3kx030AJCnq/hJvqyXlpSePfAnorUgLLSvhWQ699F2VPo/jY6fnp7azc3Ni+mls7Oz7+clO2Ik7QJINOOok5FUUVHXqjKq8nuoLpU9Mphq9NFL67zOOLw11Cs3/WfgZZ5Zh1EBg1F/V6h9VPYMVQ6Q/ZqG50k+1R72tf2yhmYdPadivk9iYK7qGqF1z++I3ctJDr2H5mf8g4jHZ/SIelLpoV/39QHm5aKyRgS+ZsDdS0L7nBb3dQgGwuPj4+V5h9baMl3leq/AM0OvWlOYSTdK/xrl9gi6xtFWwacXSLxNM6jRyx0Z2Oy9EWL3/6N6RwaW8o9GVynIpBFVorVy6gWF5EhplFW+hIJHqPe1Ab+ql2X7t9c/otk8Pb0Zld/j0flIjj/VzX4Z3U91OUhwXkkjYOK+p4foHbQRWHMNwp9z0LZSHzmoLK2hac1C5emjNNrO+r1sSU3IKwmzcrLeYYx+vDbqiKo83ks8J/5m23tIIBjJZpT/c9AM/87bGvn4t8u7Gn0c4nCcr+qIlITkeuUwH9vQc2qje6x/NqD0KNXnes106X5K7zTi7TWBorX9rb2UsxxgyuP8y28oL59TYdt7Gwd6Tt/l5z7Jg3YvCHidlS1INpSJdhOxDA8Op6en7fj4eFlM5tPVeqL57u5uWWOYodXPKSRH5w12mkVPI2eU0McIrfbKqtJWCGS27Ap1rEHGaxDlIYHmkBHLIelGaSsnV90fOaVKH9xAD2nnCHCo7FnHmpxLVXdv9MBrqYwUTEZ1V1QF4IoSX8mGHej1AkJqTxUAnBcP+D2ee22owG7Fg6dJdacjXEjKJ+fOp57l+O/u7l7scOLzDDO06kA87zANg8isb8mqymFD066RyuFVQvfzXFwBvPyqjb3rM47aKRnzIUgr1TUjX12bNV5RhXKdpA+O2slH5ah78kp9NmPQFX/U2Yonr2/23poAyTw9J5N4nEH6VV2jfJVMK4TsfI/SeT2+5bS1tof4/V4KRmwX14F6u9BmbbTHe8rTCwwjH9YbXaRraru2uG632/bx48e9XUdpoXpWTw9aU1BFvZ0bjGhVR6QAUQk0oQfWy/yzT1pXwSLxNVNeSve5nEiP1rbVKR2sNUOVoY7klaZ9Ro4rPf+ifMmhzaDA5DD0GfFY0ZqA5VMpa2gW6c6i4TWjr0NBTTVaWRuoyIcHl5lymT853B4PlQPvUZq2UTlVECDQTv+32207Oztb/muqKB3bnQJ3j1ZPH62JOs5MUtYeEqjK8esqx9NUAWWGZoPCbLmzowQG3VRHCjpV4Bk5tArB9/iv8vXKWCO7JPc0QvA+mVX+0ehF3z25VvlTmypHU6Xv0WwfJho5u++bkh84FMyMZF/Z0CGjq2oElOzLQXGPkl6k+hgM/Oyu1toyPaQpIm/DLFAjvfodzU7VVtTRUKmXfsbQ3Ygro+Z9r48o8XOi+bWBY+b+TNtmyxspzEw5lJ0/b5LKqYzC06W2zAYldxKJ55m6qzpeg3BnnJQ70kMDwIyDqtLN1Jn0pwq61DnaXHVf173MHtAc8ZrSen29EUKPUvDrAYMq6FRlt/b8bAKfceB9leX2/dlHCpWBzDr5ZIS9MnW/+r2Gx9G9xGdPyWfKWqO0lVySsVXIqZduBjlXedYEn7VOduTw1zrdtf3vDqmX/jX19UYK+l/Ju9KF0Ujbr1Xpe+j30KDX4ys5qlEfzPiXEaVRigNVIfI1waW1/XWqnp5UgS7JvDey4/s//FTfSkfWyO7gdzT7PY4QKidVGaYLJQlsFBxcsTzqz9Js+lFAG12bKW82iPr9mXyj0cRs+2aCVKpL/eijMj8np+Jr9unMGcc9U1bP+R5afy/dGgA0OxLg754Do5M8hPdZAOdp0sGGrT0/HJYc+gw/a2jU9uS0GVD8XlWG+5lqVJL0jkFht9u9eKr7tfTq6aPkAEYOh2m32+1ypGxC42mYV9UxMtyEFqiQo4CQ0M2hNHJWM873tXVWhwyKkuwPWRxVOW407Ie0eyzxmvSEjkxpqgd11gTaz9UPXs7n6MtUlgOntQjxc1Jy+rPgqErnc+bpbCBvt+tF9UQ1g0EaPfWAql936gHF3pPWSc9be37XTFpHYL5DA8WrD8Rz5mdpFpEn5FAFhpFD9/qdl1l+1qRbG0DWOq1eumSYh4waSNUoYIbnypiSU++VQ7m6Hsw48VE7D0Whh4wiqjwuk8r56787xOTMRm3x+l6Dxntyr4LFTDBzx13pN8EC81a8JgDUu+/8eD5vWxVMqMMj/SGAba11RwizASvRqqAgpNi7T6Gkl0+IRiOKWYQ2Us7RdsvZYDBDSQnXBoaRQ9S9WaN0I5lBbalf3MFUCCWNwnivAhXpRTf8Tu1RWX4KJbdCr0Xon2MU+H+bNMryFwE5KFjjGF4zwugF6ZSWRzKobkfm6Wjp1p4f+NJRD722VICLulbZR9WWtXIaBZ9eeslKTznr2O3UFvK8lsfPMlIQA5UT8Xs9pzYagq1B9YkP5/kQGiG4WRopaXKe/D1C7Lye5JYUMpXpxjIK9P6p5MU8zo9ThY71W//TQztJHlW5VbpRX/XK9nvp+kxa3ue0SRU4Z/SoRzP5ZuXJ+6Ng4f1aofaq3V7OqL5R+ak8tiVN//gIYWbEkur1gKUP9Ty1by0YJR30jmZem1GK9DsZd1qoIQJa49QrxXEequg8Eiaf5nbqBa2ZgDYy9pm8qc41wXRUfionnRtPhU27JFJ5h6KvXkBg22cc+iFAwo1zJtiN6u9RD6D1HHiFiEeBqZKbO/EeL3RWM3Jxp+h5ezxzvr4KNGuctrdnFDR7wcWPt055/DcXmFur33Xusp09IVa0+olmMZMQYWtt79jWily5eh2z2z0PHXtDRJbrZfD3yDnOBASVpaNwZ5ytK3Xi+TVOxOtxnkaOMCF2HxW4DPXfF+n5khANdRUkvD6Wpb72dnIkwOtpajDpUmpL1Qd+rTp0r8q3lipgVelA4qsHInzBvadb3ObYS+sONvFfOf2qbZX+8X6yIXeeFciYkWlq36jt5C3RjN647hLYcN1AR2zrwDtt0EntdR7X0EHTR1Vnj/LPONxUZur0Ho2c64zD5PUeb0q3pm3JeGeo57z4vwpUPZTj8hgZEL9TXUQ3Pd6rto/4q177OlNeakNV5wjRziLekeNYG2CSc/Trlc2ubdMo/aw/qJyo88q0s04tgYYEDHojgpFjr8oc8bVWdj1if6Z+TWVWNl/RwWcfOaO6r2mVaosn0yaj7AlRCMaPk3X+eo5hbVCqnBmVlvO7vu9+TYdUCGJNHl2rnHaS/2y5Xr7L01Fbay3OfYv86XeOPHgttcXr1TUOlX274qgtLI/B7LVG7fo9G0iq+nptSba5BsU6vyldTzfSYnevjJ6tp8CwJkj06ksByH97W3Rt9gVMvcDWk0tlo3qKWaefVvXRF62ZNhKteh1nz6lW0UtUIcpUTu/8e3c8PQdcTVektCPqoYXEWw99pjb1gm2iKhg4Mq9kPuqL1MZq51nP4Hrl05mnIOJlzpSV9K8KkCP+qvQzaLZn9CNknUY+hzhGH02k8is+kmOq2jIKLjM89vL0+Ff9j4+PCyCrpiBHfHk7Z3wZ03CNsVofTdTrD+qAwLY/xUxeU309v5zooOmjhIblzHvHZ1dK7oz3ojw7Yo3TTBF4NiAkfnvBMaVzOfTKGNVRpVvj9GbLXMvTGhSblDhdq1C8qNrO6vVXo4JRe1IAH+U/ZHTRy+PIdq1u9PR3pt4emOrJmzRykJWOJJ51rzfiGNnCKKj1fFFC4SmopDIr3jzYuV0z6PWCQvLNa0YLq0YKrbXlDG8xmSLlDCMKIj5V4PkkBI+YTqPOT8rzuZ0yy09BoMrTu99Tek+/Nhgk55L4mlWqnhPQ/WT0ur72HJfKaKWbStM7xmKmH3zKYI2DTfrmu9YIUkaAZzTKUD0z6Zyv3n13UmsojT5GVLXB06R6PM12u2339/dDHr2vkj+jr/OHyFhOT0el61Vb02+9h1n+0I/IFnGE0tua3aPVD6/1mE/3elGzV09rc52e0h16vUcj5+E0g+Z6DnltnT0kN6IRH73yeu2c5WFGcVNZPX1Io9SqvJ6TpyNcGxh7AMRHrX6PwdL5mR1RpLIqfkg9FD8zwljT76N6vf5RXd7WHrBJiLoqn37MEXziv+cP1zrp1p7XKkflVvX8f+1d204ku7I0l5nF///nPMwaEA00i/Owlb2DICIvVc2S9lGlhIp22em0nY4M18X1LSuFiDzIwtx9Bu5AZ5zqUGZKWWBwE8tNJLRVOblqs7I1E+cozpEyPZ06sv7fEvy4/qkDb3H4Cjw7faaCwJaVXidft43dcXZAoXxnjx3uvZrKZrdK68gWf3DlOisa1oH2KubMeODwRR0jDwcerse9T1C1A/s9Hq5x37Tn+rYGn7U2fmRHOQmfr578QPDPOs+BOZ5zoj7L56QC1gxoHbNU+SZg5ezk/mA7WX/nIYEqqMbRTRzWF8IvsHFbVBksq/J32bv6bq9ql2sPB94OueHzVf9k0slXgSe2ofP+gVplTMQBt2PpvO105ItLdjzfM7bPOzVnl/y4rLJd1eXszWxiXY4Ao6D/xNYWeNmI2+bs4cDYkfGNZpXGRrGBHRCsonEcOSpnYOc62zmDa1unDQpMOqKCXNYeFViyoKRAkfsws4nr7W4PzGVVmWzCT8ZU6avydX5zv04AchIMXHDqkJ8MyLnvuyuMjDwom7O+ZjDszg30uQmmcDsVWCpyo9rl+okZOduM+VgPg3RWBwcG/vay0uHqxGMlm95oVhVi5MflTscwN3DZCgPz8Xn35TQXaFweFwidfdVkQmdUbD/TUa0yMuDN9LKN6nc4ZRyZqWQ2Zd/YwLp4EqjA1x0L5WPZm8lO0GYEqC64OnEBhtvANzrVyqkKNFXatUXZ5OZsBcpTiTLBqkMf91uFIXtsiParm9Q4/9X7AyqYxTbZERTiHQWHo1zeBbBMNq8UXORVAcP9Vg3ADgzdWI/SlYEJ2ucm0ZTBZL87ZTJRtrgVQlaGA4+zQzEv1Ud8OZABkn87ccCeEQIVQLsOnvmCEzVZu8FV6Zn6CPoqrximNmR1qTms5kg1f5Rk+baOnbNL5e3o7pTNmLzTqeZJlFGAzTqZIOF59Z1mLsv2ufqcjFcKfH3aTeCJA1U7W6Ko5RkOBk9ed0QdbH+2WsjAIWPpmYNngJ6tDlD4pa9MlON08v3zzz+Xva1UX7u3WZ04cHKBtwrIXcffCqocAKeX0jKdGch0yk/qQybt6ssCg7OX06s8GWms6uOxqISDAOMFvndQkVulW9mPDF8BPrfdgTfqV7q4nOrXiY+Ov9GcgRnni/9jCRQ3gqKzQnjHQOcs2NHKFgeiGQuugMVNOg5GrLNi6P+WVM7t+spNSHfZyBEDN2lxUuNNxW4QzBitmwDKdzp9wulRRt0M7YJ81sY4h5dAlGTtxL5Q5dVlQGWDmgsKvLPyzn9UGTUuFcl0BA3JjPOrTluyFQrXlaU54svArvoI7ydwGpZTge3bVgrKyTJgZCDHNNYXDXK6nD60wbFXrq878FkfKODsria67LkLjkong2MFcpVt3N+8bTjbyvteZXqRqeExk2sx/WgPn+P2VkHNBd6KNKn6WYeqoytuTl67XDb34/fEftWHk/mQESE19lUA76RnNmBaN4CogMKrBNzjS9Xx7UHBiQLGMIDBQU0AdQefjcfVRQUwjrE63S4IRb2qHne+WlVkupxMJsMWmQIAsy+lL2PLrn636kA93I9utaDKItuMR/tUvWqssv5XXw3rShdsw/aMZTvdvDrhuea+fZ3Z2B1fxYxd0OysBHgeO3Dlh1zWWl9IDNui9FXzTuFWjNXd3d2XbcvdW8iuXvSp8/m83t7e1svLiwR+XjGowHf1oKCUZxPZCQ4sRz/u2Eynmrg8ibIJn3XQpF0TwM70ZsEM07t2o2TsFfs7AwDUwyuuiuU4W7srk6q8ax8DPE6aTL9bAUXaHgap7HS6nI9Uq5FJMO7mz6TDfCeydWXE9TsdCoQ5eGK+zrxzPqFIqcLQzkrh/f39y+Wh7A/1fGtQ4DQFdAqgUTASns/nT+eyx+64I1UQqMBGAYXLm/2eiApQk/+vLdMAjr95pcBOzQ7v+tH5xyToKV1sJ+pTG4mhzcjIt+yvVdmf6XNscQs4bi3bCXbTFQvb4wA0Y+lRJnuQwa1GcGzxHI63slOJstG1hXd9iL2SPj4+vqwYsnkUV0fiozr4YR3Mh/8j8XHELZNxUFBMU7H7ivEr8OClrAoCGaPm/1UZbEv3iR3WqfqhSlfnu3qzyaTyqTo7ZZ2dWT3KmVX9HVs7AZp34GUGpNjYlj3lM3/PRIFoB2QyttnNq/Sq/nH1s17FZhUDVfoy+9k250sofFMfQTPrA/aFSqo2OEbu6sJgoPRkRBXH5Hw+23sHyu4I3s7WTDbfU1CA75ihGuyKEVZsxLFETmP2qICkIw64HRBzvkpXNzC4POxgjlVHXt4CxIFgJc7WarK6eiq/UMdMD7KmqgyWZXJT2ab0Y1u5rAPqrkz7zwEP6srAf4uwX7k+yOYQ25f1I6a5Oa50OB+uROFZVi9jIQcGlT8EP8vJNlS4+q1BIYzEG8jB8BUQqxvD7HBcHtOxXtyqFn+7m88ZY+4+jrdlsioHr4JDtqrZW3dmhwoyXcfhgIvpzADRPra1W6/zDz5O2ZFj3Qhm4Sf8ASNsg/s4UFWPYujfJVP/2EKcsqCU6XTgqOyq0tWNVvZXJp7VvFPj6b6pwP6nCLTCQdW+SD+fz19uXGN9aKPy/28JCgj0nbyqI1CPA8/MOTKnxkZn3wVW9U2A3J3fyrC7AaETqDId00BXAZwbXyVV/3ZBsVoZqEmXMXJmoF1QrNhmVk7Z6uxDXRPbVJ4tZKMTsKt2Y1/hfMvKdGxw6dxmHNtOH6ixdb4Uejv3WNDXbm9vPzF/NbZqaw71P6dxQJgQpJDxSoGv+/M1XgY5HpRg9hH1eG+cYPFqm1+eIFsAzokCFVUPMw8FNIqBZ3pVfsVwlM3Klop1VICvyqLt6g/1qKCsJqvaxVY5bnUpKv5XE2AaTLOgqsZOrXhUHtbVFRcoukFirfVlzqr2TGxUc8XZndWh9Ko6eCzxhjPm4fZlcxFB1H3wpkOwJqspni94M9i1VQVSth/TVABQeTPZ/Z6CA4mY9HypKQzmpZBijo7BKaDsRsJsoJXzuvSOZADbZS5Rb3eSdgLIHlFBP35v7Z+M9XYDuiqbBYatLBr9EidbFtg7onx9wu62iPN3leb6qws4VaBU9bu5n60O4olowLMAABNkSURBVHfgT1zeUf0a5YK5s67s62jKZqxb2YaYGIEtnr50WIF4ySsTZU+2DUZXNn1PQUVgBogsUkeUzCJ55ogqIGQDg5IFGle3SkdwwDarMiotY5pKtoB6B6gdE83yqvHu1NEBYuVXWRsUI1L6O6yvK8y2s3qcL2bseosgWGRBMAN9nhsZMev0ezZuXRKR2Zmx5GmwcvW6flFtyQIp1sUkGetRevl9Lmwv2+wCwiQw7FopuBu9GOX5HO7hwasIlEh7f3//lEeV6TKzbNIptqfs4m9Kd8GHz/EAV6BVsSNXDh16D+iw7q4+Fcw5CO5hwzz5MvBzdu2RjKwgWFyD8VcBaI90QdqVZZn6awaOlX0V8DGB6wbkbn9MfDkwLN66Rrt5XuEDMerpI2wPBg21/9G3bJ3NDVN/7ryLstFBrDtEsZYpS2U9qq4sorvyFRhg3ZHmQDGzTbUly6uYTZe9urHCOtV4TQKjCr6ddqk8VQCeTupr5VXMuQMWWR90QXV6juuJ/N16O3qza+db6+gEHYVJVZ2dcah8wK0k0I64tBWXrnA/MUeyM+bfTetIOyioG8rROLUBGqa7rWMd23Rg5hgqBxcHHmqyKqnscrZ1hHWrxxzjqFh+BxhdWS7XmUj8ZEX0dUYKlD3cflXGjY+ylX1IlWV22A2+k4BSibOlssHpcf3QASvWV62ieO5WNmdgqMoiFsSxmg9cTxVcMt+M+t3upS6IZG2KNjMgKzIbGIkb22GfMaZVO6C6gDGVcVBQQQAFgwXmiSVTNM49S4x6UJ/6H9OY5XYlyvKWtNjmTgDI6s428puI6iclqm+cLi6DdWwBL86n9Lq0GAfV35jOk2LSvozxVYGNGR9vu5DpcaCeCfo0j8s1/MnZGBL1BHB17cXyKr0qw2Bc6eyswuKI209k5ZzNityq4MZ2KxwLTORLQ1j3+/v7l/MK/DnAdfrFyfg9hQ47VFFRiZtQWXBwgSGO3LlYlwMBHjwFOFuCjWuTyrtlABks+LgHOLr2dAOHGlMlbs+hbiAMm+LP1cs+o/QpVu4A3/mdsi1rQxbMMlKQBZ1JG1G6PlAFPAfyk/p5jk5tVDZxgHW4Udk1YeeMY0gYkYwiyOOeXVWgyqTbV6OgkDkjN5Y7HNNYXzXh1aOtzDiDTa61Pm1o5mzmdLW17gRYtwDwXgB1ebsv76Fk7HOqJ5vM3T5VfqX07mFFe4Im+27GdrmuDHRw3nSARgHadDUS4naPVf2P6byKqAIf51HBVx1V3V0wZlH9VfUdY45qk7MnxhSDwVr/+QCZWr3EEXdHRV2Yj3eaZmI77aPdG+K5tExPl8HF0V2uUlHenUf9Ki0DRWcb1tsp73SgDZ2ylR6V7nS5sXATEctUbc6cEf0AgQX7EwN1xaDjmL2INA0CHQZZseRMp/MdB1TK/k6+bCwxT+aDrp3ZCqTTNw5oWU/Vv9nlLe7fa62A0MauYEC4ubm5BAX3XQsGdQX4rB/vUeBq4+orBf5cYgd0MoBiHUqviqxr1cs8XtJ1mHfF3pRtThTLRVGfE2Wdlf5On7IexW6y8xnoM/OZTDpcGsd9JuX8fOONAZ4Dw1rry/XvSaDuSBYouuWnIBJlpoxYjXdVF//mOYQB3OnggFCBKz51k80Jp0P1zRaGXEkVMHGssnxIcu/u7i6fK3ZzIPtojgsieNnJ3Uh3MnoklRkZfuGoChgqvWOoK1fdvA0bJ4Es6ovymbhgww7i9LMuPpexu07/dlcuE4ng7IK1ys/AxDZ2VhJRlsuoPp48LeNsRhtUO5T9nCfr/w7QdW3r2OKkYvkd5u7yuWBe6Wa70Nc42Lt+VJsTMmPO+qfblw7IkZiotnO+Hz9+rJ8/f16+qhZye3v75Xszrg/jOwu8QvjWlYKSjJVuASQur/622FXZk7UDRYF3ZdO0T6qgtBXotzAm5chxdGPCfbQnMO1hjQxcSkenTxTzdfk6Oh2Trtra1d/N07FR1Z3ZXwXBLO80MLr6FGt2f5N6lR1u7DJ74xj/x+Uj9QnRDJcc6HfaXMmmrbPxN9/URKDADpgAOjLStT4/kdIFd7TBfUmrsmOSR7GiTBy7cvVMgpqzLcuf6c7+1vr6PDVP2Kift1iPZbOzM9KwLgUK2Pf47eVrBaQMkNm+bLUwAcQMZB2jzvRtlS54K3DcG0AzXcjSWa9bJbigoMaJy1Y2dMEXH+0PHefzef348ePTPMI9klgiCMSHd8LvVVv5ElJHxk8fTVm4O8+Owfq77L1brxv4PXVMWHQ2EVS/du1z/dVhMZx/YivWp94tcJM1G4OpHyk7J23u1t1h8plN1fnvsDmzISvvykwB3vkOt9u13QFw9j//RpBWAM55uE2Z7o5U8zX03d/fX4KC2/oHwT6eRlKXjHgFgYGhK+P3FBSD2cM8s7qq8yzMHtlBVNluHZnjZix6D1ut7KpAkpeqaLfKGzocA1VpVUDAMlVQ5qeNOL8Lsvyxk2mfM9N3ANcJWp28U7DmsVP50N/56OqvxjYbxwoss+Do6nf1YfvYDvxzdeGfunHrbM8wStmrgpXDAVw139/fr58/f14uJbmgEC+yRVDAnaY5EPAqwfWvkl2f46wiPHcIDgA3mNM7YK0CVFbWne8AYVcqxvlvCDoks54Ou3R5+PJP5HdjutbnoIEfMUeb0G5uA9bNebjNNzf9j8pnE8SBVWf8pmwyRH0/pKqH7cP0LTaw/qqvmVA4GytbFDDjOfU7jnEtHoHPAT0HfwRStJfr4u83RNsxHfVgnY5E39/fX1YGcaP5169f6+3t7ZLv9vZ2vb29rdPptB4fH20wcysFtTLqyFXeU1DC0XbCSvasEFT9Kk93xbBFOsC7tc4Ja3VpGXBNbOpMdpUPnwrj9nTGUtkZwWYrKCuZBBksk7F5lT/Oqb6ftqUiOFnQd2V51eFWIipPpcvZ0ZVqpZCJA3O219XLvus+ZoTH+D9uLkdwwECBl4deXl7Wy8vLent7+xSY1vr8boYKBFWgdLJrl1QUVWn12Ch3PEZmda5aRXRt7ZYLcY481Z2xoamN1eSeSrahINc7ATDuN2Zm+L8C/Q6hWOszY1TXULeAa1f2ECbumy22bA2EU70VmWC/cJjAbcYtonkFmq2C1Gq42zasf611uVGL/qi2oEDdccR3baIfshXwWmv9/Plz3d/fr4eHh0sA+Ouvv9bpdFrn83mdTqf1+/fv9evXr/X8/Lyen5+/2IT1uD2Pok1x/6Ej46ePskHgc4qdq7JqkF0AqFhBFTzc+Y4TZSCswMv9VqCK7BnzVwBd2a0Aq2JpCgwm/VMBnRsDxzK5byKYYFpmLy/7uV7VBvd7KtVErBg0t69isNdaJWU2cl3OxzKfQ3zotk3ZgkTSfdhezSv1x0xb2eN2V2BfxDaxr9/e3q77+/vLDeaPj4/L77XW+vPnz3p5eVmn02mdTqf19vZ2+a4MPknJcwT7GlcLeB+iI5u+vIaNzRx5r+5p2Q5AdlhnJRMWsjcAVYHI1duVDghOx6PLXNl/XADpCE/kLABj/Zm+rnTq4nzqnAoMW0GeAXnatx1gjnyd8e4C/tYVT0Zm0Cfwf1wd46UWvhSDK5h4jDoAnNunjvwXl47i8lHYHSuOx8fHy83nl5eXC6ir+eKI2MfHf29Mn8/n7wsKvDyKDovGoEFdJ1Ss8P39Xd7UVLqYaTgA2xJosKz6jZF/bx0Tmbxz0QGpTt61fJ/HORf4FGm4Vj+x31X5prqzPopLH6y/A4BKtoLitaWz0gtRNk/bMMnPcx0fXsBtUVQgQJvXWp/ek8GtJkIvfrc5gDXO44oh7gWoHR7wMVP8/8ePH5eVQtR1Op3W09PT+vvvv9fDw8O6ubn59MSRumcW9mMgi/cX+JJYV3a90VwtEVWeTKYMPAOCCvCqywgdfRP237lsMVlBZHV0bZrUnwWEjm71my/rcH/i+Wrl5HxBMfApm5+sNKrLQJ16t7DqrYGoku4qIJuH7Dtoa4codmzs/EVePmZ/TDoCYJG5RzCKoIABIYgDEjkm0XHN//X1db2+vn559BSfknLzFPNwuel83RQUuh+NYfDusMcuCKhzCqjdN6Srid6ZCNdiu1Ndk0DbEXfzqmPHWvUYdS8lsb6JL2R6KwLhyk3rWcvfF3G6OQ8/5ljV2W1TRd6ycyoAqfnr0ti/uW3V/HT2qhVBgLMibHhUVxeibJzDVSCuAirgDT147yAePY3HT/HN5njK6PHxcT09PX0KFLFCwSCEfaI2vVN9O/Hn8Y3m6kYLg4sbfOxEBiV1Y1HZwnoyR3U2sw5VVpVxv10aMoO1vj53r7biyAbS2bw1n5KpQ2H+bOMxF0wcm8Nyahz5aSY3bi7gu6DMbFHZir/Vaifq66w8mJVmeaox6ZKbKq8DZ9XeyIP6OrqrVYYilWyDI6rZuKg2xZEDWtQR8xTPqT2I+H2Dm5v/XmaK+wXx9NHr6+t6fn5ev3//Xs/Pz5f7AHE/gV9UY9srAjElnZu2uVCTxbGBynGysnxO6dvCHrvidHMAvJb+agVQgajT6c518lWBoRMk8VzXnq6tmbDvOICv6lflmKWqfN3PWIY+ZUOHJTu7OyuVLJ8q4wIDB6vOKqeyUa0YuK9dcFJ1deYrY5xLu7u7kzuh4jsG+Gg0BpZYNdzd3a2Hh4fLvYTHx8fLTqmxOypubdGVDk5ksunykWO1/PIGdySCPa44qvcSmGVXolihmwgZG1R61U3eLnvr2qx0s/4KELK0kOkmgZnuSZCs8nF/Vsxa5VH2KMDsBLvKN1SAQBu6vtUB1k6bXJnqspEjZ51Aj+8aVG3q2sNl4xKK81sGcj6XtQGDC7aFcQLPKdzCG9b4/gJeDvr4+Fin02mt9Z85+PT0tP78+bOenp4uKwy1txG2oxvgtsj46SO1OqieFKpEOUz8xiPbUtXnHFoxjGqyZYCsAs7UKZ0eVb4THLpMrZPHMeFsSZ/Z5tJUOQXu07apy0WT8h2ZtpnPqcsumd0Tdt/Nz/aosmGXSmM91epMkbepDmf/FDw7RMQFHbQz/vDeRAA6rxxjRRCXi1xQrvy3snUqu7+nEI9icYdl9x7W8teHGbArplJJtvx2d/Md66w6f8uliU5el39PvygdGTNV+dRkUOW7/cL1qeDXCQiT+lD3d5dx5ZWP72mnG9NumS2iiAOPmQJ4/iCNIp1ubyIU57sKiDkPk0/059Cx1vr0+H3Yxbbh46cYFPg9iJDz+XzB0Hg89fX1Vbal6gPMu2c8dweFLhvBzmVxwMJMXgGDYlqZjapuvBzW6UwX0JTwJOhEeUzvBISuHVn+auzwWI0LTq7JM9KsM7tMoC4vsB536SIbDyyndE7FBTO1SnWMcBrkWEfWXl6huCCi+lTZ63whs02Nj8IVPs+AzmmqHfg+A7cHdeNjpHipiL/Xwbudqm2rMW/W3/gNhcpHu2lbZLQhXsY0uoyeHc2Vma4QHIiyo2aTYtLRVTDsXprq1HFNFlfVyaICIIO3GsfMV6pzmV9Uk96VibZwWpankqreDEDjfOZze1Y83QDjbOv4PQsDXibZ5aIsnyMCkaYCBf/vynH9/GIikhz0UfZXJiwYaPCcIlF8n6Lr2+53la5k0xvNWJHqGAdmzhEcWHGkza6tucGvIi7Xw195y5zPtQn1fnx8pIy3kipP53wWKDNRTuv0d5wR/QL7nG3q2tftm2sxqEnd17BB3bzt2tANKFtWRRUh4nMVsLFuzMuAqQAXy7otyLEcgj2uHLjd/Abxx8fH5akjfHs63mGIOpgQhk34rkPcdH57e/v08ltsfRHvJrg+uka6k/FKwVWagbuTClCiXlV/pd+xlm65TkDIxDGW7sDtBTJXn9Lr+jjS3MpOMZtIV7rcdxQye/l8B4ScHrSrA1IZibi2ZDoZDK8lClS3luF+dT6R6UU9WFaJwoPJmCp7mXxGXgw0kYffWeC2xlGNHebnoMcf2clW1NnvrK8qGX9PgQWBoQvuEaE7AItskst0mCUOvgI8Zj2ZPY51OzC8BkNVNnVsrtqB5fGIeSKNH0HG8eBVkOqLyI9vmuK4ZCuRThs6ebuXErpSMewp2DrpsvLMtspHHZBnurM6OrYrmypR8xfLV4GzAtq1vl4yCp34BFF2PvSr+wdrff3uAdoWK4W4ma1exKzmercvMxm/vJYJTnR3xx8jYlYXdhouu7J6M9BXzIVt7gQEtTzlQVFl11oSWKs2sc2OySO7wDKuLjdJ3aTnelhPx1mZAXUc3kk25sp+1t9lYNeSLcDnGKhKc+y9qkP9zsqodjhfU4y40wdcTgEw+7sii1NhIhMbyrEdjAW4YsBLThww1KoEdeGHd5AMT2RvQFhr4xvNXekAbSdtqnePMNg4p5uyW+Ww/zYAXYMdsw5eQlf1KR9SfeKAZisTUgG2a7MLXhUrnZTp5M90dAMG5nerZyfVOFV17hEVINima9jQHSd81NWluS1XWBce8QkkzpfpuKbcfFx79A455JBDDvmflX37HBxyyCGHHPL/So6gcMghhxxyyEWOoHDIIYcccshFjqBwyCGHHHLIRY6gcMghhxxyyEWOoHDIIYcccshFjqBwyCGHHHLIRY6gcMghhxxyyEWOoHDIIYcccshF/g9cbXpgX3w7wwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "\n",
    "vit = model.load_vit_model()\n",
    "classification = original_classification[0]\n",
    "\n",
    "plot_image(classification.image_path)\n",
    "\n",
    "logits_path = classification.attribution_paths.logits\n",
    "logits = np.load(logits_path)\n",
    "print(f'logits = {logits}')\n",
    "\n",
    "pred = classification.prediction\n",
    "\n",
    "class_vector_predicted = vit.head.weight[pred.predicted_class_idx].detach().cpu().numpy()\n",
    "print(f'class vector of predicted = {class_vector_predicted.shape}')\n",
    "\n",
    "other_class_indices = [c for c in classes if c != pred.predicted_class_idx]\n",
    "class_vector_other1 = vit.head.weight[other_class_indices[0]].detach().cpu().numpy()\n",
    "class_vector_other2 = vit.head.weight[other_class_indices[1]].detach().cpu().numpy()\n",
    "\n",
    "# Calculate decision boundaries between classes\n",
    "direction1 = class_vector_predicted - class_vector_other1\n",
    "direction2 = class_vector_predicted - class_vector_other2\n",
    "direction3 = class_vector_predicted - 1.0*(class_vector_other1 + class_vector_other2)\n",
    "\n",
    "# Normalize the direction vectors\n",
    "norm_direction1 = direction1 / np.linalg.norm(direction1)\n",
    "norm_direction2 = direction2 / np.linalg.norm(direction2)\n",
    "norm_direction3 = direction3 / np.linalg.norm(direction3)\n",
    "\n",
    "# Initialize arrays to store results\n",
    "num_layers = 12\n",
    "num_heads = 12\n",
    "# Create individual arrays for each metric\n",
    "raw_dots1 = np.zeros((num_layers, num_heads))\n",
    "raw_dots2 = np.zeros((num_layers, num_heads))\n",
    "raw_dots3 = np.zeros((num_layers, num_heads))\n",
    "cos_sims1 = np.zeros((num_layers, num_heads))\n",
    "cos_sims2 = np.zeros((num_layers, num_heads))\n",
    "cos_sims3 = np.zeros((num_layers, num_heads))\n",
    "\n",
    "head_contributions_layers = np.load(classification.attribution_paths.head_contribution_path, allow_pickle=True)\n",
    "\n",
    "for i in range(num_layers):\n",
    "    head_contributions = head_contributions_layers[i]\n",
    "    print(f'--- Layer: {i}')\n",
    "    \n",
    "    for j in range(num_heads):\n",
    "        head_contribution = head_contributions[\"activity_data\"][j, :, :].squeeze(0)\n",
    "        \n",
    "        # Get CLS token and ensure it's 1D\n",
    "        cls_contribution = head_contribution[0]  # CLS token contribution\n",
    "        if cls_contribution.ndim > 1:\n",
    "            cls_contribution = cls_contribution.flatten()\n",
    "        \n",
    "        # Skip if contribution is all zeros\n",
    "        if np.all(cls_contribution == 0):\n",
    "            continue\n",
    "            \n",
    "        # Normalize the contribution vector\n",
    "        cls_norm = np.linalg.norm(cls_contribution)\n",
    "        norm_cls_contribution = cls_contribution / cls_norm if cls_norm > 0 else cls_contribution\n",
    "        \n",
    "        # Raw dot products (magnitude information)\n",
    "        raw_dot1 = float(np.dot(cls_contribution, direction1))  # Ensure scalar\n",
    "        raw_dot2 = float(np.dot(cls_contribution, direction2))\n",
    "        raw_dot3 = float(np.dot(cls_contribution, direction3))\n",
    "        \n",
    "        # Cosine similarities (angle information)\n",
    "        cos_sim1 = float(np.dot(norm_cls_contribution, norm_direction1))\n",
    "        cos_sim2 = float(np.dot(norm_cls_contribution, norm_direction2))\n",
    "        cos_sim3 = float(np.dot(norm_cls_contribution, norm_direction3))\n",
    "        \n",
    "        # Store results in separate arrays\n",
    "        raw_dots1[i, j] = raw_dot1\n",
    "        raw_dots2[i, j] = raw_dot2\n",
    "        raw_dots3[i, j] = raw_dot3\n",
    "        cos_sims1[i, j] = cos_sim1\n",
    "        cos_sims2[i, j] = cos_sim2\n",
    "        cos_sims3[i, j] = cos_sim3\n",
    "        \n",
    "        print(f'Head: {j}')\n",
    "        print(f'  Raw Dot 1: {raw_dot1:.4f} | Cosine Sim 1: {cos_sim1:.4f}')\n",
    "        print(f'  Raw Dot 2: {raw_dot2:.4f} | Cosine Sim 2: {cos_sim2:.4f}')\n",
    "        print(f'  Raw Dot 3: {raw_dot3:.4f} | Cosine Sim 3: {cos_sim3:.4f}')\n",
    "\n",
    "# Visualize the cosine similarities for the last two layers\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Focus on last two layers\n",
    "plot_layers = [8,9, 10, 11]\n",
    "metrics = ['Cosine Similarity with Direction 1', \n",
    "           'Cosine Similarity with Direction 2',\n",
    "           'Cosine Similarity with Direction 3']\n",
    "           \n",
    "cos_sims = [cos_sims1, cos_sims2, cos_sims3]\n",
    "\n",
    "for idx, cos_sim in enumerate(cos_sims):\n",
    "    plt.subplot(1, 3, idx+1)\n",
    "    data = np.zeros((len(plot_layers), num_heads))\n",
    "    \n",
    "    for i, layer in enumerate(plot_layers):\n",
    "        data[i] = cos_sim[layer, :]\n",
    "    \n",
    "    sns.heatmap(data, annot=True, fmt=\".2f\", cmap=\"RdBu_r\", center=0,\n",
    "                xticklabels=range(num_heads-1), \n",
    "                yticklabels=[f'Layer {i}' for i in plot_layers])\n",
    "    \n",
    "    plt.title(metrics[idx])\n",
    "    plt.xlabel('Head')\n",
    "    plt.ylabel('Layer')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1984ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading analysis data...\n",
      "Generating comprehensive visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17571/764232370.py:145: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_17571/764232370.py:361: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization descriptions saved to results/train/head_analysis/visualizations/visualization_descriptions.md\n",
      "All visualizations saved to results/train/head_analysis/visualizations\n",
      "\n",
      "Visualization generation complete!\n",
      "All visualizations saved to: results/train/head_analysis/visualizations\n",
      "Descriptions saved to: results/train/head_analysis/visualizations/visualization_descriptions.md\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Head Analysis Visualization Module\n",
    "Generates comprehensive visualizations for ViT head analysis research\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.cm import get_cmap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class HeadAnalysisVisualizer:\n",
    "    \"\"\"Comprehensive visualization suite for head analysis results.\"\"\"\n",
    "    \n",
    "    def __init__(self, save_dir: Path, class_names: Dict[int, str] = None):\n",
    "        \"\"\"\n",
    "        Initialize visualizer.\n",
    "        \n",
    "        Args:\n",
    "            save_dir: Directory to save visualizations\n",
    "            class_names: Mapping of class indices to names (default: {0: 'Covid', 1: 'Non-Covid', 2: 'Normal'})\n",
    "        \"\"\"\n",
    "        self.save_dir = save_dir\n",
    "        self.viz_dir = save_dir / \"visualizations\"\n",
    "        os.makedirs(self.viz_dir, exist_ok=True)\n",
    "        \n",
    "        self.class_names = class_names or {\n",
    "            0: 'Covid',\n",
    "            1: 'Non-Covid', \n",
    "            2: 'Normal'\n",
    "        }\n",
    "        self.class_colors = {\n",
    "            0: '#FF6B6B',  # Red for Covid\n",
    "            1: '#4ECDC4',  # Teal for Non-Covid\n",
    "            2: '#45B7D1'   # Blue for Normal\n",
    "        }\n",
    "        \n",
    "        # Set matplotlib style\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "        self.descriptions = {}\n",
    "        \n",
    "    def generate_all_visualizations(self, \n",
    "                                  direction_similarities: Dict,\n",
    "                                  head_importance: Dict,\n",
    "                                  token_patterns: Dict,\n",
    "                                  num_layers: int = 5,\n",
    "                                  start_layer: int = 7):\n",
    "        \"\"\"Generate all visualizations and descriptions.\"\"\"\n",
    "        \n",
    "        print(\"Generating comprehensive visualizations...\")\n",
    "        \n",
    "        # 1. Head Importance Heatmaps\n",
    "        self._visualize_head_importance(head_importance, num_layers, start_layer)\n",
    "        \n",
    "        # 2. Similarity Distribution Analysis\n",
    "        self._visualize_similarity_distributions(direction_similarities)\n",
    "        \n",
    "        # 3. Top Contributing Heads Comparison\n",
    "        self._visualize_top_heads_comparison(head_importance, start_layer)\n",
    "        \n",
    "        # 4. Token Pattern Analysis (PCA/Clustering)\n",
    "        self._visualize_token_patterns(token_patterns, start_layer)\n",
    "        \n",
    "        # 5. Class-wise Head Activation Patterns\n",
    "        self._visualize_class_activation_patterns(direction_similarities, num_layers)\n",
    "        \n",
    "        # 6. Statistical Summary Tables\n",
    "        self._generate_summary_tables(head_importance, token_patterns)\n",
    "        \n",
    "        # 7. Inter-class Head Specialization\n",
    "        self._visualize_head_specialization(head_importance, num_layers, start_layer)\n",
    "        \n",
    "        # 8. Layer-wise Importance Progression\n",
    "        self._visualize_layer_progression(head_importance, num_layers, start_layer)\n",
    "        \n",
    "        # Save descriptions\n",
    "        self._save_descriptions()\n",
    "        \n",
    "        print(f\"All visualizations saved to {self.viz_dir}\")\n",
    "        \n",
    "    def _visualize_head_importance(self, head_importance: Dict, num_layers: int, start_layer: int):\n",
    "        \"\"\"Create heatmaps showing head importance for each class.\"\"\"\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 8))\n",
    "        gs = gridspec.GridSpec(1, 3, figure=fig, wspace=0.3)\n",
    "        \n",
    "        importance_data = head_importance['class_head_importance']\n",
    "        \n",
    "        for class_idx in range(3):\n",
    "            ax = fig.add_subplot(gs[0, class_idx])\n",
    "            \n",
    "            # Create heatmap data\n",
    "            heatmap_data = importance_data[class_idx]\n",
    "            \n",
    "            # Create custom colormap\n",
    "            colors = ['white', self.class_colors[class_idx]]\n",
    "            n_bins = 100\n",
    "            cmap = sns.blend_palette(colors, as_cmap=True)\n",
    "            \n",
    "            # Plot heatmap\n",
    "            im = ax.imshow(heatmap_data, cmap=cmap, aspect='auto', vmin=0, vmax=1)\n",
    "            \n",
    "            # Customize axes\n",
    "            ax.set_xlabel('Head Index', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Layer', fontsize=12, fontweight='bold')\n",
    "            ax.set_title(f'{self.class_names[class_idx]} Head Importance', \n",
    "                        fontsize=14, fontweight='bold', pad=10)\n",
    "            \n",
    "            # Set ticks\n",
    "            ax.set_xticks(range(12))\n",
    "            ax.set_yticks(range(num_layers))\n",
    "            ax.set_yticklabels([f'L{start_layer + i}' for i in range(num_layers)])\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            cbar.set_label('Importance Score', fontsize=10)\n",
    "            \n",
    "            # Add grid\n",
    "            ax.set_xticks(np.arange(12) - 0.5, minor=True)\n",
    "            ax.set_yticks(np.arange(num_layers) - 0.5, minor=True)\n",
    "            ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "            \n",
    "            # Highlight most important heads\n",
    "            threshold = 0.5\n",
    "            for i in range(num_layers):\n",
    "                for j in range(12):\n",
    "                    if heatmap_data[i, j] > threshold:\n",
    "                        rect = Rectangle((j-0.45, i-0.45), 0.9, 0.9, \n",
    "                                       linewidth=2, edgecolor='black', \n",
    "                                       facecolor='none', linestyle='--')\n",
    "                        ax.add_patch(rect)\n",
    "        \n",
    "        plt.suptitle('Head Importance Analysis Across Classes', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'head_importance_heatmaps.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['head_importance_heatmaps'] = \"\"\"\n",
    "**Head Importance Heatmaps**\n",
    "\n",
    "These heatmaps visualize the importance of each attention head in the last 5 layers of the ViT model for each class prediction. The importance score (0-1) indicates how frequently a head contributes significantly to the class direction vector.\n",
    "\n",
    "Key insights:\n",
    "- Darker colors indicate heads that are more important for the respective class\n",
    "- Dashed boxes highlight heads with >50% importance score\n",
    "- Different classes show distinct patterns of head specialization\n",
    "- Later layers tend to show more class-specific specialization\n",
    "\n",
    "This visualization helps identify which attention heads are most critical for each class prediction, suggesting potential head pruning strategies or interpretation focal points.\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_similarity_distributions(self, direction_similarities: Dict):\n",
    "        \"\"\"Visualize distribution of similarity scores across classes.\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Collect similarities by class\n",
    "        class_similarities = {0: [], 1: [], 2: []}\n",
    "        all_similarities = []\n",
    "        \n",
    "        for img_data in direction_similarities.values():\n",
    "            class_idx = img_data['predicted_class']\n",
    "            similarities = img_data['similarities']['all'].flatten()\n",
    "            class_similarities[class_idx].extend(similarities)\n",
    "            all_similarities.extend(similarities)\n",
    "        \n",
    "        # Plot 1: Overall distribution\n",
    "        ax = axes[0]\n",
    "        ax.hist(all_similarities, bins=50, alpha=0.7, color='gray', edgecolor='black')\n",
    "        ax.axvline(np.mean(all_similarities), color='red', linestyle='--', \n",
    "                  label=f'Mean: {np.mean(all_similarities):.3f}')\n",
    "        ax.axvline(np.median(all_similarities), color='blue', linestyle='--', \n",
    "                  label=f'Median: {np.median(all_similarities):.3f}')\n",
    "        ax.set_xlabel('Cosine Similarity', fontsize=12)\n",
    "        ax.set_ylabel('Frequency', fontsize=12)\n",
    "        ax.set_title('Overall Similarity Distribution', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plots 2-4: Class-specific distributions\n",
    "        for idx, class_idx in enumerate([0, 1, 2]):\n",
    "            ax = axes[idx + 1]\n",
    "            similarities = class_similarities[class_idx]\n",
    "            \n",
    "            if similarities:\n",
    "                ax.hist(similarities, bins=50, alpha=0.7, \n",
    "                       color=self.class_colors[class_idx], edgecolor='black')\n",
    "                ax.axvline(np.mean(similarities), color='red', linestyle='--', \n",
    "                          label=f'Mean: {np.mean(similarities):.3f}')\n",
    "                ax.set_xlabel('Cosine Similarity', fontsize=12)\n",
    "                ax.set_ylabel('Frequency', fontsize=12)\n",
    "                ax.set_title(f'{self.class_names[class_idx]} Similarity Distribution', \n",
    "                           fontsize=14, fontweight='bold')\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Cosine Similarity Distributions by Class', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'similarity_distributions.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['similarity_distributions'] = \"\"\"\n",
    "**Similarity Distribution Analysis**\n",
    "\n",
    "These histograms show the distribution of cosine similarity scores between head outputs and class direction vectors. The analysis includes both overall distribution and class-specific breakdowns.\n",
    "\n",
    "Key observations:\n",
    "- The overall distribution shows the general alignment pattern across all classes\n",
    "- Class-specific distributions reveal unique activation patterns for each diagnosis\n",
    "- Mean and median lines indicate central tendencies\n",
    "- Distribution shape indicates consistency of head contributions\n",
    "\n",
    "This analysis helps understand:\n",
    "1. How consistently heads align with class directions\n",
    "2. Whether certain classes have more focused or dispersed attention patterns\n",
    "3. The threshold selection for determining \"important\" heads\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_top_heads_comparison(self, head_importance: Dict, start_layer: int):\n",
    "        \"\"\"Create comparative visualization of top contributing heads.\"\"\"\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Extract top heads for each class\n",
    "        top_heads_data = []\n",
    "        for class_idx in range(3):\n",
    "            ranked_heads = head_importance['class_ranked_heads'][class_idx][:10]\n",
    "            for rank, (layer, head, score) in enumerate(ranked_heads):\n",
    "                top_heads_data.append({\n",
    "                    'Class': self.class_names[class_idx],\n",
    "                    'Layer': start_layer + layer,\n",
    "                    'Head': head,\n",
    "                    'Score': score,\n",
    "                    'Rank': rank + 1,\n",
    "                    'Label': f'L{start_layer + layer}H{head}'\n",
    "                })\n",
    "        \n",
    "        # Create grouped bar plot\n",
    "        df = pd.DataFrame(top_heads_data)\n",
    "        \n",
    "        # Create position for each bar\n",
    "        class_positions = {name: i for i, name in enumerate(self.class_names.values())}\n",
    "        x_positions = []\n",
    "        colors = []\n",
    "        heights = []\n",
    "        labels = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            class_pos = class_positions[row['Class']]\n",
    "            x_pos = class_pos * 11 + row['Rank'] - 1\n",
    "            x_positions.append(x_pos)\n",
    "            colors.append(self.class_colors[list(self.class_names.values()).index(row['Class'])])\n",
    "            heights.append(row['Score'])\n",
    "            labels.append(row['Label'])\n",
    "        \n",
    "        bars = ax.bar(x_positions, heights, color=colors, alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, label in zip(bars, labels):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   label, ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Top 10 Heads per Class', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Top Contributing Heads Comparison Across Classes', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add class labels\n",
    "        for class_name, pos in class_positions.items():\n",
    "            ax.text(pos * 11 + 4.5, -0.05, class_name, ha='center', \n",
    "                   transform=ax.get_xaxis_transform(), fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Remove x-ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_ylim(0, max(heights) * 1.2)\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add legend\n",
    "        legend_elements = [plt.Rectangle((0,0),1,1, fc=self.class_colors[i], \n",
    "                                       label=self.class_names[i]) for i in range(3)]\n",
    "        ax.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'top_heads_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['top_heads_comparison'] = \"\"\"\n",
    "**Top Contributing Heads Comparison**\n",
    "\n",
    "This bar chart compares the top 10 most important attention heads for each class. Each bar represents a specific layer-head combination (e.g., L11H7 = Layer 11, Head 7) with its importance score.\n",
    "\n",
    "Key findings:\n",
    "- Each class relies on a distinct set of attention heads\n",
    "- Some heads may appear in multiple classes but with different importance levels\n",
    "- Later layers (L10-L11) tend to dominate the top positions\n",
    "- The importance scores indicate how consistently these heads contribute to correct predictions\n",
    "\n",
    "This comparison helps identify:\n",
    "1. Class-specific attention mechanisms\n",
    "2. Shared vs. unique processing pathways\n",
    "3. Potential targets for interpretability studies\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_token_patterns(self, token_patterns: Dict, start_layer: int):\n",
    "        \"\"\"Visualize token activation patterns using PCA/clustering results.\"\"\"\n",
    "        \n",
    "        # Create figure with subplots for each class\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        gs = gridspec.GridSpec(1, 3, figure=fig, wspace=0.3)\n",
    "        \n",
    "        for idx, (class_idx, patterns) in enumerate(token_patterns.items()):\n",
    "            ax = fig.add_subplot(gs[0, idx])\n",
    "            \n",
    "            # Plot PCA results with clusters\n",
    "            pca_result = patterns['pca_result']\n",
    "            cluster_labels = patterns['cluster_labels']\n",
    "            \n",
    "            # Create scatter plot\n",
    "            scatter = ax.scatter(pca_result[:, 0], pca_result[:, 1], \n",
    "                               c=cluster_labels, cmap='viridis', \n",
    "                               s=50, alpha=0.7, edgecolors='black')\n",
    "            \n",
    "            # Add cluster centers\n",
    "            for cluster_info in patterns['clusters']:\n",
    "                cluster_id = cluster_info['cluster_id']\n",
    "                cluster_points = pca_result[cluster_labels == cluster_id]\n",
    "                if len(cluster_points) > 0:\n",
    "                    center = cluster_points.mean(axis=0)\n",
    "                    ax.scatter(center[0], center[1], c='red', s=200, \n",
    "                             marker='*', edgecolors='black', linewidth=2,\n",
    "                             label=f'Cluster {cluster_id+1} center')\n",
    "            \n",
    "            ax.set_xlabel('PC1', fontsize=12)\n",
    "            ax.set_ylabel('PC2', fontsize=12)\n",
    "            ax.set_title(f'{self.class_names[class_idx]} Token Activation Patterns', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add variance explained\n",
    "            var_explained = sum(patterns['explained_variance'][:2])\n",
    "            ax.text(0.02, 0.98, f'Variance explained: {var_explained:.2%}',\n",
    "                   transform=ax.transAxes, va='top', fontsize=10,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Token Activation Pattern Clustering (PCA Visualization)', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'token_pattern_clustering.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Create detailed cluster analysis figure\n",
    "        self._visualize_cluster_details(token_patterns, start_layer)\n",
    "        \n",
    "        self.descriptions['token_pattern_clustering'] = \"\"\"\n",
    "**Token Activation Pattern Analysis**\n",
    "\n",
    "These visualizations show the results of PCA and k-means clustering applied to token activation patterns for each class. Each point represents an image, positioned based on its activation pattern similarity.\n",
    "\n",
    "Key insights:\n",
    "- Distinct clusters indicate different activation pattern \"modes\" within each class\n",
    "- Cluster centers (red stars) represent prototypical activation patterns\n",
    "- Variance explained shows how well 2D PCA captures the pattern diversity\n",
    "- Cluster separation indicates heterogeneity in processing strategies\n",
    "\n",
    "This analysis reveals:\n",
    "1. Whether images within a class are processed uniformly or through multiple pathways\n",
    "2. Potential sub-types within each diagnostic category\n",
    "3. The complexity of the learned representations\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_cluster_details(self, token_patterns: Dict, start_layer: int):\n",
    "        \"\"\"Create detailed visualization of cluster characteristics.\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "        \n",
    "        for class_idx, patterns in token_patterns.items():\n",
    "            row_axes = axes[class_idx]\n",
    "            \n",
    "            # Plot 1: Cluster sizes\n",
    "            ax = row_axes[0]\n",
    "            cluster_sizes = [c['size'] for c in patterns['clusters']]\n",
    "            cluster_names = [f'C{c[\"cluster_id\"]+1}' for c in patterns['clusters']]\n",
    "            bars = ax.bar(cluster_names, cluster_sizes, color=self.class_colors[class_idx], \n",
    "                          alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('Cluster', fontsize=10)\n",
    "            ax.set_ylabel('Number of Images', fontsize=10)\n",
    "            ax.set_title(f'{self.class_names[class_idx]} - Cluster Sizes', fontsize=12)\n",
    "            \n",
    "            # Add percentage labels\n",
    "            for bar, cluster in zip(bars, patterns['clusters']):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                       f'{cluster[\"percentage\"]*100:.1f}%', \n",
    "                       ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            # Plot 2: Top activations heatmap\n",
    "            ax = row_axes[1]\n",
    "            \n",
    "            # Create activation matrix for top tokens across clusters\n",
    "            n_clusters = len(patterns['clusters'])\n",
    "            n_top = 5  # Show top 5 activations per cluster\n",
    "            activation_matrix = np.zeros((n_clusters, n_top))\n",
    "            activation_labels = []\n",
    "            \n",
    "            for i, cluster in enumerate(patterns['clusters']):\n",
    "                top_acts = sorted(cluster['top_activations'], \n",
    "                                key=lambda x: x[3], reverse=True)[:n_top]\n",
    "                for j, (l, h, t, v) in enumerate(top_acts):\n",
    "                    activation_matrix[i, j] = v\n",
    "                    if i == 0:  # Only create labels once\n",
    "                        activation_labels.append(f'L{start_layer+l}H{h}T{t}')\n",
    "            \n",
    "            im = ax.imshow(activation_matrix, cmap='YlOrRd', aspect='auto')\n",
    "            ax.set_xticks(range(n_top))\n",
    "            ax.set_xticklabels(activation_labels, rotation=45, ha='right', fontsize=8)\n",
    "            ax.set_yticks(range(n_clusters))\n",
    "            ax.set_yticklabels([f'C{i+1}' for i in range(n_clusters)])\n",
    "            ax.set_xlabel('Top Activated Positions', fontsize=10)\n",
    "            ax.set_ylabel('Cluster', fontsize=10)\n",
    "            ax.set_title(f'{self.class_names[class_idx]} - Top Activations', fontsize=12)\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            cbar.ax.tick_params(labelsize=8)\n",
    "            \n",
    "            # Plot 3: PCA variance explained\n",
    "            ax = row_axes[2]\n",
    "            var_explained = patterns['explained_variance'][:10] * 100\n",
    "            ax.bar(range(1, len(var_explained)+1), var_explained, \n",
    "                  color=self.class_colors[class_idx], alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('Principal Component', fontsize=10)\n",
    "            ax.set_ylabel('Variance Explained (%)', fontsize=10)\n",
    "            ax.set_title(f'{self.class_names[class_idx]} - PCA Variance', fontsize=12)\n",
    "            ax.set_xticks(range(1, len(var_explained)+1))\n",
    "            \n",
    "            # Add cumulative line\n",
    "            cumsum = np.cumsum(var_explained)\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(range(1, len(var_explained)+1), cumsum, 'r-o', \n",
    "                    markersize=4, linewidth=2, label='Cumulative')\n",
    "            ax2.set_ylabel('Cumulative Variance (%)', fontsize=10, color='red')\n",
    "            ax2.tick_params(axis='y', labelcolor='red')\n",
    "            ax2.set_ylim(0, 100)\n",
    "        \n",
    "        plt.suptitle('Detailed Token Pattern Cluster Analysis', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'cluster_details.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['cluster_details'] = \"\"\"\n",
    "**Detailed Cluster Analysis**\n",
    "\n",
    "This multi-panel visualization provides in-depth analysis of the token activation clusters for each class:\n",
    "\n",
    "Left panels - Cluster Sizes:\n",
    "- Shows the distribution of images across clusters\n",
    "- Percentages indicate the prevalence of each activation pattern\n",
    "\n",
    "Middle panels - Top Activations:\n",
    "- Heatmaps show the strongest activated layer-head-token combinations per cluster\n",
    "- Darker colors indicate stronger activations\n",
    "- Labels show specific positions (e.g., L11H7T0 = Layer 11, Head 7, Token 0)\n",
    "\n",
    "Right panels - PCA Variance:\n",
    "- Bar charts show variance explained by each principal component\n",
    "- Red line shows cumulative variance\n",
    "- Indicates the dimensionality of the activation patterns\n",
    "\n",
    "This detailed view helps understand:\n",
    "1. The diversity of processing strategies within each class\n",
    "2. Which specific attention positions are most discriminative\n",
    "3. The complexity of the learned feature space\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_class_activation_patterns(self, direction_similarities: Dict, num_layers: int):\n",
    "        \"\"\"Visualize activation patterns across token positions.\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Aggregate activation patterns by class\n",
    "        for class_idx in range(3):\n",
    "            ax = axes[class_idx]\n",
    "            \n",
    "            # Collect all similarity matrices for this class\n",
    "            class_similarities = []\n",
    "            for img_data in direction_similarities.values():\n",
    "                if img_data['predicted_class'] == class_idx:\n",
    "                    # Average across layers and heads\n",
    "                    sim_matrix = img_data['similarities']['all']\n",
    "                    avg_by_token = np.mean(sim_matrix, axis=(0, 1))  # Average over layers and heads\n",
    "                    class_similarities.append(avg_by_token)\n",
    "            \n",
    "            if class_similarities:\n",
    "                # Calculate mean and std\n",
    "                similarities_array = np.array(class_similarities)\n",
    "                mean_pattern = np.mean(similarities_array, axis=0)\n",
    "                std_pattern = np.std(similarities_array, axis=0)\n",
    "                \n",
    "                # Limit to first 50 tokens for visibility\n",
    "                n_tokens = min(50, len(mean_pattern))\n",
    "                x = np.arange(n_tokens)\n",
    "                \n",
    "                # Plot with error bars\n",
    "                ax.bar(x, mean_pattern[:n_tokens], \n",
    "                      yerr=std_pattern[:n_tokens],\n",
    "                      color=self.class_colors[class_idx], \n",
    "                      alpha=0.7, edgecolor='black',\n",
    "                      error_kw={'elinewidth': 1, 'alpha': 0.5})\n",
    "                \n",
    "                # Highlight CLS token\n",
    "                ax.bar(0, mean_pattern[0], color='red', alpha=0.8, \n",
    "                      edgecolor='black', linewidth=2, label='CLS Token')\n",
    "                \n",
    "                ax.set_xlabel('Token Position', fontsize=12)\n",
    "                ax.set_ylabel('Mean Similarity Score', fontsize=12)\n",
    "                ax.set_title(f'{self.class_names[class_idx]} Token Activation Pattern', \n",
    "                           fontsize=14, fontweight='bold')\n",
    "                ax.legend()\n",
    "                ax.grid(True, axis='y', alpha=0.3)\n",
    "                \n",
    "                # Add annotation for top tokens\n",
    "                top_tokens = np.argsort(mean_pattern[:n_tokens])[-5:]\n",
    "                for token_idx in top_tokens:\n",
    "                    if token_idx != 0:  # Skip CLS token as it's already highlighted\n",
    "                        ax.annotate(f'T{token_idx}', \n",
    "                                  xy=(token_idx, mean_pattern[token_idx]),\n",
    "                                  xytext=(token_idx, mean_pattern[token_idx] + 0.05),\n",
    "                                  ha='center', fontsize=8)\n",
    "        \n",
    "        plt.suptitle('Average Token Activation Patterns by Class', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'token_activation_patterns.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['token_activation_patterns'] = \"\"\"\n",
    "**Token Activation Patterns**\n",
    "\n",
    "These bar charts show the average activation strength across token positions for each class. Error bars indicate standard deviation across images.\n",
    "\n",
    "Key observations:\n",
    "- CLS token (position 0, highlighted in red) typically shows strong activation\n",
    "- Different classes exhibit distinct spatial attention patterns\n",
    "- Some tokens consistently show high activation across images (annotated)\n",
    "- Variance (error bars) indicates consistency of the pattern\n",
    "\n",
    "This visualization reveals:\n",
    "1. How different classes attend to different spatial regions\n",
    "2. The importance of the CLS token for classification\n",
    "3. Whether certain image regions are consistently important for diagnosis\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_head_specialization(self, head_importance: Dict, num_layers: int, start_layer: int):\n",
    "        \"\"\"Visualize head specialization across classes.\"\"\"\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Calculate specialization scores\n",
    "        importance_data = head_importance['class_head_importance']\n",
    "        \n",
    "        # Reshape data for analysis\n",
    "        n_heads_total = num_layers * 12\n",
    "        head_scores = np.zeros((n_heads_total, 3))\n",
    "        \n",
    "        for class_idx in range(3):\n",
    "            class_importance = importance_data[class_idx].flatten()\n",
    "            head_scores[:, class_idx] = class_importance\n",
    "        \n",
    "        # Calculate specialization metrics\n",
    "        # 1. Entropy-based specialization (lower = more specialized)\n",
    "        epsilon = 1e-10\n",
    "        head_probs = head_scores / (head_scores.sum(axis=1, keepdims=True) + epsilon)\n",
    "        head_entropy = -np.sum(head_probs * np.log(head_probs + epsilon), axis=1)\n",
    "        \n",
    "        # 2. Max-class dominance\n",
    "        max_class_score = np.max(head_scores, axis=1)\n",
    "        dominant_class = np.argmax(head_scores, axis=1)\n",
    "        \n",
    "        # Plot 1: Specialization heatmap\n",
    "        specialization_matrix = 1 - (head_entropy / np.log(3))  # Normalize to [0,1]\n",
    "        specialization_matrix = specialization_matrix.reshape(num_layers, 12)\n",
    "        \n",
    "        im1 = ax1.imshow(specialization_matrix, cmap='RdYlBu', aspect='auto', vmin=0, vmax=1)\n",
    "        ax1.set_xlabel('Head Index', fontsize=12)\n",
    "        ax1.set_ylabel('Layer', fontsize=12)\n",
    "        ax1.set_title('Head Specialization Score\\n(Blue = Specialized, Red = General)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax1.set_yticks(range(num_layers))\n",
    "        ax1.set_yticklabels([f'L{start_layer + i}' for i in range(num_layers)])\n",
    "        ax1.set_xticks(range(12))\n",
    "        \n",
    "        cbar1 = plt.colorbar(im1, ax=ax1)\n",
    "        cbar1.set_label('Specialization Score', fontsize=10)\n",
    "        \n",
    "        # Plot 2: Class assignment\n",
    "        class_assignment = dominant_class.reshape(num_layers, 12)\n",
    "        \n",
    "        # Create custom colormap for classes\n",
    "        colors_list = [self.class_colors[i] for i in range(3)]\n",
    "        from matplotlib.colors import ListedColormap\n",
    "        cmap_classes = ListedColormap(colors_list)\n",
    "        \n",
    "        im2 = ax2.imshow(class_assignment, cmap=cmap_classes, aspect='auto', vmin=0, vmax=2)\n",
    "        ax2.set_xlabel('Head Index', fontsize=12)\n",
    "        ax2.set_ylabel('Layer', fontsize=12)\n",
    "        ax2.set_title('Dominant Class per Head', fontsize=14, fontweight='bold')\n",
    "        ax2.set_yticks(range(num_layers))\n",
    "        ax2.set_yticklabels([f'L{start_layer + i}' for i in range(num_layers)])\n",
    "        ax2.set_xticks(range(12))\n",
    "        \n",
    "        # Create discrete colorbar\n",
    "        cbar2 = plt.colorbar(im2, ax=ax2, ticks=[0, 1, 2])\n",
    "        cbar2.set_ticklabels([self.class_names[i] for i in range(3)])\n",
    "        \n",
    "        # Add significance markers for highly specialized heads\n",
    "        threshold = 0.7\n",
    "        for i in range(num_layers):\n",
    "            for j in range(12):\n",
    "                if specialization_matrix[i, j] > threshold:\n",
    "                    ax1.plot(j, i, 'k*', markersize=10)\n",
    "                    ax2.plot(j, i, 'k*', markersize=10)\n",
    "        \n",
    "        plt.suptitle('Head Specialization Analysis', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'head_specialization.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['head_specialization'] = \"\"\"\n",
    "**Head Specialization Analysis**\n",
    "\n",
    "This visualization analyzes how specialized each attention head is for specific classes:\n",
    "\n",
    "Left panel - Specialization Score:\n",
    "- Blue indicates heads specialized for one class\n",
    "- Red indicates heads that contribute equally to all classes\n",
    "- Stars mark highly specialized heads (>70% specialization)\n",
    "\n",
    "Right panel - Dominant Class:\n",
    "- Shows which class each head contributes to most strongly\n",
    "- Color coding matches the class colors (Red=Covid, Teal=Non-Covid, Blue=Normal)\n",
    "- Stars mark the same highly specialized heads\n",
    "\n",
    "Key insights:\n",
    "- Later layers tend to show more specialization\n",
    "- Some heads are class-agnostic (general feature extractors)\n",
    "- Highly specialized heads are prime candidates for interpretation\n",
    "- Class distribution reveals the model's internal organization\n",
    "\"\"\"\n",
    "\n",
    "    def _visualize_layer_progression(self, head_importance: Dict, num_layers: int, start_layer: int):\n",
    "        \"\"\"Visualize how importance progresses through layers.\"\"\"\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        importance_data = head_importance['class_head_importance']\n",
    "        \n",
    "        # Calculate layer-wise statistics\n",
    "        layer_importance = {class_idx: [] for class_idx in range(3)}\n",
    "        layer_diversity = []\n",
    "        \n",
    "        for layer in range(num_layers):\n",
    "            # Average importance per layer for each class\n",
    "            for class_idx in range(3):\n",
    "                avg_importance = np.mean(importance_data[class_idx][layer])\n",
    "                layer_importance[class_idx].append(avg_importance)\n",
    "            \n",
    "            # Calculate diversity (std across heads)\n",
    "            all_heads = []\n",
    "            for class_idx in range(3):\n",
    "                all_heads.extend(importance_data[class_idx][layer])\n",
    "            layer_diversity.append(np.std(all_heads))\n",
    "        \n",
    "        # Plot 1: Layer-wise importance progression\n",
    "        x = np.arange(num_layers)\n",
    "        width = 0.25\n",
    "        \n",
    "        for class_idx in range(3):\n",
    "            offset = (class_idx - 1) * width\n",
    "            bars = ax1.bar(x + offset, layer_importance[class_idx], width,\n",
    "                          label=self.class_names[class_idx],\n",
    "                          color=self.class_colors[class_idx],\n",
    "                          alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        ax1.set_xlabel('Layer', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Average Head Importance', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title('Layer-wise Importance Progression', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels([f'L{start_layer + i}' for i in range(num_layers)])\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, axis='y', alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Cumulative importance and diversity\n",
    "        ax2_twin = ax2.twinx()\n",
    "        \n",
    "        # Cumulative importance\n",
    "        cumulative_importance = {}\n",
    "        for class_idx in range(3):\n",
    "            cumulative = np.cumsum(layer_importance[class_idx])\n",
    "            ax2.plot(x, cumulative, 'o-', color=self.class_colors[class_idx],\n",
    "                    linewidth=2, markersize=8, label=self.class_names[class_idx])\n",
    "        \n",
    "        # Diversity\n",
    "        ax2_twin.plot(x, layer_diversity, 's--', color='purple', \n",
    "                     linewidth=2, markersize=8, label='Head Diversity')\n",
    "        \n",
    "        ax2.set_xlabel('Layer', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('Cumulative Importance', fontsize=12, fontweight='bold')\n",
    "        ax2_twin.set_ylabel('Head Diversity (Std)', fontsize=12, fontweight='bold', color='purple')\n",
    "        ax2.set_title('Cumulative Importance and Head Diversity', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels([f'L{start_layer + i}' for i in range(num_layers)])\n",
    "        ax2_twin.tick_params(axis='y', labelcolor='purple')\n",
    "        \n",
    "        # Combine legends\n",
    "        lines1, labels1 = ax2.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2_twin.get_legend_handles_labels()\n",
    "        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Layer-wise Analysis of Head Contributions', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'layer_progression.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['layer_progression'] = \"\"\"\n",
    "**Layer-wise Progression Analysis**\n",
    "\n",
    "This analysis shows how attention head importance evolves through the network layers:\n",
    "\n",
    "Left panel - Average Importance by Layer:\n",
    "- Bar heights show the mean importance of all heads in each layer\n",
    "- Different colors represent different classes\n",
    "- Higher values indicate layers with more discriminative heads\n",
    "\n",
    "Right panel - Cumulative Importance and Diversity:\n",
    "- Solid lines show cumulative importance (increasing = more heads contribute)\n",
    "- Dashed purple line shows head diversity (variation in importance scores)\n",
    "- Higher diversity indicates more specialized heads within a layer\n",
    "\n",
    "Key findings:\n",
    "- Later layers generally show higher importance for classification\n",
    "- Diversity patterns reveal where specialization occurs\n",
    "- Class-specific patterns emerge more strongly in final layers\n",
    "- The progression indicates hierarchical feature learning\n",
    "\"\"\"\n",
    "\n",
    "    def _generate_summary_tables(self, head_importance: Dict, token_patterns: Dict):\n",
    "        \"\"\"Generate summary tables for key findings.\"\"\"\n",
    "        \n",
    "        # Create figure for tables\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        fig.suptitle('Statistical Summary Tables', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Table 1: Top heads per class\n",
    "        ax1 = plt.subplot(2, 2, 1)\n",
    "        ax1.axis('tight')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        table_data = []\n",
    "        for class_idx in range(3):\n",
    "            top_heads = head_importance['class_ranked_heads'][class_idx][:5]\n",
    "            for rank, (layer, head, score) in enumerate(top_heads, 1):\n",
    "                table_data.append([\n",
    "                    self.class_names[class_idx],\n",
    "                    rank,\n",
    "                    f'L{layer + 7}H{head}',\n",
    "                    f'{score:.3f}',\n",
    "                    f'{score*100:.1f}%'\n",
    "                ])\n",
    "        \n",
    "        table1 = ax1.table(cellText=table_data,\n",
    "                          colLabels=['Class', 'Rank', 'Head', 'Score', 'Importance %'],\n",
    "                          cellLoc='center',\n",
    "                          loc='center',\n",
    "                          bbox=[0, 0, 1, 1])\n",
    "        table1.auto_set_font_size(False)\n",
    "        table1.set_fontsize(9)\n",
    "        table1.scale(1.2, 1.5)\n",
    "        ax1.set_title('Top 5 Important Heads per Class', fontsize=12, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Table 2: Class statistics\n",
    "        ax2 = plt.subplot(2, 2, 2)\n",
    "        ax2.axis('tight')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        stats_data = []\n",
    "        for class_idx in range(3):\n",
    "            n_images = head_importance['class_image_counts'][class_idx]\n",
    "            importance_scores = head_importance['class_head_importance'][class_idx].flatten()\n",
    "            stats_data.append([\n",
    "                self.class_names[class_idx],\n",
    "                n_images,\n",
    "                f'{np.mean(importance_scores):.3f}',\n",
    "                f'{np.std(importance_scores):.3f}',\n",
    "                f'{np.sum(importance_scores > 0.5)}'\n",
    "            ])\n",
    "        \n",
    "        table2 = ax2.table(cellText=stats_data,\n",
    "                          colLabels=['Class', 'Images', 'Mean Import.', 'Std Import.', 'High Import. Heads'],\n",
    "                          cellLoc='center',\n",
    "                          loc='center',\n",
    "                          bbox=[0, 0, 1, 1])\n",
    "        table2.auto_set_font_size(False)\n",
    "        table2.set_fontsize(9)\n",
    "        table2.scale(1.2, 1.5)\n",
    "        ax2.set_title('Class-wise Statistics', fontsize=12, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Table 3: Token pattern clusters\n",
    "        ax3 = plt.subplot(2, 2, 3)\n",
    "        ax3.axis('tight')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        cluster_data = []\n",
    "        for class_idx, patterns in token_patterns.items():\n",
    "            for cluster in patterns['clusters']:\n",
    "                cluster_data.append([\n",
    "                    self.class_names[class_idx],\n",
    "                    f\"Cluster {cluster['cluster_id']+1}\",\n",
    "                    cluster['size'],\n",
    "                    f\"{cluster['percentage']*100:.1f}%\",\n",
    "                    len(cluster['top_activations'])\n",
    "                ])\n",
    "        \n",
    "        table3 = ax3.table(cellText=cluster_data,\n",
    "                          colLabels=['Class', 'Cluster', 'Size', 'Percentage', 'Key Activations'],\n",
    "                          cellLoc='center',\n",
    "                          loc='center',\n",
    "                          bbox=[0, 0, 1, 1])\n",
    "        table3.auto_set_font_size(False)\n",
    "        table3.set_fontsize(9)\n",
    "        table3.scale(1.2, 1.5)\n",
    "        ax3.set_title('Token Pattern Cluster Summary', fontsize=12, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Table 4: Similarity statistics\n",
    "        ax4 = plt.subplot(2, 2, 4)\n",
    "        ax4.axis('tight')\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        sim_stats = head_importance['similarity_stats']\n",
    "        stats_rows = [\n",
    "            ['Mean', f\"{sim_stats['mean']:.4f}\"],\n",
    "            ['Median', f\"{sim_stats['median']:.4f}\"],\n",
    "            ['Std Dev', f\"{sim_stats['std']:.4f}\"],\n",
    "            ['Min', f\"{sim_stats['min']:.4f}\"],\n",
    "            ['Max', f\"{sim_stats['max']:.4f}\"],\n",
    "            ['25th Percentile', f\"{sim_stats['percentiles']['25']:.4f}\"],\n",
    "            ['75th Percentile', f\"{sim_stats['percentiles']['75']:.4f}\"],\n",
    "            ['90th Percentile', f\"{sim_stats['percentiles']['90']:.4f}\"]\n",
    "        ]\n",
    "        \n",
    "        table4 = ax4.table(cellText=stats_rows,\n",
    "                          colLabels=['Metric', 'Value'],\n",
    "                          cellLoc='center',\n",
    "                          loc='center',\n",
    "                          bbox=[0, 0, 1, 1])\n",
    "        table4.auto_set_font_size(False)\n",
    "        table4.set_fontsize(9)\n",
    "        table4.scale(1.2, 1.5)\n",
    "        ax4.set_title('Similarity Score Statistics', fontsize=12, fontweight='bold', pad=20)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.viz_dir / 'summary_tables.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.descriptions['summary_tables'] = \"\"\"\n",
    "**Statistical Summary Tables**\n",
    "\n",
    "These tables provide quantitative summaries of the analysis:\n",
    "\n",
    "Table 1 - Top Important Heads:\n",
    "- Lists the 5 most important heads for each class\n",
    "- Shows both raw scores and percentage importance\n",
    "- Reveals which specific heads drive each classification\n",
    "\n",
    "Table 2 - Class Statistics:\n",
    "- Number of images analyzed per class\n",
    "- Mean and standard deviation of importance scores\n",
    "- Count of highly important heads (>50% importance)\n",
    "\n",
    "Table 3 - Token Pattern Clusters:\n",
    "- Summary of clustering results for each class\n",
    "- Shows cluster sizes and percentages\n",
    "- Indicates the number of key activation positions\n",
    "\n",
    "Table 4 - Similarity Statistics:\n",
    "- Overall distribution metrics for cosine similarities\n",
    "- Helps understand the range and central tendency\n",
    "- Guides threshold selection for importance determination\n",
    "\n",
    "These tables provide quick reference for key quantitative findings.\n",
    "\"\"\"\n",
    "\n",
    "    def _save_descriptions(self):\n",
    "        \"\"\"Save all descriptions to a markdown file.\"\"\"\n",
    "        \n",
    "        with open(self.viz_dir / 'visualization_descriptions.md', 'w') as f:\n",
    "            f.write(\"# Head Analysis Visualization Descriptions\\n\\n\")\n",
    "            f.write(\"This document provides detailed descriptions of all generated visualizations.\\n\\n\")\n",
    "            \n",
    "            for viz_name, description in self.descriptions.items():\n",
    "                f.write(f\"## {viz_name.replace('_', ' ').title()}\\n\\n\")\n",
    "                f.write(description)\n",
    "                f.write(\"\\n\\n---\\n\\n\")\n",
    "        \n",
    "        print(f\"Visualization descriptions saved to {self.viz_dir / 'visualization_descriptions.md'}\")\n",
    "\n",
    "\n",
    "def create_comprehensive_visualizations(data_dir: Path):\n",
    "    \"\"\"\n",
    "    Main function to load data and create all visualizations.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the analysis output files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the analysis results\n",
    "    print(\"Loading analysis data...\")\n",
    "    \n",
    "    # Load head direction similarities\n",
    "    similarities_path = data_dir / \"head_direction_similarities.npy\"\n",
    "    direction_similarities = np.load(similarities_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Load head importance analysis\n",
    "    importance_path = data_dir / \"head_importance_analysis.npy\"\n",
    "    head_importance = np.load(importance_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Load token patterns for each class\n",
    "    token_patterns = {}\n",
    "    for class_idx in range(3):\n",
    "        pattern_path = data_dir / f\"token_patterns_class_{class_idx}.npy\"\n",
    "        if pattern_path.exists():\n",
    "            token_patterns[class_idx] = np.load(pattern_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Create visualizer and generate all visualizations\n",
    "    visualizer = HeadAnalysisVisualizer(data_dir)\n",
    "    visualizer.generate_all_visualizations(\n",
    "        direction_similarities,\n",
    "        head_importance,\n",
    "        token_patterns,\n",
    "        num_layers=5,\n",
    "        start_layer=7\n",
    "    )\n",
    "    \n",
    "    print(\"\\nVisualization generation complete!\")\n",
    "    print(f\"All visualizations saved to: {data_dir / 'visualizations'}\")\n",
    "    print(f\"Descriptions saved to: {data_dir / 'visualizations' / 'visualization_descriptions.md'}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual data directory\n",
    "    data_directory = Path(\"./results/train/head_analysis\")\n",
    "    create_comprehensive_visualizations(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a897f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/test/head_analysis/figures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 893\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📄 Summary report: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis_summary.md\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 883\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    880\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigures\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;66;03m# Create visualizer and generate all plots\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m \u001b[43mHeadAnalysisVisualizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m visualizer\u001b[38;5;241m.\u001b[39mgenerate_all_visualizations()\n\u001b[1;32m    885\u001b[0m visualizer\u001b[38;5;241m.\u001b[39mgenerate_summary_report()\n",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m, in \u001b[0;36mHeadAnalysisVisualizer.__init__\u001b[0;34m(self, data_dir, output_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m=\u001b[39m Path(data_dir)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigures\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Load all data\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1175\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/test/head_analysis/figures'"
     ]
    }
   ],
   "source": [
    "import head_analysis\n",
    "\n",
    "least_important = head_analysis.analyze_class_specific_head_importance(\n",
    "    direction_similarities, num_classes, num_heads, num_layers,\n",
    "    importance_threshold=0.2,  # Lower threshold for \"unimportant\"\n",
    "    find_least_important=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fd5ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results...\n",
      "Found 5 weighted result files\n",
      "Boost factors: [1.5, 2.5, 3.5, 4.5, 5.5]\n",
      "Calculating improvements...\n",
      "Found estimators: ['FaithfulnessCorrelation', 'Sufficiency']\n",
      "Creating overall plots...\n",
      "Creating class-wise plots...\n",
      "Generating summary report...\n",
      "All visualizations saved to ./visualization_output/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "def load_all_results(weighted_dir: str, baseline_path: str) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Load all weighted results and baseline results.\"\"\"\n",
    "    # Load baseline\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline = json.load(f)\n",
    "    \n",
    "    # Load all weighted results\n",
    "    weighted_files = glob.glob(f\"{weighted_dir}/faithfulness_stats_*.json\")\n",
    "    weighted_results = {}\n",
    "    \n",
    "    for file_path in weighted_files:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            boost_factor = data.get('boost_factor_per_head', 0)\n",
    "            if boost_factor > 0:  # Only include files with boost factors\n",
    "                weighted_results[boost_factor] = data\n",
    "    \n",
    "    return weighted_results, baseline\n",
    "\n",
    "def calculate_improvements(weighted_results: Dict, baseline: Dict) -> Dict:\n",
    "    \"\"\"Calculate improvement percentages for each boost factor.\"\"\"\n",
    "    baseline_metrics = baseline.get('metrics', {})\n",
    "    improvements = {}\n",
    "    \n",
    "    for boost_factor, weighted_data in weighted_results.items():\n",
    "        weighted_metrics = weighted_data.get('metrics', {})\n",
    "        improvements[boost_factor] = {}\n",
    "        \n",
    "        for estimator_name in weighted_metrics.keys():\n",
    "            if estimator_name in baseline_metrics:\n",
    "                improvements[boost_factor][estimator_name] = {\n",
    "                    'overall': {},\n",
    "                    'by_class': {}\n",
    "                }\n",
    "                \n",
    "                # Overall improvements\n",
    "                w_overall = weighted_metrics[estimator_name]['overall']\n",
    "                b_overall = baseline_metrics[estimator_name]['overall']\n",
    "                \n",
    "                for metric in ['mean', 'median']:\n",
    "                    if metric in w_overall and metric in b_overall:\n",
    "                        w_val = w_overall[metric]\n",
    "                        b_val = b_overall[metric]\n",
    "                        improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "                        improvements[boost_factor][estimator_name]['overall'][metric] = improvement\n",
    "                \n",
    "                # Per-class improvements\n",
    "                w_classes = weighted_metrics[estimator_name].get('by_class', {})\n",
    "                b_classes = baseline_metrics[estimator_name].get('by_class', {})\n",
    "                \n",
    "                for class_id in w_classes.keys():\n",
    "                    if class_id in b_classes:\n",
    "                        improvements[boost_factor][estimator_name]['by_class'][class_id] = {}\n",
    "                        \n",
    "                        for metric in ['mean', 'median']:\n",
    "                            if metric in w_classes[class_id] and metric in b_classes[class_id]:\n",
    "                                w_val = w_classes[class_id][metric]\n",
    "                                b_val = b_classes[class_id][metric]\n",
    "                                improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "                                improvements[boost_factor][estimator_name]['by_class'][class_id][metric] = improvement\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "def create_overall_plots(improvements: Dict, output_dir: str):\n",
    "    \"\"\"Create overall improvement plots.\"\"\"\n",
    "    # Set matplotlib style for LaTeX\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.figsize': (10, 6)\n",
    "    })\n",
    "    \n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Mean improvements\n",
    "        mean_improvements = [improvements[bf][estimator]['overall']['mean'] \n",
    "                           for bf in boost_factors]\n",
    "        ax1.plot(boost_factors, mean_improvements, 'o-', linewidth=2, markersize=6)\n",
    "        ax1.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax1.set_xlabel('Boost Factor')\n",
    "        ax1.set_ylabel('Mean Improvement (%)')\n",
    "        ax1.set_title(f'{estimator} - Mean Performance')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Median improvements\n",
    "        median_improvements = [improvements[bf][estimator]['overall']['median'] \n",
    "                             for bf in boost_factors]\n",
    "        ax2.plot(boost_factors, median_improvements, 'o-', linewidth=2, markersize=6, color='orange')\n",
    "        ax2.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax2.set_xlabel('Boost Factor')\n",
    "        ax2.set_ylabel('Median Improvement (%)')\n",
    "        ax2.set_title(f'{estimator} - Median Performance')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/{estimator}_overall_improvements.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def create_class_plots(improvements: Dict, output_dir: str):\n",
    "    \"\"\"Create per-class improvement plots.\"\"\"\n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        # Get all classes\n",
    "        all_classes = set()\n",
    "        for bf_data in improvements.values():\n",
    "            all_classes.update(bf_data[estimator]['by_class'].keys())\n",
    "        all_classes = sorted(all_classes)\n",
    "        \n",
    "        # Create subplots for each metric\n",
    "        for metric in ['mean', 'median']:\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            \n",
    "            colors = plt.cm.Set1(np.linspace(0, 1, len(all_classes)))\n",
    "            \n",
    "            for i, class_id in enumerate(all_classes):\n",
    "                class_improvements = []\n",
    "                for bf in boost_factors:\n",
    "                    if class_id in improvements[bf][estimator]['by_class']:\n",
    "                        improvement = improvements[bf][estimator]['by_class'][class_id].get(metric, 0)\n",
    "                        class_improvements.append(improvement)\n",
    "                    else:\n",
    "                        class_improvements.append(0)\n",
    "                \n",
    "                ax.plot(boost_factors, class_improvements, 'o-', \n",
    "                       label=f'Class {class_id}', color=colors[i], linewidth=2, markersize=5)\n",
    "            \n",
    "            ax.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "            ax.set_xlabel('Boost Factor')\n",
    "            ax.set_ylabel(f'{metric.title()} Improvement (%)')\n",
    "            ax.set_title(f'{estimator} - {metric.title()} Performance by Class')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/{estimator}_class_{metric}_improvements.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "def generate_summary_report(improvements: Dict, output_dir: str):\n",
    "    \"\"\"Generate a summary report with key findings.\"\"\"\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"# Faithfulness Metrics Analysis Report\\n\")\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        report.append(f\"## {estimator}\\n\")\n",
    "        \n",
    "        # Find best performing boost factor\n",
    "        mean_improvements = {bf: improvements[bf][estimator]['overall']['mean'] \n",
    "                           for bf in boost_factors}\n",
    "        median_improvements = {bf: improvements[bf][estimator]['overall']['median'] \n",
    "                             for bf in boost_factors}\n",
    "        \n",
    "        best_mean_bf = max(mean_improvements, key=mean_improvements.get)\n",
    "        best_median_bf = max(median_improvements, key=median_improvements.get)\n",
    "        \n",
    "        report.append(f\"**Overall Performance:**\")\n",
    "        report.append(f\"- Best mean improvement: {mean_improvements[best_mean_bf]:.2f}% at boost factor {best_mean_bf}\")\n",
    "        report.append(f\"- Best median improvement: {median_improvements[best_median_bf]:.2f}% at boost factor {best_median_bf}\")\n",
    "        \n",
    "        # Class-wise summary\n",
    "        report.append(f\"\\n**Per-Class Performance:**\")\n",
    "        all_classes = set()\n",
    "        for bf_data in improvements.values():\n",
    "            all_classes.update(bf_data[estimator]['by_class'].keys())\n",
    "        \n",
    "        for class_id in sorted(all_classes):\n",
    "            class_mean_improvements = {}\n",
    "            for bf in boost_factors:\n",
    "                if class_id in improvements[bf][estimator]['by_class']:\n",
    "                    class_mean_improvements[bf] = improvements[bf][estimator]['by_class'][class_id].get('mean', 0)\n",
    "            \n",
    "            if class_mean_improvements:\n",
    "                best_class_bf = max(class_mean_improvements, key=class_mean_improvements.get)\n",
    "                report.append(f\"- Class {class_id}: Best improvement {class_mean_improvements[best_class_bf]:.2f}% at boost factor {best_class_bf}\")\n",
    "        \n",
    "        report.append(\"\")\n",
    "    \n",
    "    # Save report\n",
    "    with open(f'{output_dir}/analysis_report.md', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    weighted_dir = \"./results/train_weighted\"\n",
    "    baseline_path = \"./results/train/faithfulness_stats_2025-05-26_19-25.json\"\n",
    "    output_dir = \"./visualization_output\"\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading results...\")\n",
    "    weighted_results, baseline = load_all_results(weighted_dir, baseline_path)\n",
    "    \n",
    "    print(f\"Found {len(weighted_results)} weighted result files\")\n",
    "    print(f\"Boost factors: {sorted(weighted_results.keys())}\")\n",
    "    \n",
    "    # Calculate improvements\n",
    "    print(\"Calculating improvements...\")\n",
    "    improvements = calculate_improvements(weighted_results, baseline)\n",
    "    \n",
    "    # Show which estimators were found\n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    print(f\"Found estimators: {estimators}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"Creating overall plots...\")\n",
    "    create_overall_plots(improvements, output_dir)\n",
    "    \n",
    "    print(\"Creating class-wise plots...\")\n",
    "    create_class_plots(improvements, output_dir)\n",
    "    \n",
    "    print(\"Generating summary report...\")\n",
    "    generate_summary_report(improvements, output_dir)\n",
    "    \n",
    "    print(f\"All visualizations saved to {output_dir}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "702f2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SaCo results...\n",
      "Loaded boost factor 1.5: 3000 samples\n",
      "Loaded boost factor 2.5: 3000 samples\n",
      "Loaded boost factor 3.5: 3000 samples\n",
      "Loaded boost factor 4.5: 3000 samples\n",
      "Loaded boost factor 5.5: 3000 samples\n",
      "Found 5 weighted result files\n",
      "Boost factors: [1.5, 2.5, 3.5, 4.5, 5.5]\n",
      "Baseline samples: 3000\n",
      "Calculating SaCo improvements...\n",
      "Creating SaCo overall plots...\n",
      "Creating SaCo class-wise plots...\n",
      "Generating SaCo summary report...\n",
      "All SaCo visualizations saved to ./visualization_output/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def load_saco_results(weighted_dir: str, baseline_path: str) -> Tuple[Dict, pd.DataFrame]:\n",
    "    \"\"\"Load all SaCo CSV files and baseline.\"\"\"\n",
    "    # Load baseline\n",
    "    baseline_df = pd.read_csv(baseline_path)\n",
    "    \n",
    "    # Define boost factors in chronological order\n",
    "    boost_factors = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "    \n",
    "    # Expected file patterns (in chronological order)\n",
    "    file_patterns = [\n",
    "        \"analysis_faithfulness_correctness_2025-05-26_19-55.csv\",  # 1.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-26_20-34.csv\",  # 2.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-26_21-18.csv\",  # 3.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-26_21-54.csv\",  # 4.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-26_22-32.csv\"   # 5.5\n",
    "    ]\n",
    "    \n",
    "    weighted_results = {}\n",
    "    for i, pattern in enumerate(file_patterns):\n",
    "        file_path = f\"{weighted_dir}/{pattern}\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            boost_factor = boost_factors[i]\n",
    "            weighted_results[boost_factor] = df\n",
    "            print(f\"Loaded boost factor {boost_factor}: {len(df)} samples\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {file_path} not found\")\n",
    "    \n",
    "    return weighted_results, baseline_df\n",
    "\n",
    "def calculate_saco_metrics(df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate overall and per-class SaCo metrics.\"\"\"\n",
    "    results = {\n",
    "        'overall': {\n",
    "            'mean': df['saco_score'].mean(),\n",
    "            'median': df['saco_score'].median(),\n",
    "            'count': len(df)\n",
    "        },\n",
    "        'by_class': {}\n",
    "    }\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for class_name in df['true_class'].unique():\n",
    "        class_data = df[df['true_class'] == class_name]\n",
    "        results['by_class'][class_name] = {\n",
    "            'mean': class_data['saco_score'].mean(),\n",
    "            'median': class_data['saco_score'].median(),\n",
    "            'count': len(class_data)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_saco_improvements(weighted_results: Dict, baseline_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate improvement percentages for SaCo scores.\"\"\"\n",
    "    baseline_metrics = calculate_saco_metrics(baseline_df)\n",
    "    improvements = {}\n",
    "    \n",
    "    for boost_factor, weighted_df in weighted_results.items():\n",
    "        weighted_metrics = calculate_saco_metrics(weighted_df)\n",
    "        improvements[boost_factor] = {\n",
    "            'overall': {},\n",
    "            'by_class': {}\n",
    "        }\n",
    "        \n",
    "        # Overall improvements\n",
    "        for metric in ['mean', 'median']:\n",
    "            w_val = weighted_metrics['overall'][metric]\n",
    "            b_val = baseline_metrics['overall'][metric]\n",
    "            improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "            improvements[boost_factor]['overall'][metric] = improvement\n",
    "        \n",
    "        # Per-class improvements\n",
    "        for class_name in weighted_metrics['by_class'].keys():\n",
    "            if class_name in baseline_metrics['by_class']:\n",
    "                improvements[boost_factor]['by_class'][class_name] = {}\n",
    "                \n",
    "                for metric in ['mean', 'median']:\n",
    "                    w_val = weighted_metrics['by_class'][class_name][metric]\n",
    "                    b_val = baseline_metrics['by_class'][class_name][metric]\n",
    "                    improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "                    improvements[boost_factor]['by_class'][class_name][metric] = improvement\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "def create_saco_overall_plots(improvements: Dict, output_dir: str):\n",
    "    \"\"\"Create overall SaCo improvement plots.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.figsize': (10, 6)\n",
    "    })\n",
    "    \n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Mean improvements\n",
    "    mean_improvements = [improvements[bf]['overall']['mean'] for bf in boost_factors]\n",
    "    ax1.plot(boost_factors, mean_improvements, 'o-', linewidth=2, markersize=6, color='green')\n",
    "    ax1.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "    ax1.set_xlabel('Boost Factor')\n",
    "    ax1.set_ylabel('Mean Improvement (%)')\n",
    "    ax1.set_title('SaCo Scores - Mean Performance')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Median improvements\n",
    "    median_improvements = [improvements[bf]['overall']['median'] for bf in boost_factors]\n",
    "    ax2.plot(boost_factors, median_improvements, 'o-', linewidth=2, markersize=6, color='purple')\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "    ax2.set_xlabel('Boost Factor')\n",
    "    ax2.set_ylabel('Median Improvement (%)')\n",
    "    ax2.set_title('SaCo Scores - Median Performance')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/SaCo_overall_improvements.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_saco_class_plots(improvements: Dict, output_dir: str):\n",
    "    \"\"\"Create per-class SaCo improvement plots.\"\"\"\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    # Get all classes\n",
    "    all_classes = set()\n",
    "    for bf_data in improvements.values():\n",
    "        all_classes.update(bf_data['by_class'].keys())\n",
    "    all_classes = sorted(all_classes)\n",
    "    \n",
    "    # Create subplots for each metric\n",
    "    for metric in ['mean', 'median']:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, len(all_classes)))\n",
    "        \n",
    "        for i, class_name in enumerate(all_classes):\n",
    "            class_improvements = []\n",
    "            for bf in boost_factors:\n",
    "                if class_name in improvements[bf]['by_class']:\n",
    "                    improvement = improvements[bf]['by_class'][class_name].get(metric, 0)\n",
    "                    class_improvements.append(improvement)\n",
    "                else:\n",
    "                    class_improvements.append(0)\n",
    "            \n",
    "            ax.plot(boost_factors, class_improvements, 'o-', \n",
    "                   label=f'{class_name}', color=colors[i], linewidth=2, markersize=5)\n",
    "        \n",
    "        ax.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax.set_xlabel('Boost Factor')\n",
    "        ax.set_ylabel(f'{metric.title()} Improvement (%)')\n",
    "        ax.set_title(f'SaCo Scores - {metric.title()} Performance by Class')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/SaCo_class_{metric}_improvements.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def generate_saco_summary_report(improvements: Dict, weighted_results: Dict, \n",
    "                                baseline_df: pd.DataFrame, output_dir: str):\n",
    "    \"\"\"Generate a summary report for SaCo scores.\"\"\"\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"# SaCo Scores Analysis Report\\n\")\n",
    "    \n",
    "    # Overall summary\n",
    "    report.append(\"## Overall Performance\\n\")\n",
    "    \n",
    "    # Find best performing boost factor\n",
    "    mean_improvements = {bf: improvements[bf]['overall']['mean'] for bf in boost_factors}\n",
    "    median_improvements = {bf: improvements[bf]['overall']['median'] for bf in boost_factors}\n",
    "    \n",
    "    best_mean_bf = max(mean_improvements, key=mean_improvements.get)\n",
    "    best_median_bf = max(median_improvements, key=median_improvements.get)\n",
    "    \n",
    "    report.append(f\"**Overall SaCo Performance:**\")\n",
    "    report.append(f\"- Baseline mean: {calculate_saco_metrics(baseline_df)['overall']['mean']:.4f}\")\n",
    "    report.append(f\"- Baseline median: {calculate_saco_metrics(baseline_df)['overall']['median']:.4f}\")\n",
    "    report.append(f\"- Best mean improvement: {mean_improvements[best_mean_bf]:.2f}% at boost factor {best_mean_bf}\")\n",
    "    report.append(f\"- Best median improvement: {median_improvements[best_median_bf]:.2f}% at boost factor {best_median_bf}\")\n",
    "    \n",
    "    # Per-class summary\n",
    "    report.append(f\"\\n## Per-Class Performance\\n\")\n",
    "    baseline_metrics = calculate_saco_metrics(baseline_df)\n",
    "    \n",
    "    all_classes = set()\n",
    "    for bf_data in improvements.values():\n",
    "        all_classes.update(bf_data['by_class'].keys())\n",
    "    \n",
    "    for class_name in sorted(all_classes):\n",
    "        report.append(f\"**{class_name}:**\")\n",
    "        \n",
    "        if class_name in baseline_metrics['by_class']:\n",
    "            baseline_mean = baseline_metrics['by_class'][class_name]['mean']\n",
    "            baseline_median = baseline_metrics['by_class'][class_name]['median']\n",
    "            report.append(f\"- Baseline mean: {baseline_mean:.4f}\")\n",
    "            report.append(f\"- Baseline median: {baseline_median:.4f}\")\n",
    "        \n",
    "        class_mean_improvements = {}\n",
    "        class_median_improvements = {}\n",
    "        for bf in boost_factors:\n",
    "            if class_name in improvements[bf]['by_class']:\n",
    "                class_mean_improvements[bf] = improvements[bf]['by_class'][class_name].get('mean', 0)\n",
    "                class_median_improvements[bf] = improvements[bf]['by_class'][class_name].get('median', 0)\n",
    "        \n",
    "        if class_mean_improvements:\n",
    "            best_class_mean_bf = max(class_mean_improvements, key=class_mean_improvements.get)\n",
    "            best_class_median_bf = max(class_median_improvements, key=class_median_improvements.get)\n",
    "            report.append(f\"- Best mean improvement: {class_mean_improvements[best_class_mean_bf]:.2f}% at boost factor {best_class_mean_bf}\")\n",
    "            report.append(f\"- Best median improvement: {class_median_improvements[best_class_median_bf]:.2f}% at boost factor {best_class_median_bf}\")\n",
    "        \n",
    "        report.append(\"\")\n",
    "    \n",
    "    # Performance trend analysis\n",
    "    report.append(\"## Performance Trends\\n\")\n",
    "    report.append(\"**Mean SaCo Improvements by Boost Factor:**\")\n",
    "    for bf in boost_factors:\n",
    "        improvement = improvements[bf]['overall']['mean']\n",
    "        report.append(f\"- Boost Factor {bf}: {improvement:+.2f}%\")\n",
    "    \n",
    "    report.append(f\"\\n**Median SaCo Improvements by Boost Factor:**\")\n",
    "    for bf in boost_factors:\n",
    "        improvement = improvements[bf]['overall']['median']\n",
    "        report.append(f\"- Boost Factor {bf}: {improvement:+.2f}%\")\n",
    "    \n",
    "    # Save report\n",
    "    with open(f'{output_dir}/saco_analysis_report.md', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    weighted_dir = \"./results/train_weighted\"\n",
    "    baseline_path = \"./results/train/analysis_faithfulness_correctness_2025-05-26_19-30.csv\"\n",
    "    output_dir = \"./visualization_output\"\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading SaCo results...\")\n",
    "    weighted_results, baseline_df = load_saco_results(weighted_dir, baseline_path)\n",
    "    \n",
    "    print(f\"Found {len(weighted_results)} weighted result files\")\n",
    "    print(f\"Boost factors: {sorted(weighted_results.keys())}\")\n",
    "    print(f\"Baseline samples: {len(baseline_df)}\")\n",
    "    \n",
    "    # Calculate improvements\n",
    "    print(\"Calculating SaCo improvements...\")\n",
    "    improvements = calculate_saco_improvements(weighted_results, baseline_df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"Creating SaCo overall plots...\")\n",
    "    create_saco_overall_plots(improvements, output_dir)\n",
    "    \n",
    "    print(\"Creating SaCo class-wise plots...\")\n",
    "    create_saco_class_plots(improvements, output_dir)\n",
    "    \n",
    "    print(\"Generating SaCo summary report...\")\n",
    "    generate_saco_summary_report(improvements, weighted_results, baseline_df, output_dir)\n",
    "    \n",
    "    print(f\"All SaCo visualizations saved to {output_dir}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "783e7e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SaCo results...\n",
      "Loaded boost factor 1.5: 1800 samples\n",
      "Loaded boost factor 2.5: 1800 samples\n",
      "Loaded boost factor 3.5: 1800 samples\n",
      "Loaded boost factor 4.5: 1800 samples\n",
      "Loaded boost factor 5.5: 1800 samples\n",
      "SaCo: Found 5 weighted result files\n",
      "SaCo boost factors: [1.5, 2.5, 3.5, 4.5, 5.5]\n",
      "SaCo baseline samples: 1800\n",
      "\n",
      "Loading faithfulness results...\n",
      "Faithfulness: Found 5 weighted result files\n",
      "Faithfulness boost factors: [1.5, 2.5, 3.5, 4.5, 5.5]\n",
      "Faithfulness estimators: ['FaithfulnessCorrelation', 'Sufficiency']\n",
      "\n",
      "Creating combined SaCo + Faithfulness plot...\n",
      "\n",
      "Running Faithfulness analysis...\n",
      "\n",
      "================================================================================\n",
      "OVERALL METRICS SUMMARY (ABSOLUTE VALUES)\n",
      "================================================================================\n",
      "\n",
      "FAITHFULNESSCORRELATION:\n",
      "------------------------\n",
      "Boost Factor |     Mean Value     |    Median Value\n",
      "-------------|-------------------|------------------\n",
      "Baseline    |          0.152006 |         0.157393\n",
      "        1.5 |          0.148532 |         0.155388\n",
      "        2.5 |          0.142446 |         0.149373\n",
      "        3.5 |          0.136468 |         0.138596\n",
      "        4.5 |          0.131674 |         0.133835\n",
      "        5.5 |          0.127774 |         0.129323\n",
      "\n",
      "\n",
      "SUFFICIENCY:\n",
      "------------\n",
      "Boost Factor |     Mean Value     |    Median Value\n",
      "-------------|-------------------|------------------\n",
      "Baseline    |          0.354067 |         0.363636\n",
      "        1.5 |          0.364086 |         0.375000\n",
      "        2.5 |          0.384937 |         0.400000\n",
      "        3.5 |          0.408029 |         0.416667\n",
      "        4.5 |          0.428066 |         0.435340\n",
      "        5.5 |          0.443791 |         0.454545\n",
      "\n",
      "================================================================================\n",
      "Creating overall plots...\n",
      "Creating combined absolute values plot...\n",
      "Creating class-wise plots...\n",
      "Generating summary report...\n",
      "All visualizations saved to ./results/test_weighted/visualization_output/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Union\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# ===============================\n",
    "# SaCo-specific functions\n",
    "# ===============================\n",
    "\n",
    "def load_saco_results(weighted_dir: str, baseline_path: str) -> Tuple[Dict, pd.DataFrame]:\n",
    "    \"\"\"Load all SaCo CSV files and baseline.\"\"\"\n",
    "    # Load baseline\n",
    "    baseline_df = pd.read_csv(baseline_path)\n",
    "    \n",
    "    # Define boost factors in chronological order\n",
    "    boost_factors = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "    \n",
    "    # Expected file patterns (in chronological order)\n",
    "    file_patterns = [\n",
    "        \"analysis_faithfulness_correctness_2025-05-27_14-21.csv\",  # 1.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-27_15-22.csv\",  # 2.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-27_15-40.csv\",  # 3.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-27_15-59.csv\",  # 4.5\n",
    "        \"analysis_faithfulness_correctness_2025-05-27_16-17.csv\"   # 5.5\n",
    "    ]\n",
    "    \n",
    "    weighted_results = {}\n",
    "    for i, pattern in enumerate(file_patterns):\n",
    "        file_path = f\"{weighted_dir}/{pattern}\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            boost_factor = boost_factors[i]\n",
    "            weighted_results[boost_factor] = df\n",
    "            print(f\"Loaded boost factor {boost_factor}: {len(df)} samples\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {file_path} not found\")\n",
    "    \n",
    "    return weighted_results, baseline_df\n",
    "\n",
    "def calculate_saco_metrics(df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate overall and per-class SaCo metrics.\"\"\"\n",
    "    results = {\n",
    "        'overall': {\n",
    "            'mean': df['saco_score'].mean(),\n",
    "            'median': df['saco_score'].median(),\n",
    "            'count': len(df)\n",
    "        },\n",
    "        'by_class': {}\n",
    "    }\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for class_name in df['true_class'].unique():\n",
    "        class_data = df[df['true_class'] == class_name]\n",
    "        results['by_class'][class_name] = {\n",
    "            'mean': class_data['saco_score'].mean(),\n",
    "            'median': class_data['saco_score'].median(),\n",
    "            'count': len(class_data)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_saco_improvements(weighted_results: Dict, baseline_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate improvement percentages for SaCo scores.\"\"\"\n",
    "    baseline_metrics = calculate_saco_metrics(baseline_df)\n",
    "    improvements = {}\n",
    "    \n",
    "    for boost_factor, weighted_df in weighted_results.items():\n",
    "        weighted_metrics = calculate_saco_metrics(weighted_df)\n",
    "        improvements[boost_factor] = {\n",
    "            'saco_score': {  # Treat SaCo as a single \"estimator\"\n",
    "                'overall': {},\n",
    "                'by_class': {}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Overall improvements\n",
    "        for metric in ['mean', 'median']:\n",
    "            w_val = weighted_metrics['overall'][metric]\n",
    "            b_val = baseline_metrics['overall'][metric]\n",
    "            improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "            improvements[boost_factor]['saco_score']['overall'][metric] = improvement\n",
    "        \n",
    "        # Per-class improvements\n",
    "        for class_name in weighted_metrics['by_class'].keys():\n",
    "            if class_name in baseline_metrics['by_class']:\n",
    "                improvements[boost_factor]['saco_score']['by_class'][class_name] = {}\n",
    "                \n",
    "                for metric in ['mean', 'median']:\n",
    "                    w_val = weighted_metrics['by_class'][class_name][metric]\n",
    "                    b_val = baseline_metrics['by_class'][class_name][metric]\n",
    "                    improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "                    improvements[boost_factor]['saco_score']['by_class'][class_name][metric] = improvement\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "# ===============================\n",
    "# Faithfulness-specific functions\n",
    "# ===============================\n",
    "\n",
    "def load_faithfulness_results(weighted_dir: str, baseline_path: str) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Load all weighted results and baseline results.\"\"\"\n",
    "    # Load baseline\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline = json.load(f)\n",
    "    \n",
    "    # Load all weighted results\n",
    "    weighted_files = glob.glob(f\"{weighted_dir}/faithfulness_stats_*.json\")\n",
    "    weighted_results = {}\n",
    "    \n",
    "    for file_path in weighted_files:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            boost_factor = data.get('boost_factor_per_head', 0)\n",
    "            if boost_factor > 0:  # Only include files with boost factors\n",
    "                weighted_results[boost_factor] = data\n",
    "    \n",
    "    return weighted_results, baseline\n",
    "\n",
    "def calculate_faithfulness_improvements(weighted_results: Dict, baseline: Dict) -> Dict:\n",
    "    \"\"\"Calculate improvement percentages for each boost factor.\"\"\"\n",
    "    baseline_metrics = baseline.get('metrics', {})\n",
    "    improvements = {}\n",
    "    \n",
    "    for boost_factor, weighted_data in weighted_results.items():\n",
    "        weighted_metrics = weighted_data.get('metrics', {})\n",
    "        improvements[boost_factor] = {}\n",
    "        \n",
    "        for estimator_name in weighted_metrics.keys():\n",
    "            if estimator_name in baseline_metrics:\n",
    "                improvements[boost_factor][estimator_name] = {\n",
    "                    'overall': {},\n",
    "                    'by_class': {}\n",
    "                }\n",
    "                \n",
    "                # Overall improvements\n",
    "                w_overall = weighted_metrics[estimator_name]['overall']\n",
    "                b_overall = baseline_metrics[estimator_name]['overall']\n",
    "                \n",
    "                for metric in ['mean', 'median']:\n",
    "                    if metric in w_overall and metric in b_overall:\n",
    "                        w_val = w_overall[metric]\n",
    "                        b_val = b_overall[metric]\n",
    "                        improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "                        improvements[boost_factor][estimator_name]['overall'][metric] = improvement\n",
    "                \n",
    "                # Per-class improvements\n",
    "                w_classes = weighted_metrics[estimator_name].get('by_class', {})\n",
    "                b_classes = baseline_metrics[estimator_name].get('by_class', {})\n",
    "                \n",
    "                for class_id in w_classes.keys():\n",
    "                    if class_id in b_classes:\n",
    "                        improvements[boost_factor][estimator_name]['by_class'][class_id] = {}\n",
    "                        \n",
    "                        for metric in ['mean', 'median']:\n",
    "                            if metric in w_classes[class_id] and metric in b_classes[class_id]:\n",
    "                                w_val = w_classes[class_id][metric]\n",
    "                                b_val = b_classes[class_id][metric]\n",
    "                                improvement = (w_val / b_val - 1) * 100 if b_val != 0 else 0\n",
    "                                improvements[boost_factor][estimator_name]['by_class'][class_id][metric] = improvement\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "# ===============================\n",
    "# Unified plotting and reporting functions\n",
    "# ===============================\n",
    "\n",
    "def create_overall_plots(improvements: Dict, output_dir: str, analysis_type: str):\n",
    "    \"\"\"Create overall improvement plots.\"\"\"\n",
    "    # Set matplotlib style\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.figsize': (10, 6)\n",
    "    })\n",
    "    \n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Mean improvements\n",
    "        mean_improvements = [improvements[bf][estimator]['overall']['mean'] \n",
    "                           for bf in boost_factors]\n",
    "        color1 = 'green' if analysis_type == 'saco' else 'blue'\n",
    "        ax1.plot(boost_factors, mean_improvements, 'o-', linewidth=2, markersize=6, color=color1)\n",
    "        ax1.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax1.set_xlabel('Boost Factor')\n",
    "        ax1.set_ylabel('Mean Improvement (%)')\n",
    "        ax1.set_title(f'{estimator} - Mean Performance')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Median improvements\n",
    "        median_improvements = [improvements[bf][estimator]['overall']['median'] \n",
    "                             for bf in boost_factors]\n",
    "        color2 = 'purple' if analysis_type == 'saco' else 'orange'\n",
    "        ax2.plot(boost_factors, median_improvements, 'o-', linewidth=2, markersize=6, color=color2)\n",
    "        ax2.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax2.set_xlabel('Boost Factor')\n",
    "        ax2.set_ylabel('Median Improvement (%)')\n",
    "        ax2.set_title(f'{estimator} - Median Performance')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/{estimator}_overall_improvements.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def create_combined_all_metrics_plot(saco_weighted_results: Dict, saco_baseline: pd.DataFrame,\n",
    "                                   faithfulness_weighted_results: Dict, faithfulness_baseline: Dict,\n",
    "                                   output_dir: str):\n",
    "    \"\"\"Create a single plot showing SaCo and all Faithfulness metrics with absolute values.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.figsize': (12, 8)\n",
    "    })\n",
    "    \n",
    "    # Get common boost factors (intersection of both datasets)\n",
    "    saco_bfs = set(saco_weighted_results.keys()) if saco_weighted_results else set()\n",
    "    faith_bfs = set(faithfulness_weighted_results.keys()) if faithfulness_weighted_results else set()\n",
    "    common_boost_factors = sorted(saco_bfs.intersection(faith_bfs))\n",
    "    \n",
    "    if not common_boost_factors:\n",
    "        print(\"Warning: No common boost factors found between SaCo and Faithfulness data\")\n",
    "        return\n",
    "    \n",
    "    # Get all metrics\n",
    "    all_metrics = []\n",
    "    baseline_values = {}\n",
    "    \n",
    "    # Add SaCo if available\n",
    "    if saco_weighted_results and saco_baseline is not None:\n",
    "        saco_baseline_metrics = calculate_saco_metrics(saco_baseline)\n",
    "        all_metrics.append('SaCo')\n",
    "        baseline_values['SaCo'] = {\n",
    "            'mean': saco_baseline_metrics['overall']['mean'],\n",
    "            'median': saco_baseline_metrics['overall']['median']\n",
    "        }\n",
    "    \n",
    "    # Add Faithfulness metrics if available\n",
    "    if faithfulness_weighted_results and faithfulness_baseline:\n",
    "        faithfulness_baseline_metrics = faithfulness_baseline.get('metrics', {})\n",
    "        for estimator in faithfulness_baseline_metrics.keys():\n",
    "            all_metrics.append(estimator)\n",
    "            baseline_values[estimator] = {\n",
    "                'mean': faithfulness_baseline_metrics[estimator]['overall'].get('mean', 0),\n",
    "                'median': faithfulness_baseline_metrics[estimator]['overall'].get('median', 0)\n",
    "            }\n",
    "    \n",
    "    if not all_metrics:\n",
    "        print(\"Warning: No metrics found to plot\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots for mean and median\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Define colors for different metrics\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(all_metrics)))\n",
    "    \n",
    "    for i, metric in enumerate(all_metrics):\n",
    "        # Collect absolute values for each boost factor\n",
    "        mean_values = [baseline_values[metric]['mean']]  # Start with baseline\n",
    "        median_values = [baseline_values[metric]['median']]\n",
    "        x_values = [0] + common_boost_factors  # Include 0 for baseline\n",
    "        \n",
    "        for bf in common_boost_factors:\n",
    "            if metric == 'SaCo':\n",
    "                if bf in saco_weighted_results:\n",
    "                    weighted_metrics = calculate_saco_metrics(saco_weighted_results[bf])\n",
    "                    mean_val = weighted_metrics['overall']['mean']\n",
    "                    median_val = weighted_metrics['overall']['median']\n",
    "                else:\n",
    "                    mean_val = baseline_values[metric]['mean']\n",
    "                    median_val = baseline_values[metric]['median']\n",
    "            else:\n",
    "                if bf in faithfulness_weighted_results:\n",
    "                    weighted_metrics = faithfulness_weighted_results[bf].get('metrics', {}).get(metric, {})\n",
    "                    mean_val = weighted_metrics.get('overall', {}).get('mean', 0)\n",
    "                    median_val = weighted_metrics.get('overall', {}).get('median', 0)\n",
    "                else:\n",
    "                    mean_val = baseline_values[metric]['mean']\n",
    "                    median_val = baseline_values[metric]['median']\n",
    "            \n",
    "            mean_values.append(mean_val)\n",
    "            median_values.append(median_val)\n",
    "        \n",
    "        # Plot mean values\n",
    "        ax1.plot(x_values, mean_values, 'o-', linewidth=2, markersize=6, \n",
    "                color=colors[i], label=f'{metric}')\n",
    "        \n",
    "        # Add baseline as dotted horizontal line for mean\n",
    "        ax1.axhline(y=baseline_values[metric]['mean'], color=colors[i], \n",
    "                   linestyle=':', alpha=0.7, linewidth=1.5)\n",
    "        \n",
    "        # Plot median values  \n",
    "        ax2.plot(x_values, median_values, 'o-', linewidth=2, markersize=6,\n",
    "                color=colors[i], label=f'{metric}')\n",
    "        \n",
    "        # Add baseline as dotted horizontal line for median\n",
    "        ax2.axhline(y=baseline_values[metric]['median'], color=colors[i], \n",
    "                   linestyle=':', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    # Customize mean plot\n",
    "    ax1.set_xlabel('Boost Factor (0 = Baseline)')\n",
    "    ax1.set_ylabel('Absolute Mean Value')\n",
    "    ax1.set_title('All Metrics (SaCo + Faithfulness) - Mean Absolute Values')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Customize median plot\n",
    "    ax2.set_xlabel('Boost Factor (0 = Baseline)')\n",
    "    ax2.set_ylabel('Absolute Median Value')\n",
    "    ax2.set_title('All Metrics (SaCo + Faithfulness) - Median Absolute Values')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/combined_saco_faithfulness_absolute.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_combined_absolute_plot(weighted_results: Dict, baseline_data: Any, \n",
    "                                output_dir: str, analysis_type: str):\n",
    "    \"\"\"Create a single plot showing all metrics with absolute values.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.figsize': (12, 8)\n",
    "    })\n",
    "    \n",
    "    boost_factors = sorted(weighted_results.keys())\n",
    "    \n",
    "    # Get baseline values for all estimators\n",
    "    if analysis_type == \"saco\":\n",
    "        baseline_metrics = calculate_saco_metrics(baseline_data)\n",
    "        estimators = ['saco_score']\n",
    "        baseline_values = {\n",
    "            'saco_score': {\n",
    "                'mean': baseline_metrics['overall']['mean'],\n",
    "                'median': baseline_metrics['overall']['median']\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        baseline_metrics = baseline_data.get('metrics', {})\n",
    "        estimators = list(baseline_metrics.keys())\n",
    "        baseline_values = {}\n",
    "        for est in estimators:\n",
    "            baseline_values[est] = {\n",
    "                'mean': baseline_metrics[est]['overall'].get('mean', 0),\n",
    "                'median': baseline_metrics[est]['overall'].get('median', 0)\n",
    "            }\n",
    "    \n",
    "    # Create subplots for mean and median\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Define colors for different estimators\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(estimators)))\n",
    "    \n",
    "    for i, estimator in enumerate(estimators):\n",
    "        # Collect absolute values for each boost factor\n",
    "        mean_values = [baseline_values[estimator]['mean']]  # Start with baseline\n",
    "        median_values = [baseline_values[estimator]['median']]\n",
    "        x_values = [0] + boost_factors  # Include 0 for baseline\n",
    "        \n",
    "        for bf in boost_factors:\n",
    "            if analysis_type == \"saco\":\n",
    "                weighted_metrics = calculate_saco_metrics(weighted_results[bf])\n",
    "                mean_val = weighted_metrics['overall']['mean']\n",
    "                median_val = weighted_metrics['overall']['median']\n",
    "            else:\n",
    "                weighted_metrics = weighted_results[bf].get('metrics', {}).get(estimator, {})\n",
    "                mean_val = weighted_metrics.get('overall', {}).get('mean', 0)\n",
    "                median_val = weighted_metrics.get('overall', {}).get('median', 0)\n",
    "            \n",
    "            mean_values.append(mean_val)\n",
    "            median_values.append(median_val)\n",
    "        \n",
    "        # Plot mean values\n",
    "        ax1.plot(x_values, mean_values, 'o-', linewidth=2, markersize=6, \n",
    "                color=colors[i], label=f'{estimator}')\n",
    "        \n",
    "        # Plot median values  \n",
    "        ax2.plot(x_values, median_values, 'o-', linewidth=2, markersize=6,\n",
    "                color=colors[i], label=f'{estimator}')\n",
    "    \n",
    "    # Customize mean plot\n",
    "    ax1.axvline(x=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "    ax1.set_xlabel('Boost Factor (0 = Baseline)')\n",
    "    ax1.set_ylabel('Absolute Mean Value')\n",
    "    ax1.set_title('All Metrics - Mean Absolute Values')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Customize median plot\n",
    "    ax2.axvline(x=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "    ax2.set_xlabel('Boost Factor (0 = Baseline)')\n",
    "    ax2.set_ylabel('Absolute Median Value')\n",
    "    ax2.set_title('All Metrics - Median Absolute Values')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/combined_absolute_values.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_class_plots(improvements: Dict, output_dir: str, analysis_type: str):\n",
    "    \"\"\"Create per-class improvement plots.\"\"\"\n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        # Get all classes\n",
    "        all_classes = set()\n",
    "        for bf_data in improvements.values():\n",
    "            all_classes.update(bf_data[estimator]['by_class'].keys())\n",
    "        all_classes = sorted(all_classes)\n",
    "        \n",
    "        # Create subplots for each metric\n",
    "        for metric in ['mean', 'median']:\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            \n",
    "            colors = plt.cm.Set1(np.linspace(0, 1, len(all_classes)))\n",
    "            \n",
    "            for i, class_id in enumerate(all_classes):\n",
    "                class_improvements = []\n",
    "                for bf in boost_factors:\n",
    "                    if class_id in improvements[bf][estimator]['by_class']:\n",
    "                        improvement = improvements[bf][estimator]['by_class'][class_id].get(metric, 0)\n",
    "                        class_improvements.append(improvement)\n",
    "                    else:\n",
    "                        class_improvements.append(0)\n",
    "                \n",
    "                label = f'{class_id}' if analysis_type == 'saco' else f'Class {class_id}'\n",
    "                ax.plot(boost_factors, class_improvements, 'o-', \n",
    "                       label=label, color=colors[i], linewidth=2, markersize=5)\n",
    "            \n",
    "            ax.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "            ax.set_xlabel('Boost Factor')\n",
    "            ax.set_ylabel(f'{metric.title()} Improvement (%)')\n",
    "            ax.set_title(f'{estimator} - {metric.title()} Performance by Class')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/{estimator}_class_{metric}_improvements.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "def generate_summary_report(improvements: Dict, weighted_results: Dict, baseline_data: Any, \n",
    "                          output_dir: str, analysis_type: str):\n",
    "    \"\"\"Generate a summary report with key findings.\"\"\"\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    \n",
    "    report = []\n",
    "    title = \"SaCo Scores Analysis Report\" if analysis_type == 'saco' else \"Faithfulness Metrics Analysis Report\"\n",
    "    report.append(f\"# {title}\\n\")\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        report.append(f\"## {estimator}\\n\")\n",
    "        \n",
    "        # Get baseline metrics for context\n",
    "        if analysis_type == 'saco':\n",
    "            baseline_metrics = calculate_saco_metrics(baseline_data)\n",
    "            baseline_overall = baseline_metrics['overall']\n",
    "            baseline_classes = baseline_metrics['by_class']\n",
    "        else:\n",
    "            baseline_metrics = baseline_data.get('metrics', {}).get(estimator, {})\n",
    "            baseline_overall = baseline_metrics.get('overall', {})\n",
    "            baseline_classes = baseline_metrics.get('by_class', {})\n",
    "        \n",
    "        # Overall performance summary\n",
    "        if baseline_overall:\n",
    "            report.append(f\"**Overall {estimator} Performance:**\")\n",
    "            if 'mean' in baseline_overall:\n",
    "                report.append(f\"- Baseline mean: {baseline_overall['mean']:.4f}\")  \n",
    "            if 'median' in baseline_overall:\n",
    "                report.append(f\"- Baseline median: {baseline_overall['median']:.4f}\")\n",
    "        \n",
    "        # Find best performing boost factor\n",
    "        mean_improvements = {bf: improvements[bf][estimator]['overall']['mean'] \n",
    "                           for bf in boost_factors}\n",
    "        median_improvements = {bf: improvements[bf][estimator]['overall']['median'] \n",
    "                             for bf in boost_factors}\n",
    "        \n",
    "        best_mean_bf = max(mean_improvements, key=mean_improvements.get)\n",
    "        best_median_bf = max(median_improvements, key=median_improvements.get)\n",
    "        \n",
    "        report.append(f\"- Best mean improvement: {mean_improvements[best_mean_bf]:.2f}% at boost factor {best_mean_bf}\")\n",
    "        report.append(f\"- Best median improvement: {median_improvements[best_median_bf]:.2f}% at boost factor {best_median_bf}\")\n",
    "        \n",
    "        # Per-class summary\n",
    "        report.append(f\"\\n**Per-Class Performance:**\")\n",
    "        all_classes = set()\n",
    "        for bf_data in improvements.values():\n",
    "            all_classes.update(bf_data[estimator]['by_class'].keys())\n",
    "        \n",
    "        for class_id in sorted(all_classes):\n",
    "            class_label = f\"**{class_id}:**\" if analysis_type == 'saco' else f\"**Class {class_id}:**\"\n",
    "            report.append(class_label)\n",
    "            \n",
    "            # Add baseline info if available\n",
    "            if class_id in baseline_classes:\n",
    "                if 'mean' in baseline_classes[class_id]:\n",
    "                    report.append(f\"- Baseline mean: {baseline_classes[class_id]['mean']:.4f}\")\n",
    "                if 'median' in baseline_classes[class_id]:\n",
    "                    report.append(f\"- Baseline median: {baseline_classes[class_id]['median']:.4f}\")\n",
    "            \n",
    "            class_mean_improvements = {}\n",
    "            class_median_improvements = {}\n",
    "            for bf in boost_factors:\n",
    "                if class_id in improvements[bf][estimator]['by_class']:\n",
    "                    class_mean_improvements[bf] = improvements[bf][estimator]['by_class'][class_id].get('mean', 0)\n",
    "                    class_median_improvements[bf] = improvements[bf][estimator]['by_class'][class_id].get('median', 0)\n",
    "            \n",
    "            if class_mean_improvements:\n",
    "                best_class_mean_bf = max(class_mean_improvements, key=class_mean_improvements.get)\n",
    "                best_class_median_bf = max(class_median_improvements, key=class_median_improvements.get)\n",
    "                report.append(f\"- Best mean improvement: {class_mean_improvements[best_class_mean_bf]:.2f}% at boost factor {best_class_mean_bf}\")\n",
    "                report.append(f\"- Best median improvement: {class_median_improvements[best_class_median_bf]:.2f}% at boost factor {best_class_median_bf}\")\n",
    "            \n",
    "            report.append(\"\")\n",
    "        \n",
    "        # Performance trend analysis\n",
    "        report.append(\"## Performance Trends\\n\")\n",
    "        report.append(f\"**Mean {estimator} Improvements by Boost Factor:**\")\n",
    "        for bf in boost_factors:\n",
    "            improvement = improvements[bf][estimator]['overall']['mean']\n",
    "            report.append(f\"- Boost Factor {bf}: {improvement:+.2f}%\")\n",
    "        \n",
    "        report.append(f\"\\n**Median {estimator} Improvements by Boost Factor:**\")\n",
    "        for bf in boost_factors:\n",
    "            improvement = improvements[bf][estimator]['overall']['median']\n",
    "            report.append(f\"- Boost Factor {bf}: {improvement:+.2f}%\")\n",
    "        \n",
    "        report.append(\"\")\n",
    "    \n",
    "    # Save report\n",
    "    filename = f'{analysis_type}_analysis_report.md'\n",
    "    with open(f'{output_dir}/{filename}', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "\n",
    "def main():\n",
    "    # Configuration - specify which analysis to run for individual plots\n",
    "    ANALYSIS_TYPE = \"faithfulness\"  # Change to \"faithfulness\" for individual analysis focus\n",
    "    \n",
    "    # Paths for both analyses\n",
    "    saco_weighted_dir = \"./results/test_weighted\"\n",
    "    saco_baseline_path = \"./results/test/analysis_faithfulness_correctness_2025-05-27_15-02.csv\"\n",
    "    faithfulness_weighted_dir = \"./results/test_weighted\"\n",
    "    faithfulness_baseline_path = \"./results/test/faithfulness_stats_2025-05-27_14-37.json\"\n",
    "    output_dir = \"./results/test_weighted/visualization_output\"\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Try to load both datasets\n",
    "    saco_weighted_results = None\n",
    "    saco_baseline_data = None\n",
    "    faithfulness_weighted_results = None\n",
    "    faithfulness_baseline_data = None\n",
    "    \n",
    "    # Load SaCo data\n",
    "    try:\n",
    "        print(\"Loading SaCo results...\")\n",
    "        saco_weighted_results, saco_baseline_data = load_saco_results(saco_weighted_dir, saco_baseline_path)\n",
    "        print(f\"SaCo: Found {len(saco_weighted_results)} weighted result files\")\n",
    "        print(f\"SaCo boost factors: {sorted(saco_weighted_results.keys())}\")\n",
    "        print(f\"SaCo baseline samples: {len(saco_baseline_data)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load SaCo data: {e}\")\n",
    "    \n",
    "    # Load Faithfulness data\n",
    "    try:\n",
    "        print(\"\\nLoading faithfulness results...\")\n",
    "        faithfulness_weighted_results, faithfulness_baseline_data = load_faithfulness_results(faithfulness_weighted_dir, faithfulness_baseline_path)\n",
    "        print(f\"Faithfulness: Found {len(faithfulness_weighted_results)} weighted result files\")\n",
    "        print(f\"Faithfulness boost factors: {sorted(faithfulness_weighted_results.keys())}\")\n",
    "        if faithfulness_baseline_data:\n",
    "            estimators = list(faithfulness_baseline_data.get('metrics', {}).keys())\n",
    "            print(f\"Faithfulness estimators: {estimators}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load Faithfulness data: {e}\")\n",
    "    \n",
    "    # Create combined plot if both datasets are available\n",
    "    if saco_weighted_results and faithfulness_weighted_results:\n",
    "        print(\"\\nCreating combined SaCo + Faithfulness plot...\")\n",
    "        create_combined_all_metrics_plot(saco_weighted_results, saco_baseline_data,\n",
    "                                       faithfulness_weighted_results, faithfulness_baseline_data,\n",
    "                                       output_dir)\n",
    "    else:\n",
    "        print(\"Warning: Cannot create combined plot - missing SaCo or Faithfulness data\")\n",
    "    \n",
    "    # Run individual analysis based on ANALYSIS_TYPE\n",
    "    if ANALYSIS_TYPE == \"saco\" and saco_weighted_results:\n",
    "        print(\"\\nRunning SaCo analysis...\")\n",
    "        weighted_results, baseline_data = saco_weighted_results, saco_baseline_data\n",
    "        improvements = calculate_saco_improvements(weighted_results, baseline_data)\n",
    "        \n",
    "    elif ANALYSIS_TYPE == \"faithfulness\" and faithfulness_weighted_results:\n",
    "        print(\"\\nRunning Faithfulness analysis...\")\n",
    "        weighted_results, baseline_data = faithfulness_weighted_results, faithfulness_baseline_data\n",
    "        improvements = calculate_faithfulness_improvements(weighted_results, baseline_data)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Cannot run {ANALYSIS_TYPE} analysis - data not available\")\n",
    "        return\n",
    "    \n",
    "    # Print overall metrics for easy copying\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL METRICS SUMMARY (ABSOLUTE VALUES)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Print baseline values first\n",
    "    estimators = list(list(improvements.values())[0].keys())\n",
    "    boost_factors = sorted(improvements.keys())\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        print(f\"\\n{estimator.upper()}:\")\n",
    "        print(\"-\" * (len(estimator) + 1))\n",
    "        \n",
    "        # Get baseline values\n",
    "        if ANALYSIS_TYPE == \"saco\":\n",
    "            baseline_metrics = calculate_saco_metrics(baseline_data)\n",
    "            baseline_mean = baseline_metrics['overall']['mean']\n",
    "            baseline_median = baseline_metrics['overall']['median']\n",
    "        else:\n",
    "            baseline_metrics = baseline_data.get('metrics', {}).get(estimator, {})\n",
    "            baseline_mean = baseline_metrics.get('overall', {}).get('mean', 0)\n",
    "            baseline_median = baseline_metrics.get('overall', {}).get('median', 0)\n",
    "        \n",
    "        # Print table with absolute values\n",
    "        print(\"Boost Factor |     Mean Value     |    Median Value\")\n",
    "        print(\"-------------|-------------------|------------------\")\n",
    "        print(f\"{'Baseline':11} | {baseline_mean:17.6f} | {baseline_median:16.6f}\")\n",
    "        \n",
    "        # Print absolute values for each boost factor\n",
    "        for bf in boost_factors:\n",
    "            if ANALYSIS_TYPE == \"saco\":\n",
    "                # Get actual values from the DataFrame\n",
    "                weighted_metrics = calculate_saco_metrics(weighted_results[bf])\n",
    "                actual_mean = weighted_metrics['overall']['mean']\n",
    "                actual_median = weighted_metrics['overall']['median']\n",
    "            else:\n",
    "                # Get actual values from the JSON data\n",
    "                weighted_metrics = weighted_results[bf].get('metrics', {}).get(estimator, {})\n",
    "                actual_mean = weighted_metrics.get('overall', {}).get('mean', 0)\n",
    "                actual_median = weighted_metrics.get('overall', {}).get('median', 0)\n",
    "            \n",
    "            print(f\"{bf:11.1f} | {actual_mean:17.6f} | {actual_median:16.6f}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create visualizations (unified for both types)\n",
    "    print(\"Creating overall plots...\")\n",
    "    create_overall_plots(improvements, output_dir, ANALYSIS_TYPE)\n",
    "    \n",
    "    print(\"Creating combined absolute values plot...\")\n",
    "    create_combined_absolute_plot(weighted_results, baseline_data, output_dir, ANALYSIS_TYPE)\n",
    "    \n",
    "    print(\"Creating class-wise plots...\")\n",
    "    create_class_plots(improvements, output_dir, ANALYSIS_TYPE)\n",
    "    \n",
    "    print(\"Generating summary report...\")\n",
    "    generate_summary_report(improvements, weighted_results, baseline_data, output_dir, ANALYSIS_TYPE)\n",
    "    \n",
    "    print(f\"All visualizations saved to {output_dir}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
